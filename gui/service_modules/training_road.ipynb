{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-11 02:16:04.452779: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import copy\n",
    "from math import pi\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from pandas import DataFrame as DF\n",
    "from models import AP_ResNet, ResNet, VGG_branch\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "from classifier import preprocessing as prep\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['asphalt','bicycle','block','floor','ground']\n",
    "bound = 414"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(matrix,title):\n",
    "    df=DF(matrix, index = class_names, columns = class_names)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    sns.heatmap(df, annot=True)\n",
    "    plt.tick_params(axis='x', top=True, labeltop = True,bottom=False, labelbottom=False)\n",
    "    plt.xticks(np.arange(0.5, len(df.columns), 1), df.columns)\n",
    "    plt.yticks(np.arange(0.5, len(df.index), 1), df.index)\n",
    "    plt.xlabel(\"Prediction\",position = (0.5,1.0+0.05))\n",
    "    plt.ylabel(\"Object\")\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2idx_Dict = {\n",
    "                'asphalt' : 0,\n",
    "                'bicycle' : 1,\n",
    "                'block' : 2,\n",
    "                'floor' : 3,\n",
    "                'ground' : 4,\n",
    "            }\n",
    "\n",
    "idx2label_Dict = {\n",
    "    0 : 'asphalt',\n",
    "    1 : 'bicycle',\n",
    "    2 : 'block',\n",
    "    3 : 'floor',\n",
    "    4 : 'ground',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = './road_data'\n",
    "def readNpy(dir_path):\n",
    "    class_num = len(idx2label_Dict)\n",
    "\n",
    "    Asphalt = list()\n",
    "    Bicycle = list()\n",
    "    Block = list()\n",
    "    Floor = list()\n",
    "    Ground = list()\n",
    "    Asphalt = np.array(Asphalt)\n",
    "    Bicycle = np.array(Bicycle)\n",
    "    Block = np.array(Block)\n",
    "    Floor = np.array(Floor)\n",
    "    Ground = np.array(Ground)\n",
    "    \n",
    "\n",
    "    for dir in os.listdir(dir_path):\n",
    "        d_path = os.path.join(dir_path, dir)\n",
    "        file_list = os.listdir(d_path)\n",
    "        for file in file_list:\n",
    "            file_path = os.path.join(d_path, file)\n",
    "            if dir == idx2label_Dict[0] :\n",
    "                if len(Asphalt) == 0:\n",
    "                    Asphalt = np.load(file_path, allow_pickle=True)\n",
    "                else :\n",
    "                    Asphalt = np.append(Asphalt, np.load(file_path), axis = 0)\n",
    "            elif dir == idx2label_Dict[1]:\n",
    "                if len(Bicycle) == 0:\n",
    "                    Bicycle = np.load(file_path, allow_pickle=True)\n",
    "                else :\n",
    "                    Bicycle = np.append(Bicycle, np.load(file_path), axis = 0)\n",
    "            elif dir == idx2label_Dict[2]:\n",
    "                if len(Block) == 0:\n",
    "                    Block = np.load(file_path, allow_pickle=True)\n",
    "                else:\n",
    "                    Block = np.append(Block, np.load(file_path), axis = 0)\n",
    "            elif dir == idx2label_Dict[3]:\n",
    "                if len(Floor) == 0:\n",
    "                    Floor = np.load(file_path, allow_pickle=True)\n",
    "                else:\n",
    "                    Floor = np.append(Floor, np.load(file_path), axis = 0)\n",
    "            elif dir == idx2label_Dict[4]:\n",
    "                if len(Ground) == 0:\n",
    "                    Ground = np.load(file_path, allow_pickle=True)\n",
    "                else:\n",
    "                    Ground = np.append(Ground, np.load(file_path), axis = 0)\n",
    "\n",
    "    bound = Asphalt.shape[1]\n",
    "\n",
    "    Ground_label = np.full((Ground.shape[0], class_num), np.eye(len(label2idx_Dict))[label2idx_Dict['ground']])\n",
    "    Asphalt_label = np.full((Asphalt.shape[0],class_num), np.eye(len(label2idx_Dict))[label2idx_Dict['asphalt']])\n",
    "    Bicycle_label = np.full((Bicycle.shape[0],class_num), np.eye(len(label2idx_Dict))[label2idx_Dict['bicycle']])\n",
    "    Block_label = np.full((Block.shape[0],class_num), np.eye(len(label2idx_Dict))[label2idx_Dict['block']])\n",
    "    Floor_label = np.full((Floor.shape[0],class_num), np.eye(len(label2idx_Dict))[label2idx_Dict['floor']])\n",
    "\n",
    "    Ground = np.concatenate((Ground, Ground_label), axis=1)\n",
    "    Asphalt = np.concatenate((Asphalt, Asphalt_label), axis=1)\n",
    "    Bicycle = np.concatenate((Bicycle, Bicycle_label), axis=1)\n",
    "    Block = np.concatenate((Block, Block_label), axis=1)\n",
    "    Floor = np.concatenate((Floor, Floor_label), axis=1)\n",
    "    \n",
    "    array = Asphalt\n",
    "    array = np.append(array, Bicycle, axis = 0)\n",
    "    array = np.append(array, Block, axis = 0)\n",
    "    array = np.append(array, Floor, axis = 0)\n",
    "    array = np.append(array, Ground, axis = 0)\n",
    "    s = np.arange(array.shape[0])\n",
    "    np.random.shuffle(s)\n",
    "    array_s = array[s]\n",
    "\n",
    "    X = array_s[:,:bound]\n",
    "    Y = np.real(array_s[:,bound:])\n",
    "    return copy.deepcopy(X), copy.deepcopy(Y)\n",
    "\n",
    "X, Y = readNpy(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intervalMean(arr, num):\n",
    "    meaned_arr = []\n",
    "    meaned_arr = np.array(meaned_arr)\n",
    "    meaned_arr = np.mean(arr[0:num], axis = 0)\n",
    "    meaned_arr = np.expand_dims(meaned_arr, axis = 0)\n",
    "    for i in range(num, len(arr), num):\n",
    "        # print(arr.shape)\n",
    "        if (i+num) > len(arr):\n",
    "            temp = np.mean(arr[i : (len(arr) + 1)], axis = 0)\n",
    "            temp = np.expand_dims(temp, axis = 0)\n",
    "            meaned_arr = np.concatenate((meaned_arr, temp), axis = 0)\n",
    "        else :\n",
    "            # print(np.mean(arr[i:i+num], axis = 0).shape)\n",
    "            temp = np.mean(arr[i : (i + num)], axis = 0)\n",
    "            temp = np.expand_dims(temp, axis = 0)\n",
    "            # print(temp.shape)\n",
    "            meaned_arr = np.concatenate((meaned_arr, temp), axis = 0)\n",
    "    return meaned_arr\n",
    "    \n",
    "def readNpyMean(dir_path, num):\n",
    "    class_num = len(idx2label_Dict)\n",
    "\n",
    "    Asphalt = list()\n",
    "    Bicycle = list()\n",
    "    Block = list()\n",
    "    Floor = list()\n",
    "    Ground = list()\n",
    "    Asphalt = np.array(Asphalt)\n",
    "    Bicycle = np.array(Bicycle)\n",
    "    Block = np.array(Block)\n",
    "    Floor = np.array(Floor)\n",
    "    Ground = np.array(Ground)\n",
    "    \n",
    "\n",
    "    for dir in os.listdir(dir_path):\n",
    "        d_path = os.path.join(dir_path, dir)\n",
    "        file_list = os.listdir(d_path)\n",
    "        for file in file_list:\n",
    "            file_path = os.path.join(d_path, file)\n",
    "            if dir == idx2label_Dict[0] :\n",
    "                if len(Asphalt) == 0:\n",
    "                    Asphalt = np.load(file_path, allow_pickle=True)\n",
    "                else :\n",
    "                    Asphalt = np.append(Asphalt, np.load(file_path), axis = 0)\n",
    "            elif dir == idx2label_Dict[1]:\n",
    "                if len(Bicycle) == 0:\n",
    "                    Bicycle = np.load(file_path, allow_pickle=True)\n",
    "                else :\n",
    "                    Bicycle = np.append(Bicycle, np.load(file_path), axis = 0)\n",
    "            elif dir == idx2label_Dict[2]:\n",
    "                if len(Block) == 0:\n",
    "                    Block = np.load(file_path, allow_pickle=True)\n",
    "                else:\n",
    "                    Block = np.append(Block, np.load(file_path), axis = 0)\n",
    "            elif dir == idx2label_Dict[3]:\n",
    "                if len(Floor) == 0:\n",
    "                    Floor = np.load(file_path, allow_pickle=True)\n",
    "                else:\n",
    "                    Floor = np.append(Floor, np.load(file_path), axis = 0)\n",
    "            elif dir == idx2label_Dict[4]:\n",
    "                if len(Ground) == 0:\n",
    "                    Ground = np.load(file_path, allow_pickle=True)\n",
    "                else:\n",
    "                    Ground = np.append(Ground, np.load(file_path), axis = 0)\n",
    "\n",
    "    bound = Asphalt.shape[1]\n",
    "    Asphalt_mean = intervalMean(Asphalt, num)\n",
    "    Bicycle_mean = intervalMean(Bicycle, num)\n",
    "    Block_mean = intervalMean(Block, num)\n",
    "    Floor_mean = intervalMean(Floor, num)\n",
    "    Ground_mean = intervalMean(Ground, num)\n",
    "\n",
    "    Ground_label = np.full((Ground_mean.shape[0], class_num), np.eye(len(label2idx_Dict))[label2idx_Dict['ground']])\n",
    "    Asphalt_label = np.full((Asphalt_mean.shape[0],class_num), np.eye(len(label2idx_Dict))[label2idx_Dict['asphalt']])\n",
    "    Bicycle_label = np.full((Bicycle_mean.shape[0],class_num), np.eye(len(label2idx_Dict))[label2idx_Dict['bicycle']])\n",
    "    Block_label = np.full((Block_mean.shape[0],class_num), np.eye(len(label2idx_Dict))[label2idx_Dict['block']])\n",
    "    Floor_label = np.full((Floor_mean.shape[0],class_num), np.eye(len(label2idx_Dict))[label2idx_Dict['floor']])\n",
    "\n",
    "    Ground = np.concatenate((Ground_mean, Ground_label), axis=1)\n",
    "    Asphalt = np.concatenate((Asphalt_mean, Asphalt_label), axis=1)\n",
    "    Bicycle = np.concatenate((Bicycle_mean, Bicycle_label), axis=1)\n",
    "    Block = np.concatenate((Block_mean, Block_label), axis=1)\n",
    "    Floor = np.concatenate((Floor_mean, Floor_label), axis=1)\n",
    "    \n",
    "    array = Asphalt\n",
    "    array = np.append(array, Bicycle, axis = 0)\n",
    "    array = np.append(array, Block, axis = 0)\n",
    "    array = np.append(array, Floor, axis = 0)\n",
    "    array = np.append(array, Ground, axis = 0)\n",
    "    s = np.arange(array.shape[0])\n",
    "    np.random.shuffle(s)\n",
    "    array_s = array[s]\n",
    "\n",
    "    X = array_s[:,:bound]\n",
    "    Y = np.real(array_s[:,bound:])\n",
    "    return copy.deepcopy(X), copy.deepcopy(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperater(arr):\n",
    "    global maximum\n",
    "    pre_data = arr\n",
    "    amp = np.abs(pre_data)\n",
    "    amp = amp / maximum\n",
    "    phs = np.angle(pre_data)\n",
    "    # phs = (phs - (- pi)) / (pi - (- pi))\n",
    "    sin = np.sin(phs)\n",
    "    sin = (sin + 1) / 2\n",
    "    seperated_data = np.stack((amp.T,sin.T), axis=0)\n",
    "    seperated_data = np.expand_dims(seperated_data, axis=0)\n",
    "    return np.array(seperated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataSeperator(arr):\n",
    "    temp = copy.deepcopy(seperater(arr[0]))\n",
    "    for i in range(1, len(arr)):\n",
    "        temp = np.concatenate((temp, seperater(arr[i])), axis=0)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Split_X = dataSeperator(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Split_X, Y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = 'ap_model'\n",
    "callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = './model/' + checkpoint_filepath,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only = True,\n",
    "    save_weigths_only = False,\n",
    ")\n",
    "log_dir = './logs/fit/'\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = log_dir, histogram_freq = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 01:36:49.256516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-04 01:36:49.763957: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22304 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:d8:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def train_step(model, images, labels, loss_object, optimizer, train_loss, train_accuracy):\n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions = model(images, training=True)\n",
    "    loss = loss_object(labels, predictions)\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "  train_loss(loss)\n",
    "  train_accuracy(labels, predictions)\n",
    "  # print(\"Training loss (for one batch) at step %d: %.4f\" % (step, float(loss)))\n",
    "@tf.function\n",
    "def test_step(model, images, labels, loss_object, test_loss, test_accuracy):\n",
    "  predictions = model(images, training=False)\n",
    "\n",
    "  t_loss = loss_object(labels, predictions)\n",
    "  test_loss(t_loss)\n",
    "  test_accuracy(labels, predictions)\n",
    "  \n",
    "ap_model = AP_ResNet()\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name = 'train_loss')\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name = 'train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name = 'test_loss')\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name = 'test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 01:38:53.358029: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-04 01:38:53.874056: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22304 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:d8:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_test,y_test))\n",
    "val_dataset = val_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "  for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "    train_step(ap_model, x_batch_train, y_batch_train, loss_fn, optimizer, train_loss, train_accuracy)\n",
    "\n",
    "  for step ,(x_batch_test, y_batch_test) in enumerate(val_dataset):\n",
    "    test_step(ap_model, x_batch_test, y_batch_test, loss_fn, test_loss, test_accuracy)\n",
    "\n",
    "  template = \"Epoch {}, Loss: {:.4f}, Accuracy: {:.4f}, Test Loss: {:.4f}, Test Accuracy: {:.4f}\"\n",
    "  print(template.format(epoch+1,\n",
    "                        train_loss.result(),\n",
    "                        train_accuracy.result() * 100,\n",
    "                        test_loss.result(),\n",
    "                        test_accuracy.result() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X, Y, history_dict=None):\n",
    "    Epoch = 100\n",
    "    callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath = './model/' + 'Resnet',\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        save_best_only = True,\n",
    "        save_weigths_only = False,\n",
    "    )\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "    model.compile(optimizer = optimizer , loss = loss, metrics = ['accuracy', tf.keras.metrics.categorical_crossentropy()])\n",
    "    history = model.fit(X, Y, batch_size = 64, callbacks = callback, validation_split = 0.3)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Missing required positional argument",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/data_disk/home/joongho/Intelligent_Radar/gui/service_modules/training_road.ipynb 셀 18\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Baisl_gpu_server/data_disk/home/joongho/Intelligent_Radar/gui/service_modules/training_road.ipynb#ch0000024vscode-remote?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m AP_ResNet()\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Baisl_gpu_server/data_disk/home/joongho/Intelligent_Radar/gui/service_modules/training_road.ipynb#ch0000024vscode-remote?line=1'>2</a>\u001b[0m ap_history \u001b[39m=\u001b[39m train(model, Split_X, Y)\n",
      "\u001b[1;32m/data_disk/home/joongho/Intelligent_Radar/gui/service_modules/training_road.ipynb 셀 18\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, X, Y, history_dict)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baisl_gpu_server/data_disk/home/joongho/Intelligent_Radar/gui/service_modules/training_road.ipynb#ch0000024vscode-remote?line=9'>10</a>\u001b[0m optimizer \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baisl_gpu_server/data_disk/home/joongho/Intelligent_Radar/gui/service_modules/training_road.ipynb#ch0000024vscode-remote?line=10'>11</a>\u001b[0m loss \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mCategoricalCrossentropy()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Baisl_gpu_server/data_disk/home/joongho/Intelligent_Radar/gui/service_modules/training_road.ipynb#ch0000024vscode-remote?line=11'>12</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer \u001b[39m=\u001b[39m optimizer , loss \u001b[39m=\u001b[39m loss, metrics \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m, tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mmetrics\u001b[39m.\u001b[39;49mcategorical_crossentropy()])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baisl_gpu_server/data_disk/home/joongho/Intelligent_Radar/gui/service_modules/training_road.ipynb#ch0000024vscode-remote?line=12'>13</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(X, Y, batch_size \u001b[39m=\u001b[39m \u001b[39m64\u001b[39m, callbacks \u001b[39m=\u001b[39m callback, validation_split \u001b[39m=\u001b[39m \u001b[39m0.3\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baisl_gpu_server/data_disk/home/joongho/Intelligent_Radar/gui/service_modules/training_road.ipynb#ch0000024vscode-remote?line=13'>14</a>\u001b[0m \u001b[39mreturn\u001b[39;00m history\n",
      "File \u001b[0;32m~/.conda/envs/radar/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.conda/envs/radar/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1076\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1074\u001b[0m \u001b[39mif\u001b[39;00m iterable_params \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1075\u001b[0m   args, kwargs \u001b[39m=\u001b[39m replace_iterable_params(args, kwargs, iterable_params)\n\u001b[0;32m-> 1076\u001b[0m result \u001b[39m=\u001b[39m api_dispatcher\u001b[39m.\u001b[39;49mDispatch(args, kwargs)\n\u001b[1;32m   1077\u001b[0m \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[1;32m   1078\u001b[0m   \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[0;31mTypeError\u001b[0m: Missing required positional argument"
     ]
    }
   ],
   "source": [
    "model = AP_ResNet()\n",
    "ap_history = train(model, Split_X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average of 1 each\n",
      "Epoch 1, Loss: 7.4142, Accuracy: 23.9881, Test Loss: 1.6055, Test Accuracy: 25.4167\n",
      "Epoch 2, Loss: 4.5213, Accuracy: 23.8988, Test Loss: 1.6019, Test Accuracy: 25.4167\n",
      "Epoch 3, Loss: 3.5471, Accuracy: 24.7024, Test Loss: 1.5987, Test Accuracy: 24.0741\n",
      "Epoch 4, Loss: 3.0566, Accuracy: 25.1935, Test Loss: 1.5959, Test Accuracy: 23.4028\n",
      "Epoch 5, Loss: 2.7628, Accuracy: 25.5833, Test Loss: 1.5935, Test Accuracy: 23.0000\n",
      "Epoch 6, Loss: 2.5696, Accuracy: 25.9722, Test Loss: 1.5915, Test Accuracy: 22.7315\n",
      "Epoch 7, Loss: 2.4270, Accuracy: 26.1905, Test Loss: 1.5900, Test Accuracy: 22.5397\n",
      "Epoch 8, Loss: 2.3216, Accuracy: 26.2574, Test Loss: 1.5885, Test Accuracy: 22.3958\n",
      "Epoch 9, Loss: 2.2376, Accuracy: 26.3029, Test Loss: 1.5872, Test Accuracy: 22.2840\n",
      "Epoch 10, Loss: 2.1696, Accuracy: 26.3750, Test Loss: 1.5860, Test Accuracy: 22.1944\n",
      "Epoch 11, Loss: 2.1146, Accuracy: 26.4610, Test Loss: 1.5851, Test Accuracy: 22.1212\n",
      "Epoch 12, Loss: 2.0686, Accuracy: 26.4732, Test Loss: 1.5843, Test Accuracy: 22.0602\n",
      "Epoch 13, Loss: 2.0294, Accuracy: 26.5064, Test Loss: 1.5835, Test Accuracy: 22.0085\n",
      "Epoch 14, Loss: 1.9951, Accuracy: 26.5476, Test Loss: 1.5829, Test Accuracy: 21.9643\n",
      "Epoch 15, Loss: 1.9662, Accuracy: 26.5714, Test Loss: 1.5824, Test Accuracy: 21.9259\n",
      "Epoch 16, Loss: 1.9404, Accuracy: 26.5699, Test Loss: 1.5819, Test Accuracy: 21.8924\n",
      "Epoch 17, Loss: 1.9177, Accuracy: 26.5721, Test Loss: 1.5815, Test Accuracy: 21.8627\n",
      "Epoch 18, Loss: 1.8976, Accuracy: 26.5708, Test Loss: 1.5812, Test Accuracy: 21.8364\n",
      "Epoch 19, Loss: 1.8794, Accuracy: 26.5727, Test Loss: 1.5809, Test Accuracy: 21.8129\n",
      "Epoch 20, Loss: 1.8631, Accuracy: 26.5744, Test Loss: 1.5806, Test Accuracy: 21.7917\n",
      "Epoch 21, Loss: 1.8484, Accuracy: 26.5845, Test Loss: 1.5804, Test Accuracy: 21.7725\n",
      "Epoch 22, Loss: 1.8350, Accuracy: 26.5990, Test Loss: 1.5802, Test Accuracy: 21.7551\n",
      "Epoch 23, Loss: 1.8231, Accuracy: 26.6097, Test Loss: 1.5800, Test Accuracy: 21.7391\n",
      "Epoch 24, Loss: 1.8118, Accuracy: 26.6146, Test Loss: 1.5798, Test Accuracy: 21.7245\n",
      "Epoch 25, Loss: 1.8022, Accuracy: 26.6167, Test Loss: 1.5797, Test Accuracy: 21.7111\n",
      "Epoch 26, Loss: 1.7927, Accuracy: 26.6140, Test Loss: 1.5796, Test Accuracy: 21.6987\n",
      "Epoch 27, Loss: 1.7838, Accuracy: 26.6138, Test Loss: 1.5795, Test Accuracy: 21.6872\n",
      "Epoch 28, Loss: 1.7756, Accuracy: 26.6114, Test Loss: 1.5794, Test Accuracy: 21.6766\n",
      "Epoch 29, Loss: 1.7679, Accuracy: 26.6071, Test Loss: 1.5793, Test Accuracy: 21.6667\n",
      "Epoch 30, Loss: 1.7607, Accuracy: 26.6052, Test Loss: 1.5792, Test Accuracy: 21.6574\n",
      "Epoch 31, Loss: 1.7540, Accuracy: 26.6033, Test Loss: 1.5792, Test Accuracy: 21.6487\n",
      "Epoch 32, Loss: 1.7477, Accuracy: 26.6016, Test Loss: 1.5791, Test Accuracy: 21.6406\n",
      "Epoch 33, Loss: 1.7418, Accuracy: 26.5999, Test Loss: 1.5790, Test Accuracy: 21.6330\n",
      "Epoch 34, Loss: 1.7363, Accuracy: 26.5984, Test Loss: 1.5790, Test Accuracy: 21.6258\n",
      "Epoch 35, Loss: 1.7310, Accuracy: 26.5969, Test Loss: 1.5789, Test Accuracy: 21.6190\n",
      "Epoch 36, Loss: 1.7260, Accuracy: 26.5956, Test Loss: 1.5789, Test Accuracy: 21.6127\n",
      "Epoch 37, Loss: 1.7213, Accuracy: 26.5959, Test Loss: 1.5789, Test Accuracy: 21.6066\n",
      "Epoch 38, Loss: 1.7171, Accuracy: 26.5977, Test Loss: 1.5789, Test Accuracy: 21.6009\n",
      "Epoch 39, Loss: 1.7128, Accuracy: 26.5965, Test Loss: 1.5788, Test Accuracy: 21.5954\n",
      "Epoch 40, Loss: 1.7089, Accuracy: 26.5952, Test Loss: 1.5788, Test Accuracy: 21.5903\n",
      "Epoch 41, Loss: 1.7050, Accuracy: 26.5941, Test Loss: 1.5788, Test Accuracy: 21.5854\n",
      "Epoch 42, Loss: 1.7013, Accuracy: 26.5972, Test Loss: 1.5787, Test Accuracy: 21.5807\n",
      "Epoch 43, Loss: 1.6978, Accuracy: 26.5961, Test Loss: 1.5787, Test Accuracy: 21.5762\n",
      "Epoch 44, Loss: 1.6945, Accuracy: 26.5950, Test Loss: 1.5787, Test Accuracy: 21.5720\n",
      "Epoch 45, Loss: 1.6913, Accuracy: 26.5952, Test Loss: 1.5787, Test Accuracy: 21.5679\n",
      "Epoch 46, Loss: 1.6883, Accuracy: 26.5942, Test Loss: 1.5787, Test Accuracy: 21.5640\n",
      "Epoch 47, Loss: 1.6854, Accuracy: 26.5932, Test Loss: 1.5787, Test Accuracy: 21.5603\n",
      "Epoch 48, Loss: 1.6826, Accuracy: 26.5923, Test Loss: 1.5786, Test Accuracy: 21.5567\n",
      "Epoch 49, Loss: 1.6800, Accuracy: 26.5914, Test Loss: 1.5786, Test Accuracy: 21.5533\n",
      "Epoch 50, Loss: 1.6774, Accuracy: 26.5905, Test Loss: 1.5786, Test Accuracy: 21.5500\n",
      "Epoch 51, Loss: 1.6750, Accuracy: 26.5908, Test Loss: 1.5786, Test Accuracy: 21.5468\n",
      "Epoch 52, Loss: 1.6726, Accuracy: 26.5911, Test Loss: 1.5786, Test Accuracy: 21.5438\n",
      "Epoch 53, Loss: 1.6704, Accuracy: 26.5903, Test Loss: 1.5786, Test Accuracy: 21.5409\n",
      "Epoch 54, Loss: 1.6682, Accuracy: 26.5895, Test Loss: 1.5786, Test Accuracy: 21.5381\n",
      "Epoch 55, Loss: 1.6661, Accuracy: 26.5887, Test Loss: 1.5786, Test Accuracy: 21.5354\n",
      "Epoch 56, Loss: 1.6640, Accuracy: 26.5880, Test Loss: 1.5785, Test Accuracy: 21.5327\n",
      "Epoch 57, Loss: 1.6621, Accuracy: 26.5873, Test Loss: 1.5785, Test Accuracy: 21.5302\n",
      "Epoch 58, Loss: 1.6602, Accuracy: 26.5866, Test Loss: 1.5785, Test Accuracy: 21.5278\n",
      "Epoch 59, Loss: 1.6584, Accuracy: 26.5860, Test Loss: 1.5785, Test Accuracy: 21.5254\n",
      "Epoch 60, Loss: 1.6566, Accuracy: 26.5853, Test Loss: 1.5785, Test Accuracy: 21.5231\n",
      "Epoch 61, Loss: 1.6549, Accuracy: 26.5847, Test Loss: 1.5785, Test Accuracy: 21.5209\n",
      "Epoch 62, Loss: 1.6533, Accuracy: 26.5841, Test Loss: 1.5785, Test Accuracy: 21.5188\n",
      "Epoch 63, Loss: 1.6517, Accuracy: 26.5835, Test Loss: 1.5785, Test Accuracy: 21.5168\n",
      "Epoch 64, Loss: 1.6501, Accuracy: 26.5830, Test Loss: 1.5785, Test Accuracy: 21.5148\n",
      "Epoch 65, Loss: 1.6486, Accuracy: 26.5824, Test Loss: 1.5784, Test Accuracy: 21.5128\n",
      "Epoch 66, Loss: 1.6472, Accuracy: 26.5819, Test Loss: 1.5784, Test Accuracy: 21.5109\n",
      "Epoch 67, Loss: 1.6457, Accuracy: 26.5814, Test Loss: 1.5784, Test Accuracy: 21.5091\n",
      "Epoch 68, Loss: 1.6444, Accuracy: 26.5809, Test Loss: 1.5784, Test Accuracy: 21.5074\n",
      "Epoch 69, Loss: 1.6431, Accuracy: 26.5804, Test Loss: 1.5784, Test Accuracy: 21.5056\n",
      "Epoch 70, Loss: 1.6418, Accuracy: 26.5799, Test Loss: 1.5784, Test Accuracy: 21.5040\n",
      "Epoch 71, Loss: 1.6405, Accuracy: 26.5795, Test Loss: 1.5784, Test Accuracy: 21.5023\n",
      "Epoch 72, Loss: 1.6393, Accuracy: 26.5790, Test Loss: 1.5784, Test Accuracy: 21.5008\n",
      "Epoch 73, Loss: 1.6381, Accuracy: 26.5786, Test Loss: 1.5784, Test Accuracy: 21.4992\n",
      "Epoch 74, Loss: 1.6369, Accuracy: 26.5782, Test Loss: 1.5784, Test Accuracy: 21.4977\n",
      "Epoch 75, Loss: 1.6358, Accuracy: 26.5778, Test Loss: 1.5783, Test Accuracy: 21.4963\n",
      "Epoch 76, Loss: 1.6347, Accuracy: 26.5774, Test Loss: 1.5783, Test Accuracy: 21.4949\n",
      "Epoch 77, Loss: 1.6336, Accuracy: 26.5770, Test Loss: 1.5783, Test Accuracy: 21.4935\n",
      "Epoch 78, Loss: 1.6326, Accuracy: 26.5766, Test Loss: 1.5783, Test Accuracy: 21.4922\n",
      "Epoch 79, Loss: 1.6316, Accuracy: 26.5763, Test Loss: 1.5783, Test Accuracy: 21.4909\n",
      "Epoch 80, Loss: 1.6306, Accuracy: 26.5759, Test Loss: 1.5783, Test Accuracy: 21.4896\n",
      "Epoch 81, Loss: 1.6296, Accuracy: 26.5755, Test Loss: 1.5783, Test Accuracy: 21.4883\n",
      "Epoch 82, Loss: 1.6287, Accuracy: 26.5752, Test Loss: 1.5783, Test Accuracy: 21.4871\n",
      "Epoch 83, Loss: 1.6278, Accuracy: 26.5749, Test Loss: 1.5783, Test Accuracy: 21.4859\n",
      "Epoch 84, Loss: 1.6269, Accuracy: 26.5745, Test Loss: 1.5783, Test Accuracy: 21.4848\n",
      "Epoch 85, Loss: 1.6260, Accuracy: 26.5742, Test Loss: 1.5783, Test Accuracy: 21.4837\n",
      "Epoch 86, Loss: 1.6252, Accuracy: 26.5739, Test Loss: 1.5783, Test Accuracy: 21.4826\n",
      "Epoch 87, Loss: 1.6243, Accuracy: 26.5736, Test Loss: 1.5783, Test Accuracy: 21.4815\n",
      "Epoch 88, Loss: 1.6235, Accuracy: 26.5733, Test Loss: 1.5783, Test Accuracy: 21.4804\n",
      "Epoch 89, Loss: 1.6227, Accuracy: 26.5730, Test Loss: 1.5783, Test Accuracy: 21.4794\n",
      "Epoch 90, Loss: 1.6219, Accuracy: 26.5728, Test Loss: 1.5783, Test Accuracy: 21.4784\n",
      "Epoch 91, Loss: 1.6212, Accuracy: 26.5725, Test Loss: 1.5783, Test Accuracy: 21.4774\n",
      "Epoch 92, Loss: 1.6204, Accuracy: 26.5722, Test Loss: 1.5783, Test Accuracy: 21.4764\n",
      "Epoch 93, Loss: 1.6197, Accuracy: 26.5719, Test Loss: 1.5783, Test Accuracy: 21.4755\n",
      "Epoch 94, Loss: 1.6189, Accuracy: 26.5717, Test Loss: 1.5782, Test Accuracy: 21.4746\n",
      "Epoch 95, Loss: 1.6183, Accuracy: 26.5714, Test Loss: 1.5782, Test Accuracy: 21.4737\n",
      "Epoch 96, Loss: 1.6176, Accuracy: 26.5712, Test Loss: 1.5782, Test Accuracy: 21.4728\n",
      "Epoch 97, Loss: 1.6169, Accuracy: 26.5709, Test Loss: 1.5782, Test Accuracy: 21.4719\n",
      "Epoch 98, Loss: 1.6162, Accuracy: 26.5707, Test Loss: 1.5782, Test Accuracy: 21.4711\n",
      "Epoch 99, Loss: 1.6156, Accuracy: 26.5705, Test Loss: 1.5782, Test Accuracy: 21.4703\n",
      "Epoch 100, Loss: 1.6149, Accuracy: 26.5702, Test Loss: 1.5782, Test Accuracy: 21.4694\n",
      "Epoch 101, Loss: 1.6143, Accuracy: 26.5700, Test Loss: 1.5782, Test Accuracy: 21.4686\n",
      "Epoch 102, Loss: 1.6137, Accuracy: 26.5698, Test Loss: 1.5782, Test Accuracy: 21.4679\n",
      "Epoch 103, Loss: 1.6131, Accuracy: 26.5696, Test Loss: 1.5782, Test Accuracy: 21.4671\n",
      "Epoch 104, Loss: 1.6125, Accuracy: 26.5694, Test Loss: 1.5782, Test Accuracy: 21.4663\n",
      "Epoch 105, Loss: 1.6119, Accuracy: 26.5692, Test Loss: 1.5782, Test Accuracy: 21.4656\n",
      "Epoch 106, Loss: 1.6114, Accuracy: 26.5690, Test Loss: 1.5782, Test Accuracy: 21.4649\n",
      "Epoch 107, Loss: 1.6108, Accuracy: 26.5688, Test Loss: 1.5782, Test Accuracy: 21.4642\n",
      "Epoch 108, Loss: 1.6103, Accuracy: 26.5686, Test Loss: 1.5782, Test Accuracy: 21.4635\n",
      "Epoch 109, Loss: 1.6098, Accuracy: 26.5684, Test Loss: 1.5782, Test Accuracy: 21.4628\n",
      "Epoch 110, Loss: 1.6093, Accuracy: 26.5682, Test Loss: 1.5782, Test Accuracy: 21.4621\n",
      "Epoch 111, Loss: 1.6087, Accuracy: 26.5680, Test Loss: 1.5782, Test Accuracy: 21.4615\n",
      "Epoch 112, Loss: 1.6082, Accuracy: 26.5683, Test Loss: 1.5782, Test Accuracy: 21.4608\n",
      "Epoch 113, Loss: 1.6077, Accuracy: 26.5682, Test Loss: 1.5782, Test Accuracy: 21.4602\n",
      "Epoch 114, Loss: 1.6072, Accuracy: 26.5685, Test Loss: 1.5782, Test Accuracy: 21.4596\n",
      "Epoch 115, Loss: 1.6067, Accuracy: 26.5683, Test Loss: 1.5782, Test Accuracy: 21.4589\n",
      "Epoch 116, Loss: 1.6063, Accuracy: 26.5681, Test Loss: 1.5782, Test Accuracy: 21.4583\n",
      "Epoch 117, Loss: 1.6058, Accuracy: 26.5680, Test Loss: 1.5782, Test Accuracy: 21.4577\n",
      "Epoch 118, Loss: 1.6054, Accuracy: 26.5678, Test Loss: 1.5782, Test Accuracy: 21.4572\n",
      "Epoch 119, Loss: 1.6049, Accuracy: 26.5676, Test Loss: 1.5782, Test Accuracy: 21.4566\n",
      "Epoch 120, Loss: 1.6045, Accuracy: 26.5675, Test Loss: 1.5782, Test Accuracy: 21.4560\n",
      "Epoch 121, Loss: 1.6041, Accuracy: 26.5668, Test Loss: 1.5782, Test Accuracy: 21.4555\n",
      "Epoch 122, Loss: 1.6037, Accuracy: 26.5666, Test Loss: 1.5782, Test Accuracy: 21.4549\n",
      "Epoch 123, Loss: 1.6032, Accuracy: 26.5665, Test Loss: 1.5782, Test Accuracy: 21.4544\n",
      "Epoch 124, Loss: 1.6028, Accuracy: 26.5663, Test Loss: 1.5782, Test Accuracy: 21.4539\n",
      "Epoch 125, Loss: 1.6024, Accuracy: 26.5662, Test Loss: 1.5782, Test Accuracy: 21.4533\n",
      "Epoch 126, Loss: 1.6020, Accuracy: 26.5660, Test Loss: 1.5782, Test Accuracy: 21.4528\n",
      "Epoch 127, Loss: 1.6016, Accuracy: 26.5659, Test Loss: 1.5782, Test Accuracy: 21.4523\n",
      "Epoch 128, Loss: 1.6013, Accuracy: 26.5658, Test Loss: 1.5782, Test Accuracy: 21.4518\n",
      "Epoch 129, Loss: 1.6012, Accuracy: 26.5670, Test Loss: 1.5781, Test Accuracy: 21.4513\n",
      "Epoch 130, Loss: 1.6009, Accuracy: 26.5664, Test Loss: 1.5781, Test Accuracy: 21.4509\n",
      "Epoch 131, Loss: 1.6005, Accuracy: 26.5667, Test Loss: 1.5781, Test Accuracy: 21.4504\n",
      "Epoch 132, Loss: 1.6002, Accuracy: 26.5666, Test Loss: 1.5781, Test Accuracy: 21.4499\n",
      "Epoch 133, Loss: 1.5998, Accuracy: 26.5664, Test Loss: 1.5781, Test Accuracy: 21.4495\n",
      "Epoch 134, Loss: 1.5995, Accuracy: 26.5672, Test Loss: 1.5781, Test Accuracy: 21.4490\n",
      "Epoch 135, Loss: 1.5994, Accuracy: 26.5670, Test Loss: 1.5781, Test Accuracy: 21.4486\n",
      "Epoch 136, Loss: 1.5991, Accuracy: 26.5669, Test Loss: 1.5781, Test Accuracy: 21.4481\n",
      "Epoch 137, Loss: 1.5987, Accuracy: 26.5676, Test Loss: 1.5781, Test Accuracy: 21.4477\n",
      "Epoch 138, Loss: 1.5985, Accuracy: 26.5700, Test Loss: 1.5781, Test Accuracy: 21.4473\n",
      "Epoch 139, Loss: 1.5981, Accuracy: 26.5699, Test Loss: 1.5781, Test Accuracy: 21.4468\n",
      "Epoch 140, Loss: 1.5978, Accuracy: 26.5697, Test Loss: 1.5781, Test Accuracy: 21.4464\n",
      "Epoch 141, Loss: 1.5975, Accuracy: 26.5696, Test Loss: 1.5781, Test Accuracy: 21.4460\n",
      "Epoch 142, Loss: 1.5972, Accuracy: 26.5694, Test Loss: 1.5781, Test Accuracy: 21.4456\n",
      "Epoch 143, Loss: 1.5968, Accuracy: 26.5693, Test Loss: 1.5781, Test Accuracy: 21.4452\n",
      "Epoch 144, Loss: 1.5967, Accuracy: 26.5691, Test Loss: 1.5781, Test Accuracy: 21.4448\n",
      "Epoch 145, Loss: 1.5964, Accuracy: 26.5690, Test Loss: 1.5781, Test Accuracy: 21.4444\n",
      "Epoch 146, Loss: 1.5961, Accuracy: 26.5688, Test Loss: 1.5781, Test Accuracy: 21.4441\n",
      "Epoch 147, Loss: 1.5958, Accuracy: 26.5687, Test Loss: 1.5781, Test Accuracy: 21.4437\n",
      "Epoch 148, Loss: 1.5955, Accuracy: 26.5685, Test Loss: 1.5781, Test Accuracy: 21.4433\n",
      "Epoch 149, Loss: 1.5952, Accuracy: 26.5684, Test Loss: 1.5781, Test Accuracy: 21.4430\n",
      "Epoch 150, Loss: 1.5949, Accuracy: 26.5683, Test Loss: 1.5781, Test Accuracy: 21.4426\n",
      "Epoch 151, Loss: 1.5946, Accuracy: 26.5681, Test Loss: 1.5781, Test Accuracy: 21.4422\n",
      "Epoch 152, Loss: 1.5943, Accuracy: 26.5680, Test Loss: 1.5781, Test Accuracy: 21.4419\n",
      "Epoch 153, Loss: 1.5941, Accuracy: 26.5679, Test Loss: 1.5781, Test Accuracy: 21.4415\n",
      "Epoch 154, Loss: 1.5938, Accuracy: 26.5677, Test Loss: 1.5781, Test Accuracy: 21.4412\n",
      "Epoch 155, Loss: 1.5936, Accuracy: 26.5680, Test Loss: 1.5781, Test Accuracy: 21.4409\n",
      "Epoch 156, Loss: 1.5933, Accuracy: 26.5678, Test Loss: 1.5781, Test Accuracy: 21.4405\n",
      "Epoch 157, Loss: 1.5931, Accuracy: 26.5677, Test Loss: 1.5781, Test Accuracy: 21.4402\n",
      "Epoch 158, Loss: 1.5928, Accuracy: 26.5676, Test Loss: 1.5781, Test Accuracy: 21.4399\n",
      "Epoch 159, Loss: 1.5925, Accuracy: 26.5675, Test Loss: 1.5781, Test Accuracy: 21.4396\n",
      "Epoch 160, Loss: 1.5923, Accuracy: 26.5673, Test Loss: 1.5781, Test Accuracy: 21.4392\n",
      "Epoch 161, Loss: 1.5920, Accuracy: 26.5672, Test Loss: 1.5781, Test Accuracy: 21.4389\n",
      "Epoch 162, Loss: 1.5918, Accuracy: 26.5671, Test Loss: 1.5781, Test Accuracy: 21.4386\n",
      "Epoch 163, Loss: 1.5916, Accuracy: 26.5670, Test Loss: 1.5781, Test Accuracy: 21.4383\n",
      "Epoch 164, Loss: 1.5913, Accuracy: 26.5669, Test Loss: 1.5781, Test Accuracy: 21.4380\n",
      "Epoch 165, Loss: 1.5911, Accuracy: 26.5667, Test Loss: 1.5781, Test Accuracy: 21.4377\n",
      "Epoch 166, Loss: 1.5909, Accuracy: 26.5666, Test Loss: 1.5781, Test Accuracy: 21.4374\n",
      "Epoch 167, Loss: 1.5906, Accuracy: 26.5665, Test Loss: 1.5781, Test Accuracy: 21.4371\n",
      "Epoch 168, Loss: 1.5904, Accuracy: 26.5664, Test Loss: 1.5781, Test Accuracy: 21.4368\n",
      "Epoch 169, Loss: 1.5902, Accuracy: 26.5663, Test Loss: 1.5781, Test Accuracy: 21.4366\n",
      "Epoch 170, Loss: 1.5899, Accuracy: 26.5662, Test Loss: 1.5781, Test Accuracy: 21.4363\n",
      "Epoch 171, Loss: 1.5897, Accuracy: 26.5661, Test Loss: 1.5781, Test Accuracy: 21.4360\n",
      "Epoch 172, Loss: 1.5895, Accuracy: 26.5660, Test Loss: 1.5781, Test Accuracy: 21.4357\n",
      "Epoch 173, Loss: 1.5893, Accuracy: 26.5659, Test Loss: 1.5781, Test Accuracy: 21.4355\n",
      "Epoch 174, Loss: 1.5891, Accuracy: 26.5657, Test Loss: 1.5781, Test Accuracy: 21.4352\n",
      "Epoch 175, Loss: 1.5889, Accuracy: 26.5656, Test Loss: 1.5781, Test Accuracy: 21.4349\n",
      "Epoch 176, Loss: 1.5887, Accuracy: 26.5655, Test Loss: 1.5781, Test Accuracy: 21.4347\n",
      "Epoch 177, Loss: 1.5884, Accuracy: 26.5654, Test Loss: 1.5781, Test Accuracy: 21.4344\n",
      "Epoch 178, Loss: 1.5882, Accuracy: 26.5653, Test Loss: 1.5781, Test Accuracy: 21.4341\n",
      "Epoch 179, Loss: 1.5880, Accuracy: 26.5652, Test Loss: 1.5781, Test Accuracy: 21.4339\n",
      "Epoch 180, Loss: 1.5878, Accuracy: 26.5651, Test Loss: 1.5781, Test Accuracy: 21.4336\n",
      "Epoch 181, Loss: 1.5876, Accuracy: 26.5650, Test Loss: 1.5781, Test Accuracy: 21.4334\n",
      "Epoch 182, Loss: 1.5874, Accuracy: 26.5650, Test Loss: 1.5781, Test Accuracy: 21.4332\n",
      "Epoch 183, Loss: 1.5872, Accuracy: 26.5649, Test Loss: 1.5781, Test Accuracy: 21.4329\n",
      "Epoch 184, Loss: 1.5871, Accuracy: 26.5648, Test Loss: 1.5781, Test Accuracy: 21.4327\n",
      "Epoch 185, Loss: 1.5869, Accuracy: 26.5647, Test Loss: 1.5781, Test Accuracy: 21.4324\n",
      "Epoch 186, Loss: 1.5867, Accuracy: 26.5646, Test Loss: 1.5781, Test Accuracy: 21.4322\n",
      "Epoch 187, Loss: 1.5865, Accuracy: 26.5645, Test Loss: 1.5781, Test Accuracy: 21.4320\n",
      "Epoch 188, Loss: 1.5863, Accuracy: 26.5644, Test Loss: 1.5781, Test Accuracy: 21.4317\n",
      "Epoch 189, Loss: 1.5861, Accuracy: 26.5643, Test Loss: 1.5781, Test Accuracy: 21.4315\n",
      "Epoch 190, Loss: 1.5860, Accuracy: 26.5642, Test Loss: 1.5781, Test Accuracy: 21.4313\n",
      "Epoch 191, Loss: 1.5858, Accuracy: 26.5641, Test Loss: 1.5781, Test Accuracy: 21.4311\n",
      "Epoch 192, Loss: 1.5856, Accuracy: 26.5640, Test Loss: 1.5781, Test Accuracy: 21.4308\n",
      "Epoch 193, Loss: 1.5854, Accuracy: 26.5640, Test Loss: 1.5781, Test Accuracy: 21.4306\n",
      "Epoch 194, Loss: 1.5853, Accuracy: 26.5639, Test Loss: 1.5781, Test Accuracy: 21.4304\n",
      "Epoch 195, Loss: 1.5851, Accuracy: 26.5638, Test Loss: 1.5781, Test Accuracy: 21.4302\n",
      "Epoch 196, Loss: 1.5849, Accuracy: 26.5637, Test Loss: 1.5781, Test Accuracy: 21.4300\n",
      "Epoch 197, Loss: 1.5848, Accuracy: 26.5636, Test Loss: 1.5781, Test Accuracy: 21.4298\n",
      "Epoch 198, Loss: 1.5846, Accuracy: 26.5636, Test Loss: 1.5781, Test Accuracy: 21.4296\n",
      "Epoch 199, Loss: 1.5844, Accuracy: 26.5635, Test Loss: 1.5781, Test Accuracy: 21.4294\n",
      "Epoch 200, Loss: 1.5843, Accuracy: 26.5634, Test Loss: 1.5781, Test Accuracy: 21.4292\n",
      "average of 2 each\n",
      "Epoch 1, Loss: 12.1602, Accuracy: 22.6190, Test Loss: 1.6709, Test Accuracy: 26.6667\n",
      "Epoch 2, Loss: 7.1531, Accuracy: 24.4048, Test Loss: 1.6386, Test Accuracy: 26.3889\n",
      "Epoch 3, Loss: 5.3303, Accuracy: 24.8413, Test Loss: 1.6266, Test Accuracy: 26.2963\n",
      "Epoch 4, Loss: 4.3996, Accuracy: 24.8810, Test Loss: 1.6194, Test Accuracy: 26.2500\n",
      "Epoch 5, Loss: 3.8392, Accuracy: 24.5238, Test Loss: 1.6142, Test Accuracy: 25.6111\n",
      "Epoch 6, Loss: 3.4649, Accuracy: 24.1270, Test Loss: 1.6102, Test Accuracy: 25.6944\n",
      "Epoch 7, Loss: 3.1972, Accuracy: 24.2857, Test Loss: 1.6068, Test Accuracy: 25.3175\n",
      "Epoch 8, Loss: 2.9978, Accuracy: 24.4643, Test Loss: 1.6039, Test Accuracy: 25.0347\n",
      "Epoch 9, Loss: 2.8451, Accuracy: 24.5767, Test Loss: 1.6013, Test Accuracy: 24.8148\n",
      "Epoch 10, Loss: 2.7197, Accuracy: 24.6905, Test Loss: 1.5989, Test Accuracy: 24.6389\n",
      "Epoch 11, Loss: 2.6158, Accuracy: 24.7836, Test Loss: 1.5969, Test Accuracy: 24.4949\n",
      "Epoch 12, Loss: 2.5301, Accuracy: 24.8611, Test Loss: 1.5987, Test Accuracy: 24.4444\n",
      "Epoch 13, Loss: 2.4570, Accuracy: 24.9084, Test Loss: 1.6025, Test Accuracy: 24.5726\n",
      "Epoch 14, Loss: 2.3943, Accuracy: 24.9660, Test Loss: 1.6044, Test Accuracy: 24.6429\n",
      "Epoch 15, Loss: 2.3396, Accuracy: 25.0238, Test Loss: 1.6041, Test Accuracy: 24.6852\n",
      "Epoch 16, Loss: 2.2917, Accuracy: 25.0744, Test Loss: 1.6031, Test Accuracy: 24.6701\n",
      "Epoch 17, Loss: 2.2497, Accuracy: 25.1120, Test Loss: 1.6012, Test Accuracy: 24.5588\n",
      "Epoch 18, Loss: 2.2124, Accuracy: 25.1455, Test Loss: 1.5998, Test Accuracy: 24.4907\n",
      "Epoch 19, Loss: 2.1789, Accuracy: 25.1754, Test Loss: 1.5987, Test Accuracy: 24.4591\n",
      "Epoch 20, Loss: 2.1483, Accuracy: 25.2083, Test Loss: 1.5977, Test Accuracy: 24.4306\n",
      "Epoch 21, Loss: 2.1207, Accuracy: 25.2381, Test Loss: 1.5970, Test Accuracy: 24.4048\n",
      "Epoch 22, Loss: 2.0956, Accuracy: 25.2597, Test Loss: 1.5959, Test Accuracy: 24.3561\n",
      "Epoch 23, Loss: 2.0727, Accuracy: 25.2899, Test Loss: 1.5944, Test Accuracy: 24.2874\n",
      "Epoch 24, Loss: 2.0520, Accuracy: 25.3125, Test Loss: 1.5929, Test Accuracy: 24.2361\n",
      "Epoch 25, Loss: 2.0325, Accuracy: 25.3333, Test Loss: 1.5915, Test Accuracy: 24.1889\n",
      "Epoch 26, Loss: 2.0141, Accuracy: 25.3526, Test Loss: 1.5903, Test Accuracy: 24.1453\n",
      "Epoch 27, Loss: 1.9980, Accuracy: 25.3704, Test Loss: 1.5890, Test Accuracy: 24.0947\n",
      "Epoch 28, Loss: 1.9825, Accuracy: 25.3869, Test Loss: 1.5878, Test Accuracy: 24.0575\n",
      "Epoch 29, Loss: 1.9680, Accuracy: 25.4023, Test Loss: 1.5867, Test Accuracy: 24.0230\n",
      "Epoch 30, Loss: 1.9546, Accuracy: 25.4206, Test Loss: 1.5857, Test Accuracy: 23.9907\n",
      "Epoch 31, Loss: 1.9429, Accuracy: 25.4339, Test Loss: 1.5847, Test Accuracy: 23.9516\n",
      "Epoch 32, Loss: 1.9310, Accuracy: 25.4501, Test Loss: 1.5837, Test Accuracy: 23.9149\n",
      "Epoch 33, Loss: 1.9197, Accuracy: 25.4618, Test Loss: 1.5828, Test Accuracy: 23.8889\n",
      "Epoch 34, Loss: 1.9091, Accuracy: 25.4727, Test Loss: 1.5820, Test Accuracy: 23.8644\n",
      "Epoch 35, Loss: 1.8988, Accuracy: 25.4830, Test Loss: 1.5812, Test Accuracy: 23.8492\n",
      "Epoch 36, Loss: 1.8895, Accuracy: 25.4894, Test Loss: 1.5804, Test Accuracy: 23.8349\n",
      "Epoch 37, Loss: 1.8808, Accuracy: 25.4987, Test Loss: 1.5796, Test Accuracy: 23.8138\n",
      "Epoch 38, Loss: 1.8719, Accuracy: 25.5075, Test Loss: 1.5806, Test Accuracy: 23.7939\n",
      "Epoch 39, Loss: 1.8636, Accuracy: 25.5128, Test Loss: 1.5818, Test Accuracy: 23.7749\n",
      "Epoch 40, Loss: 1.8574, Accuracy: 25.5179, Test Loss: 1.5897, Test Accuracy: 23.7917\n",
      "Epoch 41, Loss: 1.8502, Accuracy: 25.5256, Test Loss: 1.5930, Test Accuracy: 23.7602\n",
      "Epoch 42, Loss: 1.8434, Accuracy: 25.5215, Test Loss: 1.5920, Test Accuracy: 23.7434\n",
      "Epoch 43, Loss: 1.8366, Accuracy: 25.5288, Test Loss: 1.5911, Test Accuracy: 23.7274\n",
      "Epoch 44, Loss: 1.8304, Accuracy: 25.5330, Test Loss: 1.5902, Test Accuracy: 23.7121\n",
      "Epoch 45, Loss: 1.8245, Accuracy: 25.5397, Test Loss: 1.5893, Test Accuracy: 23.6975\n",
      "Epoch 46, Loss: 1.8187, Accuracy: 25.5435, Test Loss: 1.5885, Test Accuracy: 23.6836\n",
      "Epoch 47, Loss: 1.8131, Accuracy: 25.5496, Test Loss: 1.5878, Test Accuracy: 23.6761\n",
      "Epoch 48, Loss: 1.8084, Accuracy: 25.5506, Test Loss: 1.5871, Test Accuracy: 23.6516\n",
      "Epoch 49, Loss: 1.8035, Accuracy: 25.5539, Test Loss: 1.5864, Test Accuracy: 23.6451\n",
      "Epoch 50, Loss: 1.7986, Accuracy: 25.5548, Test Loss: 1.5857, Test Accuracy: 23.6333\n",
      "Epoch 51, Loss: 1.7940, Accuracy: 25.5602, Test Loss: 1.5850, Test Accuracy: 23.6220\n",
      "Epoch 52, Loss: 1.7896, Accuracy: 25.5655, Test Loss: 1.5843, Test Accuracy: 23.6111\n",
      "Epoch 53, Loss: 1.7860, Accuracy: 25.5638, Test Loss: 1.5837, Test Accuracy: 23.6006\n",
      "Epoch 54, Loss: 1.7818, Accuracy: 25.5688, Test Loss: 1.5831, Test Accuracy: 23.5905\n",
      "Epoch 55, Loss: 1.7779, Accuracy: 25.5736, Test Loss: 1.5825, Test Accuracy: 23.5808\n",
      "Epoch 56, Loss: 1.7740, Accuracy: 25.5782, Test Loss: 1.5820, Test Accuracy: 23.5714\n",
      "Epoch 57, Loss: 1.7704, Accuracy: 25.5806, Test Loss: 1.5814, Test Accuracy: 23.5624\n",
      "Epoch 58, Loss: 1.7667, Accuracy: 25.5850, Test Loss: 1.5809, Test Accuracy: 23.5536\n",
      "Epoch 59, Loss: 1.7631, Accuracy: 25.5892, Test Loss: 1.5804, Test Accuracy: 23.5452\n",
      "Epoch 60, Loss: 1.7599, Accuracy: 25.5913, Test Loss: 1.5799, Test Accuracy: 23.5324\n",
      "Epoch 61, Loss: 1.7566, Accuracy: 25.5933, Test Loss: 1.5794, Test Accuracy: 23.5200\n",
      "Epoch 62, Loss: 1.7536, Accuracy: 25.5972, Test Loss: 1.5790, Test Accuracy: 23.5081\n",
      "Epoch 63, Loss: 1.7505, Accuracy: 25.6009, Test Loss: 1.5791, Test Accuracy: 23.4832\n",
      "Epoch 64, Loss: 1.7478, Accuracy: 25.6027, Test Loss: 1.5803, Test Accuracy: 23.4766\n",
      "Epoch 65, Loss: 1.7449, Accuracy: 25.6062, Test Loss: 1.5799, Test Accuracy: 23.4615\n",
      "Epoch 66, Loss: 1.7422, Accuracy: 25.6097, Test Loss: 1.5799, Test Accuracy: 23.4343\n",
      "Epoch 67, Loss: 1.7394, Accuracy: 25.6130, Test Loss: 1.5800, Test Accuracy: 23.4163\n",
      "Epoch 68, Loss: 1.7369, Accuracy: 25.6162, Test Loss: 1.5808, Test Accuracy: 23.4109\n",
      "Epoch 69, Loss: 1.7348, Accuracy: 25.6211, Test Loss: 1.5814, Test Accuracy: 23.3937\n",
      "Epoch 70, Loss: 1.7322, Accuracy: 25.6241, Test Loss: 1.5814, Test Accuracy: 23.3730\n",
      "Epoch 71, Loss: 1.7298, Accuracy: 25.6271, Test Loss: 1.5811, Test Accuracy: 23.3529\n",
      "Epoch 72, Loss: 1.7274, Accuracy: 25.6300, Test Loss: 1.5807, Test Accuracy: 23.3333\n",
      "Epoch 73, Loss: 1.7251, Accuracy: 25.6327, Test Loss: 1.5803, Test Accuracy: 23.3181\n",
      "Epoch 74, Loss: 1.7228, Accuracy: 25.6371, Test Loss: 1.5799, Test Accuracy: 23.3033\n",
      "Epoch 75, Loss: 1.7206, Accuracy: 25.6397, Test Loss: 1.5796, Test Accuracy: 23.2889\n",
      "Epoch 76, Loss: 1.7184, Accuracy: 25.6422, Test Loss: 1.5792, Test Accuracy: 23.2895\n",
      "Epoch 77, Loss: 1.7165, Accuracy: 25.6447, Test Loss: 1.5788, Test Accuracy: 23.2720\n",
      "Epoch 78, Loss: 1.7144, Accuracy: 25.6471, Test Loss: 1.5785, Test Accuracy: 23.2657\n",
      "Epoch 79, Loss: 1.7125, Accuracy: 25.6495, Test Loss: 1.5781, Test Accuracy: 23.2560\n",
      "Epoch 80, Loss: 1.7106, Accuracy: 25.6518, Test Loss: 1.5778, Test Accuracy: 23.2535\n",
      "Epoch 81, Loss: 1.7089, Accuracy: 25.6540, Test Loss: 1.5774, Test Accuracy: 23.2510\n",
      "Epoch 82, Loss: 1.7071, Accuracy: 25.6548, Test Loss: 1.5771, Test Accuracy: 23.2486\n",
      "Epoch 83, Loss: 1.7054, Accuracy: 25.6555, Test Loss: 1.5768, Test Accuracy: 23.2463\n",
      "Epoch 84, Loss: 1.7037, Accuracy: 25.6576, Test Loss: 1.5765, Test Accuracy: 23.2440\n",
      "Epoch 85, Loss: 1.7020, Accuracy: 25.6597, Test Loss: 1.5762, Test Accuracy: 23.2418\n",
      "Epoch 86, Loss: 1.7004, Accuracy: 25.6617, Test Loss: 1.5759, Test Accuracy: 23.2397\n",
      "Epoch 87, Loss: 1.6988, Accuracy: 25.6637, Test Loss: 1.5756, Test Accuracy: 23.2375\n",
      "Epoch 88, Loss: 1.6973, Accuracy: 25.6656, Test Loss: 1.5753, Test Accuracy: 23.2355\n",
      "Epoch 89, Loss: 1.6958, Accuracy: 25.6675, Test Loss: 1.5750, Test Accuracy: 23.2335\n",
      "Epoch 90, Loss: 1.6944, Accuracy: 25.6680, Test Loss: 1.5747, Test Accuracy: 23.2315\n",
      "Epoch 91, Loss: 1.6929, Accuracy: 25.6698, Test Loss: 1.5745, Test Accuracy: 23.2295\n",
      "Epoch 92, Loss: 1.6915, Accuracy: 25.6716, Test Loss: 1.5742, Test Accuracy: 23.2277\n",
      "Epoch 93, Loss: 1.6901, Accuracy: 25.6733, Test Loss: 1.5740, Test Accuracy: 23.2258\n",
      "Epoch 94, Loss: 1.6887, Accuracy: 25.6750, Test Loss: 1.5737, Test Accuracy: 23.2240\n",
      "Epoch 95, Loss: 1.6874, Accuracy: 25.6767, Test Loss: 1.5735, Test Accuracy: 23.2222\n",
      "Epoch 96, Loss: 1.6861, Accuracy: 25.6783, Test Loss: 1.5733, Test Accuracy: 23.2205\n",
      "Epoch 97, Loss: 1.6848, Accuracy: 25.6799, Test Loss: 1.5730, Test Accuracy: 23.2188\n",
      "Epoch 98, Loss: 1.6835, Accuracy: 25.6815, Test Loss: 1.5728, Test Accuracy: 23.2171\n",
      "Epoch 99, Loss: 1.6823, Accuracy: 25.6830, Test Loss: 1.5726, Test Accuracy: 23.2155\n",
      "Epoch 100, Loss: 1.6811, Accuracy: 25.6845, Test Loss: 1.5724, Test Accuracy: 23.2139\n",
      "Epoch 101, Loss: 1.6799, Accuracy: 25.6860, Test Loss: 1.5721, Test Accuracy: 23.2123\n",
      "Epoch 102, Loss: 1.6788, Accuracy: 25.6874, Test Loss: 1.5719, Test Accuracy: 23.2108\n",
      "Epoch 103, Loss: 1.6776, Accuracy: 25.6889, Test Loss: 1.5717, Test Accuracy: 23.2093\n",
      "Epoch 104, Loss: 1.6765, Accuracy: 25.6902, Test Loss: 1.5715, Test Accuracy: 23.2078\n",
      "Epoch 105, Loss: 1.6754, Accuracy: 25.6916, Test Loss: 1.5713, Test Accuracy: 23.2063\n",
      "Epoch 106, Loss: 1.6743, Accuracy: 25.6929, Test Loss: 1.5711, Test Accuracy: 23.2049\n",
      "Epoch 107, Loss: 1.6732, Accuracy: 25.6943, Test Loss: 1.5709, Test Accuracy: 23.2035\n",
      "Epoch 108, Loss: 1.6723, Accuracy: 25.6955, Test Loss: 1.5708, Test Accuracy: 23.2022\n",
      "Epoch 109, Loss: 1.6713, Accuracy: 25.6968, Test Loss: 1.5706, Test Accuracy: 23.2008\n",
      "Epoch 110, Loss: 1.6702, Accuracy: 25.6981, Test Loss: 1.5704, Test Accuracy: 23.1995\n",
      "Epoch 111, Loss: 1.6693, Accuracy: 25.6993, Test Loss: 1.5702, Test Accuracy: 23.1982\n",
      "Epoch 112, Loss: 1.6683, Accuracy: 25.7005, Test Loss: 1.5701, Test Accuracy: 23.1969\n",
      "Epoch 113, Loss: 1.6678, Accuracy: 25.7016, Test Loss: 1.5699, Test Accuracy: 23.1957\n",
      "Epoch 114, Loss: 1.6669, Accuracy: 25.7028, Test Loss: 1.5697, Test Accuracy: 23.1944\n",
      "Epoch 115, Loss: 1.6660, Accuracy: 25.7039, Test Loss: 1.5696, Test Accuracy: 23.1932\n",
      "Epoch 116, Loss: 1.6651, Accuracy: 25.7050, Test Loss: 1.5694, Test Accuracy: 23.1920\n",
      "Epoch 117, Loss: 1.6643, Accuracy: 25.7061, Test Loss: 1.5692, Test Accuracy: 23.1909\n",
      "Epoch 118, Loss: 1.6634, Accuracy: 25.7062, Test Loss: 1.5691, Test Accuracy: 23.1897\n",
      "Epoch 119, Loss: 1.6626, Accuracy: 25.7073, Test Loss: 1.5689, Test Accuracy: 23.1886\n",
      "Epoch 120, Loss: 1.6617, Accuracy: 25.7083, Test Loss: 1.5688, Test Accuracy: 23.1875\n",
      "Epoch 121, Loss: 1.6609, Accuracy: 25.7094, Test Loss: 1.5686, Test Accuracy: 23.1864\n",
      "Epoch 122, Loss: 1.6601, Accuracy: 25.7104, Test Loss: 1.5685, Test Accuracy: 23.1853\n",
      "Epoch 123, Loss: 1.6593, Accuracy: 25.7114, Test Loss: 1.5684, Test Accuracy: 23.1843\n",
      "Epoch 124, Loss: 1.6585, Accuracy: 25.7124, Test Loss: 1.5682, Test Accuracy: 23.1832\n",
      "Epoch 125, Loss: 1.6577, Accuracy: 25.7133, Test Loss: 1.5681, Test Accuracy: 23.1822\n",
      "Epoch 126, Loss: 1.6569, Accuracy: 25.7143, Test Loss: 1.5679, Test Accuracy: 23.1812\n",
      "Epoch 127, Loss: 1.6562, Accuracy: 25.7152, Test Loss: 1.5678, Test Accuracy: 23.1802\n",
      "Epoch 128, Loss: 1.6554, Accuracy: 25.7161, Test Loss: 1.5677, Test Accuracy: 23.1793\n",
      "Epoch 129, Loss: 1.6547, Accuracy: 25.7171, Test Loss: 1.5675, Test Accuracy: 23.1783\n",
      "Epoch 130, Loss: 1.6540, Accuracy: 25.7179, Test Loss: 1.5674, Test Accuracy: 23.1774\n",
      "Epoch 131, Loss: 1.6532, Accuracy: 25.7188, Test Loss: 1.5673, Test Accuracy: 23.1764\n",
      "Epoch 132, Loss: 1.6526, Accuracy: 25.7197, Test Loss: 1.5671, Test Accuracy: 23.1755\n",
      "Epoch 133, Loss: 1.6519, Accuracy: 25.7206, Test Loss: 1.5670, Test Accuracy: 23.1746\n",
      "Epoch 134, Loss: 1.6512, Accuracy: 25.7214, Test Loss: 1.5669, Test Accuracy: 23.1737\n",
      "Epoch 135, Loss: 1.6506, Accuracy: 25.7222, Test Loss: 1.5668, Test Accuracy: 23.1728\n",
      "Epoch 136, Loss: 1.6500, Accuracy: 25.7230, Test Loss: 1.5667, Test Accuracy: 23.1720\n",
      "Epoch 137, Loss: 1.6493, Accuracy: 25.7238, Test Loss: 1.5665, Test Accuracy: 23.1711\n",
      "Epoch 138, Loss: 1.6487, Accuracy: 25.7246, Test Loss: 1.5664, Test Accuracy: 23.1703\n",
      "Epoch 139, Loss: 1.6481, Accuracy: 25.7254, Test Loss: 1.5663, Test Accuracy: 23.1695\n",
      "Epoch 140, Loss: 1.6475, Accuracy: 25.7262, Test Loss: 1.5662, Test Accuracy: 23.1686\n",
      "Epoch 141, Loss: 1.6469, Accuracy: 25.7269, Test Loss: 1.5661, Test Accuracy: 23.1678\n",
      "Epoch 142, Loss: 1.6463, Accuracy: 25.7277, Test Loss: 1.5660, Test Accuracy: 23.1671\n",
      "Epoch 143, Loss: 1.6457, Accuracy: 25.7284, Test Loss: 1.5659, Test Accuracy: 23.1663\n",
      "Epoch 144, Loss: 1.6451, Accuracy: 25.7292, Test Loss: 1.5658, Test Accuracy: 23.1655\n",
      "Epoch 145, Loss: 1.6445, Accuracy: 25.7299, Test Loss: 1.5657, Test Accuracy: 23.1648\n",
      "Epoch 146, Loss: 1.6439, Accuracy: 25.7306, Test Loss: 1.5656, Test Accuracy: 23.1640\n",
      "Epoch 147, Loss: 1.6434, Accuracy: 25.7313, Test Loss: 1.5655, Test Accuracy: 23.1633\n",
      "Epoch 148, Loss: 1.6429, Accuracy: 25.7320, Test Loss: 1.5654, Test Accuracy: 23.1625\n",
      "Epoch 149, Loss: 1.6423, Accuracy: 25.7327, Test Loss: 1.5653, Test Accuracy: 23.1618\n",
      "Epoch 150, Loss: 1.6418, Accuracy: 25.7333, Test Loss: 1.5652, Test Accuracy: 23.1611\n",
      "Epoch 151, Loss: 1.6413, Accuracy: 25.7340, Test Loss: 1.5651, Test Accuracy: 23.1604\n",
      "Epoch 152, Loss: 1.6407, Accuracy: 25.7346, Test Loss: 1.5650, Test Accuracy: 23.1597\n",
      "Epoch 153, Loss: 1.6402, Accuracy: 25.7353, Test Loss: 1.5649, Test Accuracy: 23.1590\n",
      "Epoch 154, Loss: 1.6397, Accuracy: 25.7359, Test Loss: 1.5648, Test Accuracy: 23.1584\n",
      "Epoch 155, Loss: 1.6392, Accuracy: 25.7366, Test Loss: 1.5647, Test Accuracy: 23.1577\n",
      "Epoch 156, Loss: 1.6387, Accuracy: 25.7372, Test Loss: 1.5646, Test Accuracy: 23.1571\n",
      "Epoch 157, Loss: 1.6382, Accuracy: 25.7378, Test Loss: 1.5645, Test Accuracy: 23.1564\n",
      "Epoch 158, Loss: 1.6378, Accuracy: 25.7384, Test Loss: 1.5644, Test Accuracy: 23.1558\n",
      "Epoch 159, Loss: 1.6373, Accuracy: 25.7390, Test Loss: 1.5644, Test Accuracy: 23.1551\n",
      "Epoch 160, Loss: 1.6368, Accuracy: 25.7396, Test Loss: 1.5643, Test Accuracy: 23.1545\n",
      "Epoch 161, Loss: 1.6364, Accuracy: 25.7402, Test Loss: 1.5642, Test Accuracy: 23.1539\n",
      "Epoch 162, Loss: 1.6359, Accuracy: 25.7407, Test Loss: 1.5641, Test Accuracy: 23.1533\n",
      "Epoch 163, Loss: 1.6355, Accuracy: 25.7413, Test Loss: 1.5640, Test Accuracy: 23.1527\n",
      "Epoch 164, Loss: 1.6350, Accuracy: 25.7419, Test Loss: 1.5640, Test Accuracy: 23.1521\n",
      "Epoch 165, Loss: 1.6346, Accuracy: 25.7424, Test Loss: 1.5639, Test Accuracy: 23.1515\n",
      "Epoch 166, Loss: 1.6342, Accuracy: 25.7430, Test Loss: 1.5638, Test Accuracy: 23.1509\n",
      "Epoch 167, Loss: 1.6337, Accuracy: 25.7435, Test Loss: 1.5637, Test Accuracy: 23.1504\n",
      "Epoch 168, Loss: 1.6333, Accuracy: 25.7440, Test Loss: 1.5636, Test Accuracy: 23.1498\n",
      "Epoch 169, Loss: 1.6328, Accuracy: 25.7446, Test Loss: 1.5636, Test Accuracy: 23.1492\n",
      "Epoch 170, Loss: 1.6324, Accuracy: 25.7451, Test Loss: 1.5635, Test Accuracy: 23.1487\n",
      "Epoch 171, Loss: 1.6321, Accuracy: 25.7456, Test Loss: 1.5634, Test Accuracy: 23.1481\n",
      "Epoch 172, Loss: 1.6316, Accuracy: 25.7461, Test Loss: 1.5633, Test Accuracy: 23.1476\n",
      "Epoch 173, Loss: 1.6312, Accuracy: 25.7466, Test Loss: 1.5633, Test Accuracy: 23.1471\n",
      "Epoch 174, Loss: 1.6309, Accuracy: 25.7471, Test Loss: 1.5632, Test Accuracy: 23.1466\n",
      "Epoch 175, Loss: 1.6305, Accuracy: 25.7476, Test Loss: 1.5631, Test Accuracy: 23.1460\n",
      "Epoch 176, Loss: 1.6301, Accuracy: 25.7481, Test Loss: 1.5631, Test Accuracy: 23.1455\n",
      "Epoch 177, Loss: 1.6297, Accuracy: 25.7486, Test Loss: 1.5630, Test Accuracy: 23.1450\n",
      "Epoch 178, Loss: 1.6294, Accuracy: 25.7491, Test Loss: 1.5629, Test Accuracy: 23.1445\n",
      "Epoch 179, Loss: 1.6290, Accuracy: 25.7495, Test Loss: 1.5629, Test Accuracy: 23.1440\n",
      "Epoch 180, Loss: 1.6286, Accuracy: 25.7500, Test Loss: 1.5628, Test Accuracy: 23.1435\n",
      "Epoch 181, Loss: 1.6282, Accuracy: 25.7505, Test Loss: 1.5627, Test Accuracy: 23.1430\n",
      "Epoch 182, Loss: 1.6278, Accuracy: 25.7509, Test Loss: 1.5627, Test Accuracy: 23.1426\n",
      "Epoch 183, Loss: 1.6274, Accuracy: 25.7514, Test Loss: 1.5626, Test Accuracy: 23.1421\n",
      "Epoch 184, Loss: 1.6271, Accuracy: 25.7518, Test Loss: 1.5625, Test Accuracy: 23.1416\n",
      "Epoch 185, Loss: 1.6267, Accuracy: 25.7523, Test Loss: 1.5625, Test Accuracy: 23.1411\n",
      "Epoch 186, Loss: 1.6264, Accuracy: 25.7527, Test Loss: 1.5624, Test Accuracy: 23.1407\n",
      "Epoch 187, Loss: 1.6260, Accuracy: 25.7531, Test Loss: 1.5624, Test Accuracy: 23.1402\n",
      "Epoch 188, Loss: 1.6257, Accuracy: 25.7535, Test Loss: 1.5623, Test Accuracy: 23.1398\n",
      "Epoch 189, Loss: 1.6253, Accuracy: 25.7540, Test Loss: 1.5622, Test Accuracy: 23.1393\n",
      "Epoch 190, Loss: 1.6250, Accuracy: 25.7544, Test Loss: 1.5622, Test Accuracy: 23.1389\n",
      "Epoch 191, Loss: 1.6247, Accuracy: 25.7548, Test Loss: 1.5621, Test Accuracy: 23.1385\n",
      "Epoch 192, Loss: 1.6243, Accuracy: 25.7552, Test Loss: 1.5621, Test Accuracy: 23.1380\n",
      "Epoch 193, Loss: 1.6240, Accuracy: 25.7556, Test Loss: 1.5620, Test Accuracy: 23.1376\n",
      "Epoch 194, Loss: 1.6238, Accuracy: 25.7560, Test Loss: 1.5619, Test Accuracy: 23.1372\n",
      "Epoch 195, Loss: 1.6236, Accuracy: 25.7558, Test Loss: 1.5619, Test Accuracy: 23.1368\n",
      "Epoch 196, Loss: 1.6233, Accuracy: 25.7562, Test Loss: 1.5618, Test Accuracy: 23.1363\n",
      "Epoch 197, Loss: 1.6230, Accuracy: 25.7566, Test Loss: 1.5618, Test Accuracy: 23.1359\n",
      "Epoch 198, Loss: 1.6227, Accuracy: 25.7570, Test Loss: 1.5617, Test Accuracy: 23.1355\n",
      "Epoch 199, Loss: 1.6224, Accuracy: 25.7574, Test Loss: 1.5617, Test Accuracy: 23.1351\n",
      "Epoch 200, Loss: 1.6221, Accuracy: 25.7577, Test Loss: 1.5616, Test Accuracy: 23.1347\n",
      "average of 3 each\n",
      "Epoch 1, Loss: 14.8093, Accuracy: 22.6786, Test Loss: 1.7423, Test Accuracy: 25.4167\n",
      "Epoch 2, Loss: 9.9059, Accuracy: 23.3929, Test Loss: 1.6749, Test Accuracy: 24.7917\n",
      "Epoch 3, Loss: 7.2257, Accuracy: 23.9881, Test Loss: 1.6515, Test Accuracy: 24.5833\n",
      "Epoch 4, Loss: 5.8415, Accuracy: 24.4196, Test Loss: 1.6391, Test Accuracy: 24.4792\n",
      "Epoch 5, Loss: 4.9915, Accuracy: 24.7500, Test Loss: 1.6312, Test Accuracy: 24.4167\n",
      "Epoch 6, Loss: 4.4365, Accuracy: 25.0000, Test Loss: 1.6254, Test Accuracy: 24.3750\n",
      "Epoch 7, Loss: 4.0321, Accuracy: 25.1020, Test Loss: 1.6210, Test Accuracy: 24.3452\n",
      "Epoch 8, Loss: 3.7313, Accuracy: 25.1786, Test Loss: 1.6174, Test Accuracy: 24.3229\n",
      "Epoch 9, Loss: 3.4940, Accuracy: 25.2976, Test Loss: 1.6143, Test Accuracy: 24.3056\n",
      "Epoch 10, Loss: 3.3063, Accuracy: 25.3571, Test Loss: 1.6117, Test Accuracy: 24.2917\n",
      "Epoch 11, Loss: 3.1514, Accuracy: 25.4221, Test Loss: 1.6094, Test Accuracy: 24.2803\n",
      "Epoch 12, Loss: 3.0221, Accuracy: 25.4613, Test Loss: 1.6073, Test Accuracy: 24.2708\n",
      "Epoch 13, Loss: 2.9143, Accuracy: 25.4945, Test Loss: 1.6054, Test Accuracy: 24.2628\n",
      "Epoch 14, Loss: 2.8188, Accuracy: 25.5102, Test Loss: 1.6037, Test Accuracy: 24.2560\n",
      "Epoch 15, Loss: 2.7361, Accuracy: 25.5119, Test Loss: 1.6021, Test Accuracy: 24.2500\n",
      "Epoch 16, Loss: 2.6633, Accuracy: 25.5246, Test Loss: 1.6007, Test Accuracy: 24.2448\n",
      "Epoch 17, Loss: 2.5997, Accuracy: 25.3782, Test Loss: 1.5993, Test Accuracy: 24.2402\n",
      "Epoch 18, Loss: 2.5441, Accuracy: 25.4464, Test Loss: 1.5980, Test Accuracy: 24.2361\n",
      "Epoch 19, Loss: 2.4931, Accuracy: 25.4323, Test Loss: 1.5968, Test Accuracy: 24.2325\n",
      "Epoch 20, Loss: 2.4470, Accuracy: 25.4286, Test Loss: 1.5957, Test Accuracy: 24.2292\n",
      "Epoch 21, Loss: 2.4053, Accuracy: 25.4422, Test Loss: 1.5947, Test Accuracy: 24.2262\n",
      "Epoch 22, Loss: 2.3675, Accuracy: 25.4627, Test Loss: 1.5937, Test Accuracy: 24.2235\n",
      "Epoch 23, Loss: 2.3322, Accuracy: 25.5202, Test Loss: 1.5927, Test Accuracy: 24.2391\n",
      "Epoch 24, Loss: 2.3008, Accuracy: 25.5283, Test Loss: 1.5918, Test Accuracy: 24.2361\n",
      "Epoch 25, Loss: 2.2714, Accuracy: 25.5214, Test Loss: 1.5910, Test Accuracy: 24.2333\n",
      "Epoch 26, Loss: 2.2445, Accuracy: 25.5220, Test Loss: 1.5902, Test Accuracy: 24.2308\n",
      "Epoch 27, Loss: 2.2193, Accuracy: 25.5159, Test Loss: 1.5894, Test Accuracy: 24.2284\n",
      "Epoch 28, Loss: 2.1963, Accuracy: 25.4911, Test Loss: 1.5887, Test Accuracy: 24.2262\n",
      "Epoch 29, Loss: 2.1749, Accuracy: 25.4988, Test Loss: 1.5880, Test Accuracy: 24.2241\n",
      "Epoch 30, Loss: 2.1555, Accuracy: 25.5179, Test Loss: 1.5873, Test Accuracy: 24.2222\n",
      "Epoch 31, Loss: 2.1365, Accuracy: 25.5127, Test Loss: 1.5867, Test Accuracy: 24.2204\n",
      "Epoch 32, Loss: 2.1186, Accuracy: 25.5134, Test Loss: 1.5861, Test Accuracy: 24.2188\n",
      "Epoch 33, Loss: 2.1022, Accuracy: 25.5087, Test Loss: 1.5855, Test Accuracy: 24.2172\n",
      "Epoch 34, Loss: 2.0862, Accuracy: 25.5147, Test Loss: 1.5849, Test Accuracy: 24.2157\n",
      "Epoch 35, Loss: 2.0711, Accuracy: 25.5153, Test Loss: 1.5844, Test Accuracy: 24.2143\n",
      "Epoch 36, Loss: 2.0567, Accuracy: 25.5357, Test Loss: 1.5839, Test Accuracy: 24.2130\n",
      "Epoch 37, Loss: 2.0435, Accuracy: 25.5550, Test Loss: 1.5834, Test Accuracy: 24.2117\n",
      "Epoch 38, Loss: 2.0314, Accuracy: 25.5545, Test Loss: 1.5830, Test Accuracy: 24.2105\n",
      "Epoch 39, Loss: 2.0193, Accuracy: 25.5494, Test Loss: 1.5825, Test Accuracy: 24.2094\n",
      "Epoch 40, Loss: 2.0084, Accuracy: 25.5491, Test Loss: 1.5821, Test Accuracy: 24.2083\n",
      "Epoch 41, Loss: 1.9974, Accuracy: 25.5444, Test Loss: 1.5817, Test Accuracy: 24.2073\n",
      "Epoch 42, Loss: 1.9873, Accuracy: 25.5442, Test Loss: 1.5813, Test Accuracy: 24.2063\n",
      "Epoch 43, Loss: 1.9771, Accuracy: 25.5482, Test Loss: 1.5809, Test Accuracy: 24.2054\n",
      "Epoch 44, Loss: 1.9680, Accuracy: 25.5479, Test Loss: 1.5805, Test Accuracy: 24.2045\n",
      "Epoch 45, Loss: 1.9589, Accuracy: 25.5437, Test Loss: 1.5802, Test Accuracy: 24.2037\n",
      "Epoch 46, Loss: 1.9502, Accuracy: 25.5551, Test Loss: 1.5799, Test Accuracy: 24.2029\n",
      "Epoch 47, Loss: 1.9420, Accuracy: 25.5547, Test Loss: 1.5795, Test Accuracy: 24.2021\n",
      "Epoch 48, Loss: 1.9340, Accuracy: 25.5506, Test Loss: 1.5792, Test Accuracy: 24.2014\n",
      "Epoch 49, Loss: 1.9263, Accuracy: 25.5503, Test Loss: 1.5789, Test Accuracy: 24.2007\n",
      "Epoch 50, Loss: 1.9189, Accuracy: 25.5464, Test Loss: 1.5786, Test Accuracy: 24.2000\n",
      "Epoch 51, Loss: 1.9118, Accuracy: 25.5497, Test Loss: 1.5784, Test Accuracy: 24.1993\n",
      "Epoch 52, Loss: 1.9049, Accuracy: 25.5460, Test Loss: 1.5781, Test Accuracy: 24.1987\n",
      "Epoch 53, Loss: 1.8984, Accuracy: 25.5425, Test Loss: 1.5778, Test Accuracy: 24.1981\n",
      "Epoch 54, Loss: 1.8921, Accuracy: 25.5390, Test Loss: 1.5776, Test Accuracy: 24.1975\n",
      "Epoch 55, Loss: 1.8860, Accuracy: 25.5357, Test Loss: 1.5773, Test Accuracy: 24.1970\n",
      "Epoch 56, Loss: 1.8803, Accuracy: 25.5325, Test Loss: 1.5771, Test Accuracy: 24.1964\n",
      "Epoch 57, Loss: 1.8747, Accuracy: 25.5294, Test Loss: 1.5769, Test Accuracy: 24.1959\n",
      "Epoch 58, Loss: 1.8693, Accuracy: 25.5265, Test Loss: 1.5767, Test Accuracy: 24.1954\n",
      "Epoch 59, Loss: 1.8640, Accuracy: 25.5236, Test Loss: 1.5765, Test Accuracy: 24.1949\n",
      "Epoch 60, Loss: 1.8589, Accuracy: 25.5208, Test Loss: 1.5763, Test Accuracy: 24.1944\n",
      "Epoch 61, Loss: 1.8540, Accuracy: 25.5181, Test Loss: 1.5761, Test Accuracy: 24.1940\n",
      "Epoch 62, Loss: 1.8492, Accuracy: 25.5156, Test Loss: 1.5759, Test Accuracy: 24.1935\n",
      "Epoch 63, Loss: 1.8445, Accuracy: 25.5130, Test Loss: 1.5757, Test Accuracy: 24.1931\n",
      "Epoch 64, Loss: 1.8400, Accuracy: 25.5106, Test Loss: 1.5755, Test Accuracy: 24.1927\n",
      "Epoch 65, Loss: 1.8357, Accuracy: 25.5110, Test Loss: 1.5753, Test Accuracy: 24.1923\n",
      "Epoch 66, Loss: 1.8314, Accuracy: 25.5114, Test Loss: 1.5752, Test Accuracy: 24.1919\n",
      "Epoch 67, Loss: 1.8273, Accuracy: 25.5091, Test Loss: 1.5750, Test Accuracy: 24.1915\n",
      "Epoch 68, Loss: 1.8236, Accuracy: 25.5042, Test Loss: 1.5749, Test Accuracy: 24.1912\n",
      "Epoch 69, Loss: 1.8198, Accuracy: 25.5021, Test Loss: 1.5747, Test Accuracy: 24.1908\n",
      "Epoch 70, Loss: 1.8161, Accuracy: 25.5000, Test Loss: 1.5746, Test Accuracy: 24.1905\n",
      "Epoch 71, Loss: 1.8125, Accuracy: 25.4980, Test Loss: 1.5744, Test Accuracy: 24.1901\n",
      "Epoch 72, Loss: 1.8090, Accuracy: 25.4960, Test Loss: 1.5743, Test Accuracy: 24.1898\n",
      "Epoch 73, Loss: 1.8057, Accuracy: 25.4941, Test Loss: 1.5741, Test Accuracy: 24.1895\n",
      "Epoch 74, Loss: 1.8024, Accuracy: 25.4923, Test Loss: 1.5740, Test Accuracy: 24.1892\n",
      "Epoch 75, Loss: 1.7991, Accuracy: 25.4905, Test Loss: 1.5739, Test Accuracy: 24.1889\n",
      "Epoch 76, Loss: 1.7960, Accuracy: 25.4887, Test Loss: 1.5737, Test Accuracy: 24.1886\n",
      "Epoch 77, Loss: 1.7929, Accuracy: 25.4870, Test Loss: 1.5736, Test Accuracy: 24.1883\n",
      "Epoch 78, Loss: 1.7898, Accuracy: 25.4853, Test Loss: 1.5735, Test Accuracy: 24.1880\n",
      "Epoch 79, Loss: 1.7875, Accuracy: 25.4882, Test Loss: 1.5734, Test Accuracy: 24.1878\n",
      "Epoch 80, Loss: 1.7846, Accuracy: 25.4844, Test Loss: 1.5733, Test Accuracy: 24.1875\n",
      "Epoch 81, Loss: 1.7818, Accuracy: 25.4828, Test Loss: 1.5732, Test Accuracy: 24.1872\n",
      "Epoch 82, Loss: 1.7790, Accuracy: 25.4834, Test Loss: 1.5731, Test Accuracy: 24.1870\n",
      "Epoch 83, Loss: 1.7764, Accuracy: 25.4819, Test Loss: 1.5730, Test Accuracy: 24.1867\n",
      "Epoch 84, Loss: 1.7738, Accuracy: 25.4804, Test Loss: 1.5729, Test Accuracy: 24.1865\n",
      "Epoch 85, Loss: 1.7713, Accuracy: 25.4790, Test Loss: 1.5728, Test Accuracy: 24.1863\n",
      "Epoch 86, Loss: 1.7688, Accuracy: 25.4776, Test Loss: 1.5727, Test Accuracy: 24.1860\n",
      "Epoch 87, Loss: 1.7664, Accuracy: 25.4762, Test Loss: 1.5726, Test Accuracy: 24.1858\n",
      "Epoch 88, Loss: 1.7639, Accuracy: 25.4748, Test Loss: 1.5725, Test Accuracy: 24.1856\n",
      "Epoch 89, Loss: 1.7616, Accuracy: 25.4735, Test Loss: 1.5724, Test Accuracy: 24.1854\n",
      "Epoch 90, Loss: 1.7593, Accuracy: 25.4722, Test Loss: 1.5723, Test Accuracy: 24.1852\n",
      "Epoch 91, Loss: 1.7571, Accuracy: 25.4710, Test Loss: 1.5722, Test Accuracy: 24.1850\n",
      "Epoch 92, Loss: 1.7550, Accuracy: 25.4717, Test Loss: 1.5721, Test Accuracy: 24.1848\n",
      "Epoch 93, Loss: 1.7529, Accuracy: 25.4723, Test Loss: 1.5721, Test Accuracy: 24.1846\n",
      "Epoch 94, Loss: 1.7508, Accuracy: 25.4711, Test Loss: 1.5720, Test Accuracy: 24.1844\n",
      "Epoch 95, Loss: 1.7488, Accuracy: 25.4756, Test Loss: 1.5719, Test Accuracy: 24.1842\n",
      "Epoch 96, Loss: 1.7468, Accuracy: 25.4743, Test Loss: 1.5718, Test Accuracy: 24.1840\n",
      "Epoch 97, Loss: 1.7448, Accuracy: 25.4731, Test Loss: 1.5718, Test Accuracy: 24.1838\n",
      "Epoch 98, Loss: 1.7429, Accuracy: 25.4719, Test Loss: 1.5717, Test Accuracy: 24.1837\n",
      "Epoch 99, Loss: 1.7410, Accuracy: 25.4708, Test Loss: 1.5716, Test Accuracy: 24.1835\n",
      "Epoch 100, Loss: 1.7392, Accuracy: 25.4696, Test Loss: 1.5715, Test Accuracy: 24.1833\n",
      "Epoch 101, Loss: 1.7374, Accuracy: 25.4685, Test Loss: 1.5715, Test Accuracy: 24.1832\n",
      "Epoch 102, Loss: 1.7358, Accuracy: 25.4744, Test Loss: 1.5714, Test Accuracy: 24.1830\n",
      "Epoch 103, Loss: 1.7341, Accuracy: 25.4733, Test Loss: 1.5713, Test Accuracy: 24.1828\n",
      "Epoch 104, Loss: 1.7324, Accuracy: 25.4722, Test Loss: 1.5713, Test Accuracy: 24.1827\n",
      "Epoch 105, Loss: 1.7308, Accuracy: 25.4711, Test Loss: 1.5712, Test Accuracy: 24.1825\n",
      "Epoch 106, Loss: 1.7291, Accuracy: 25.4700, Test Loss: 1.5711, Test Accuracy: 24.1824\n",
      "Epoch 107, Loss: 1.7275, Accuracy: 25.4690, Test Loss: 1.5711, Test Accuracy: 24.1822\n",
      "Epoch 108, Loss: 1.7259, Accuracy: 25.4679, Test Loss: 1.5710, Test Accuracy: 24.1821\n",
      "Epoch 109, Loss: 1.7244, Accuracy: 25.4669, Test Loss: 1.5710, Test Accuracy: 24.1820\n",
      "Epoch 110, Loss: 1.7229, Accuracy: 25.4675, Test Loss: 1.5709, Test Accuracy: 24.1818\n",
      "Epoch 111, Loss: 1.7214, Accuracy: 25.4649, Test Loss: 1.5708, Test Accuracy: 24.1817\n",
      "Epoch 112, Loss: 1.7200, Accuracy: 25.4640, Test Loss: 1.5708, Test Accuracy: 24.1815\n",
      "Epoch 113, Loss: 1.7185, Accuracy: 25.4630, Test Loss: 1.5707, Test Accuracy: 24.1814\n",
      "Epoch 114, Loss: 1.7171, Accuracy: 25.4621, Test Loss: 1.5707, Test Accuracy: 24.1813\n",
      "Epoch 115, Loss: 1.7157, Accuracy: 25.4612, Test Loss: 1.5706, Test Accuracy: 24.1812\n",
      "Epoch 116, Loss: 1.7143, Accuracy: 25.4603, Test Loss: 1.5706, Test Accuracy: 24.1810\n",
      "Epoch 117, Loss: 1.7130, Accuracy: 25.4594, Test Loss: 1.5705, Test Accuracy: 24.1809\n",
      "Epoch 118, Loss: 1.7117, Accuracy: 25.4585, Test Loss: 1.5705, Test Accuracy: 24.1808\n",
      "Epoch 119, Loss: 1.7104, Accuracy: 25.4577, Test Loss: 1.5704, Test Accuracy: 24.1807\n",
      "Epoch 120, Loss: 1.7091, Accuracy: 25.4568, Test Loss: 1.5704, Test Accuracy: 24.1806\n",
      "Epoch 121, Loss: 1.7079, Accuracy: 25.4560, Test Loss: 1.5703, Test Accuracy: 24.1804\n",
      "Epoch 122, Loss: 1.7067, Accuracy: 25.4552, Test Loss: 1.5703, Test Accuracy: 24.1803\n",
      "Epoch 123, Loss: 1.7054, Accuracy: 25.4544, Test Loss: 1.5702, Test Accuracy: 24.1802\n",
      "Epoch 124, Loss: 1.7042, Accuracy: 25.4536, Test Loss: 1.5702, Test Accuracy: 24.1801\n",
      "Epoch 125, Loss: 1.7031, Accuracy: 25.4529, Test Loss: 1.5701, Test Accuracy: 24.1800\n",
      "Epoch 126, Loss: 1.7019, Accuracy: 25.4521, Test Loss: 1.5701, Test Accuracy: 24.1799\n",
      "Epoch 127, Loss: 1.7008, Accuracy: 25.4514, Test Loss: 1.5701, Test Accuracy: 24.1798\n",
      "Epoch 128, Loss: 1.6996, Accuracy: 25.4506, Test Loss: 1.5700, Test Accuracy: 24.1797\n",
      "Epoch 129, Loss: 1.6986, Accuracy: 25.4485, Test Loss: 1.5700, Test Accuracy: 24.1796\n",
      "Epoch 130, Loss: 1.6975, Accuracy: 25.4478, Test Loss: 1.5699, Test Accuracy: 24.1795\n",
      "Epoch 131, Loss: 1.6964, Accuracy: 25.4471, Test Loss: 1.5699, Test Accuracy: 24.1794\n",
      "Epoch 132, Loss: 1.6954, Accuracy: 25.4464, Test Loss: 1.5699, Test Accuracy: 24.1793\n",
      "Epoch 133, Loss: 1.6944, Accuracy: 25.4458, Test Loss: 1.5698, Test Accuracy: 24.1792\n",
      "Epoch 134, Loss: 1.6934, Accuracy: 25.4451, Test Loss: 1.5698, Test Accuracy: 24.1791\n",
      "Epoch 135, Loss: 1.6924, Accuracy: 25.4458, Test Loss: 1.5697, Test Accuracy: 24.1790\n",
      "Epoch 136, Loss: 1.6914, Accuracy: 25.4438, Test Loss: 1.5697, Test Accuracy: 24.1789\n",
      "Epoch 137, Loss: 1.6904, Accuracy: 25.4432, Test Loss: 1.5697, Test Accuracy: 24.1788\n",
      "Epoch 138, Loss: 1.6895, Accuracy: 25.4425, Test Loss: 1.5696, Test Accuracy: 24.1787\n",
      "Epoch 139, Loss: 1.6885, Accuracy: 25.4419, Test Loss: 1.5696, Test Accuracy: 24.1787\n",
      "Epoch 140, Loss: 1.6876, Accuracy: 25.4413, Test Loss: 1.5696, Test Accuracy: 24.1786\n",
      "Epoch 141, Loss: 1.6867, Accuracy: 25.4407, Test Loss: 1.5695, Test Accuracy: 24.1785\n",
      "Epoch 142, Loss: 1.6858, Accuracy: 25.4401, Test Loss: 1.5695, Test Accuracy: 24.1784\n",
      "Epoch 143, Loss: 1.6849, Accuracy: 25.4396, Test Loss: 1.5695, Test Accuracy: 24.1783\n",
      "Epoch 144, Loss: 1.6840, Accuracy: 25.4390, Test Loss: 1.5694, Test Accuracy: 24.1782\n",
      "Epoch 145, Loss: 1.6832, Accuracy: 25.4384, Test Loss: 1.5694, Test Accuracy: 24.1782\n",
      "Epoch 146, Loss: 1.6823, Accuracy: 25.4379, Test Loss: 1.5694, Test Accuracy: 24.1781\n",
      "Epoch 147, Loss: 1.6815, Accuracy: 25.4373, Test Loss: 1.5693, Test Accuracy: 24.1780\n",
      "Epoch 148, Loss: 1.6807, Accuracy: 25.4368, Test Loss: 1.5693, Test Accuracy: 24.1779\n",
      "Epoch 149, Loss: 1.6798, Accuracy: 25.4362, Test Loss: 1.5693, Test Accuracy: 24.1779\n",
      "Epoch 150, Loss: 1.6790, Accuracy: 25.4357, Test Loss: 1.5693, Test Accuracy: 24.1778\n",
      "Epoch 151, Loss: 1.6782, Accuracy: 25.4352, Test Loss: 1.5692, Test Accuracy: 24.1777\n",
      "Epoch 152, Loss: 1.6774, Accuracy: 25.4347, Test Loss: 1.5692, Test Accuracy: 24.1776\n",
      "Epoch 153, Loss: 1.6766, Accuracy: 25.4353, Test Loss: 1.5692, Test Accuracy: 24.1776\n",
      "Epoch 154, Loss: 1.6759, Accuracy: 25.4348, Test Loss: 1.5691, Test Accuracy: 24.1775\n",
      "Epoch 155, Loss: 1.6751, Accuracy: 25.4343, Test Loss: 1.5691, Test Accuracy: 24.1774\n",
      "Epoch 156, Loss: 1.6743, Accuracy: 25.4338, Test Loss: 1.5691, Test Accuracy: 24.1774\n",
      "Epoch 157, Loss: 1.6736, Accuracy: 25.4333, Test Loss: 1.5691, Test Accuracy: 24.1773\n",
      "Epoch 158, Loss: 1.6729, Accuracy: 25.4329, Test Loss: 1.5690, Test Accuracy: 24.1772\n",
      "Epoch 159, Loss: 1.6721, Accuracy: 25.4313, Test Loss: 1.5690, Test Accuracy: 24.1771\n",
      "Epoch 160, Loss: 1.6715, Accuracy: 25.4286, Test Loss: 1.5690, Test Accuracy: 24.1771\n",
      "Epoch 161, Loss: 1.6707, Accuracy: 25.4281, Test Loss: 1.5690, Test Accuracy: 24.1770\n",
      "Epoch 162, Loss: 1.6700, Accuracy: 25.4277, Test Loss: 1.5689, Test Accuracy: 24.1770\n",
      "Epoch 163, Loss: 1.6693, Accuracy: 25.4273, Test Loss: 1.5689, Test Accuracy: 24.1769\n",
      "Epoch 164, Loss: 1.6686, Accuracy: 25.4268, Test Loss: 1.5689, Test Accuracy: 24.1768\n",
      "Epoch 165, Loss: 1.6680, Accuracy: 25.4264, Test Loss: 1.5689, Test Accuracy: 24.1768\n",
      "Epoch 166, Loss: 1.6673, Accuracy: 25.4260, Test Loss: 1.5688, Test Accuracy: 24.1767\n",
      "Epoch 167, Loss: 1.6666, Accuracy: 25.4256, Test Loss: 1.5688, Test Accuracy: 24.1766\n",
      "Epoch 168, Loss: 1.6660, Accuracy: 25.4252, Test Loss: 1.5688, Test Accuracy: 24.1766\n",
      "Epoch 169, Loss: 1.6653, Accuracy: 25.4248, Test Loss: 1.5688, Test Accuracy: 24.1765\n",
      "Epoch 170, Loss: 1.6647, Accuracy: 25.4244, Test Loss: 1.5687, Test Accuracy: 24.1765\n",
      "Epoch 171, Loss: 1.6641, Accuracy: 25.4240, Test Loss: 1.5687, Test Accuracy: 24.1764\n",
      "Epoch 172, Loss: 1.6635, Accuracy: 25.4111, Test Loss: 1.5687, Test Accuracy: 24.1788\n",
      "Epoch 173, Loss: 1.6629, Accuracy: 25.4067, Test Loss: 1.5687, Test Accuracy: 24.1787\n",
      "Epoch 174, Loss: 1.6622, Accuracy: 25.4064, Test Loss: 1.5686, Test Accuracy: 24.1786\n",
      "Epoch 175, Loss: 1.6617, Accuracy: 25.4061, Test Loss: 1.5686, Test Accuracy: 24.1786\n",
      "Epoch 176, Loss: 1.6611, Accuracy: 25.4058, Test Loss: 1.5686, Test Accuracy: 24.1785\n",
      "Epoch 177, Loss: 1.6605, Accuracy: 25.4056, Test Loss: 1.5686, Test Accuracy: 24.1784\n",
      "Epoch 178, Loss: 1.6599, Accuracy: 25.4053, Test Loss: 1.5686, Test Accuracy: 24.1784\n",
      "Epoch 179, Loss: 1.6593, Accuracy: 25.4050, Test Loss: 1.5685, Test Accuracy: 24.1783\n",
      "Epoch 180, Loss: 1.6588, Accuracy: 25.4048, Test Loss: 1.5685, Test Accuracy: 24.1782\n",
      "Epoch 181, Loss: 1.6582, Accuracy: 25.4045, Test Loss: 1.5685, Test Accuracy: 24.1782\n",
      "Epoch 182, Loss: 1.6577, Accuracy: 25.4042, Test Loss: 1.5685, Test Accuracy: 24.1781\n",
      "Epoch 183, Loss: 1.6571, Accuracy: 25.3972, Test Loss: 1.5685, Test Accuracy: 24.1803\n",
      "Epoch 184, Loss: 1.6566, Accuracy: 25.3960, Test Loss: 1.5684, Test Accuracy: 24.1803\n",
      "Epoch 185, Loss: 1.6561, Accuracy: 25.3958, Test Loss: 1.5684, Test Accuracy: 24.1802\n",
      "Epoch 186, Loss: 1.6556, Accuracy: 25.3955, Test Loss: 1.5684, Test Accuracy: 24.1801\n",
      "Epoch 187, Loss: 1.6550, Accuracy: 25.3953, Test Loss: 1.5684, Test Accuracy: 24.1800\n",
      "Epoch 188, Loss: 1.6545, Accuracy: 25.3951, Test Loss: 1.5684, Test Accuracy: 24.1800\n",
      "Epoch 189, Loss: 1.6540, Accuracy: 25.3949, Test Loss: 1.5683, Test Accuracy: 24.1799\n",
      "Epoch 190, Loss: 1.6535, Accuracy: 25.3947, Test Loss: 1.5683, Test Accuracy: 24.1798\n",
      "Epoch 191, Loss: 1.6530, Accuracy: 25.3945, Test Loss: 1.5683, Test Accuracy: 24.1798\n",
      "Epoch 192, Loss: 1.6525, Accuracy: 25.3943, Test Loss: 1.5683, Test Accuracy: 24.1797\n",
      "Epoch 193, Loss: 1.6520, Accuracy: 25.3942, Test Loss: 1.5683, Test Accuracy: 24.1796\n",
      "Epoch 194, Loss: 1.6516, Accuracy: 25.3940, Test Loss: 1.5683, Test Accuracy: 24.1796\n",
      "Epoch 195, Loss: 1.6511, Accuracy: 25.3938, Test Loss: 1.5682, Test Accuracy: 24.1795\n",
      "Epoch 196, Loss: 1.6506, Accuracy: 25.3936, Test Loss: 1.5682, Test Accuracy: 24.1794\n",
      "Epoch 197, Loss: 1.6501, Accuracy: 25.3934, Test Loss: 1.5682, Test Accuracy: 24.1794\n",
      "Epoch 198, Loss: 1.6497, Accuracy: 25.3932, Test Loss: 1.5682, Test Accuracy: 24.1793\n",
      "Epoch 199, Loss: 1.6492, Accuracy: 25.3930, Test Loss: 1.5682, Test Accuracy: 24.1792\n",
      "Epoch 200, Loss: 1.6488, Accuracy: 25.3929, Test Loss: 1.5682, Test Accuracy: 24.1792\n",
      "average of 4 each\n",
      "Epoch 1, Loss: 15.9369, Accuracy: 22.1429, Test Loss: 1.6193, Test Accuracy: 18.3333\n",
      "Epoch 2, Loss: 11.1035, Accuracy: 21.4286, Test Loss: 1.6143, Test Accuracy: 19.7222\n",
      "Epoch 3, Loss: 8.0950, Accuracy: 22.9365, Test Loss: 1.6120, Test Accuracy: 20.1852\n",
      "Epoch 4, Loss: 6.4881, Accuracy: 23.9286, Test Loss: 1.6106, Test Accuracy: 20.4167\n",
      "Epoch 5, Loss: 5.5152, Accuracy: 24.6190, Test Loss: 1.6094, Test Accuracy: 20.5556\n",
      "Epoch 6, Loss: 4.8647, Accuracy: 25.2381, Test Loss: 1.6083, Test Accuracy: 20.6481\n",
      "Epoch 7, Loss: 4.4049, Accuracy: 25.4082, Test Loss: 1.6072, Test Accuracy: 20.7143\n",
      "Epoch 8, Loss: 4.0531, Accuracy: 25.6250, Test Loss: 1.6062, Test Accuracy: 20.7639\n",
      "Epoch 9, Loss: 3.7882, Accuracy: 25.7937, Test Loss: 1.6052, Test Accuracy: 20.8025\n",
      "Epoch 10, Loss: 3.5709, Accuracy: 26.0238, Test Loss: 1.6043, Test Accuracy: 20.8333\n",
      "Epoch 11, Loss: 3.3917, Accuracy: 26.0823, Test Loss: 1.6033, Test Accuracy: 20.8586\n",
      "Epoch 12, Loss: 3.2418, Accuracy: 26.1508, Test Loss: 1.6025, Test Accuracy: 20.8796\n",
      "Epoch 13, Loss: 3.1191, Accuracy: 26.1905, Test Loss: 1.6016, Test Accuracy: 20.8974\n",
      "Epoch 14, Loss: 3.0111, Accuracy: 26.1905, Test Loss: 1.6008, Test Accuracy: 20.9127\n",
      "Epoch 15, Loss: 2.9164, Accuracy: 26.2064, Test Loss: 1.6000, Test Accuracy: 20.9259\n",
      "Epoch 16, Loss: 2.8339, Accuracy: 26.2946, Test Loss: 1.5993, Test Accuracy: 20.9375\n",
      "Epoch 17, Loss: 2.7605, Accuracy: 26.3165, Test Loss: 1.5985, Test Accuracy: 20.9477\n",
      "Epoch 18, Loss: 2.6961, Accuracy: 26.3228, Test Loss: 1.5978, Test Accuracy: 20.9568\n",
      "Epoch 19, Loss: 2.6384, Accuracy: 26.3409, Test Loss: 1.5972, Test Accuracy: 20.9649\n",
      "Epoch 20, Loss: 2.5857, Accuracy: 26.3571, Test Loss: 1.5965, Test Accuracy: 20.9722\n",
      "Epoch 21, Loss: 2.5386, Accuracy: 26.3832, Test Loss: 1.5959, Test Accuracy: 20.9788\n",
      "Epoch 22, Loss: 2.4955, Accuracy: 26.3853, Test Loss: 1.5953, Test Accuracy: 20.9848\n",
      "Epoch 23, Loss: 2.4555, Accuracy: 26.4079, Test Loss: 1.5947, Test Accuracy: 20.9903\n",
      "Epoch 24, Loss: 2.4188, Accuracy: 26.4087, Test Loss: 1.5941, Test Accuracy: 20.9954\n",
      "Epoch 25, Loss: 2.3852, Accuracy: 26.4381, Test Loss: 1.5935, Test Accuracy: 21.0000\n",
      "Epoch 26, Loss: 2.3540, Accuracy: 26.4377, Test Loss: 1.5930, Test Accuracy: 21.0043\n",
      "Epoch 27, Loss: 2.3250, Accuracy: 26.4638, Test Loss: 1.5924, Test Accuracy: 21.0082\n",
      "Epoch 28, Loss: 2.2982, Accuracy: 26.4711, Test Loss: 1.5919, Test Accuracy: 21.0119\n",
      "Epoch 29, Loss: 2.2735, Accuracy: 26.4860, Test Loss: 1.5914, Test Accuracy: 21.0153\n",
      "Epoch 30, Loss: 2.2501, Accuracy: 26.5000, Test Loss: 1.5909, Test Accuracy: 21.0185\n",
      "Epoch 31, Loss: 2.2281, Accuracy: 26.5131, Test Loss: 1.5904, Test Accuracy: 21.0215\n",
      "Epoch 32, Loss: 2.2072, Accuracy: 26.5625, Test Loss: 1.5899, Test Accuracy: 21.0243\n",
      "Epoch 33, Loss: 2.1880, Accuracy: 26.5945, Test Loss: 1.5895, Test Accuracy: 21.0269\n",
      "Epoch 34, Loss: 2.1700, Accuracy: 26.5966, Test Loss: 1.5891, Test Accuracy: 21.0294\n",
      "Epoch 35, Loss: 2.1526, Accuracy: 26.6054, Test Loss: 1.5887, Test Accuracy: 21.0317\n",
      "Epoch 36, Loss: 2.1367, Accuracy: 26.6138, Test Loss: 1.5883, Test Accuracy: 21.0340\n",
      "Epoch 37, Loss: 2.1214, Accuracy: 26.6152, Test Loss: 1.5879, Test Accuracy: 21.0360\n",
      "Epoch 38, Loss: 2.1068, Accuracy: 26.6165, Test Loss: 1.5875, Test Accuracy: 21.0380\n",
      "Epoch 39, Loss: 2.0932, Accuracy: 26.6178, Test Loss: 1.5872, Test Accuracy: 21.0399\n",
      "Epoch 40, Loss: 2.0805, Accuracy: 26.6071, Test Loss: 1.5869, Test Accuracy: 21.0417\n",
      "Epoch 41, Loss: 2.0681, Accuracy: 26.5970, Test Loss: 1.5866, Test Accuracy: 21.0434\n",
      "Epoch 42, Loss: 2.0561, Accuracy: 26.5986, Test Loss: 1.5862, Test Accuracy: 21.0450\n",
      "Epoch 43, Loss: 2.0445, Accuracy: 26.6002, Test Loss: 1.5859, Test Accuracy: 21.0465\n",
      "Epoch 44, Loss: 2.0335, Accuracy: 26.6017, Test Loss: 1.5856, Test Accuracy: 21.0480\n",
      "Epoch 45, Loss: 2.0234, Accuracy: 26.6032, Test Loss: 1.5853, Test Accuracy: 21.0494\n",
      "Epoch 46, Loss: 2.0136, Accuracy: 26.6046, Test Loss: 1.5850, Test Accuracy: 21.0507\n",
      "Epoch 47, Loss: 2.0042, Accuracy: 26.6160, Test Loss: 1.5847, Test Accuracy: 21.0520\n",
      "Epoch 48, Loss: 1.9948, Accuracy: 26.6270, Test Loss: 1.5844, Test Accuracy: 21.0532\n",
      "Epoch 49, Loss: 1.9862, Accuracy: 26.6327, Test Loss: 1.5841, Test Accuracy: 21.0544\n",
      "Epoch 50, Loss: 1.9778, Accuracy: 26.6333, Test Loss: 1.5838, Test Accuracy: 21.0556\n",
      "Epoch 51, Loss: 1.9699, Accuracy: 26.6620, Test Loss: 1.5835, Test Accuracy: 21.0675\n",
      "Epoch 52, Loss: 1.9620, Accuracy: 26.6667, Test Loss: 1.5832, Test Accuracy: 21.0684\n",
      "Epoch 53, Loss: 1.9546, Accuracy: 26.6712, Test Loss: 1.5830, Test Accuracy: 21.0692\n",
      "Epoch 54, Loss: 1.9470, Accuracy: 26.6843, Test Loss: 1.5827, Test Accuracy: 21.0700\n",
      "Epoch 55, Loss: 1.9402, Accuracy: 26.6883, Test Loss: 1.5824, Test Accuracy: 21.0707\n",
      "Epoch 56, Loss: 1.9336, Accuracy: 26.6922, Test Loss: 1.5822, Test Accuracy: 21.0714\n",
      "Epoch 57, Loss: 1.9268, Accuracy: 26.7168, Test Loss: 1.5819, Test Accuracy: 21.0721\n",
      "Epoch 58, Loss: 1.9205, Accuracy: 26.7323, Test Loss: 1.5817, Test Accuracy: 21.0728\n",
      "Epoch 59, Loss: 1.9149, Accuracy: 26.7393, Test Loss: 1.5815, Test Accuracy: 21.0734\n",
      "Epoch 60, Loss: 1.9093, Accuracy: 26.7659, Test Loss: 1.5812, Test Accuracy: 21.0741\n",
      "Epoch 61, Loss: 1.9034, Accuracy: 26.7838, Test Loss: 1.5810, Test Accuracy: 21.0747\n",
      "Epoch 62, Loss: 1.8975, Accuracy: 26.8126, Test Loss: 1.5808, Test Accuracy: 21.0753\n",
      "Epoch 63, Loss: 1.8923, Accuracy: 26.8292, Test Loss: 1.5806, Test Accuracy: 21.0758\n",
      "Epoch 64, Loss: 1.8873, Accuracy: 26.8266, Test Loss: 1.5804, Test Accuracy: 21.0764\n",
      "Epoch 65, Loss: 1.8821, Accuracy: 26.8315, Test Loss: 1.5802, Test Accuracy: 21.0769\n",
      "Epoch 66, Loss: 1.8773, Accuracy: 26.8326, Test Loss: 1.5800, Test Accuracy: 21.0774\n",
      "Epoch 67, Loss: 1.8726, Accuracy: 26.8408, Test Loss: 1.5798, Test Accuracy: 21.0779\n",
      "Epoch 68, Loss: 1.8684, Accuracy: 26.8452, Test Loss: 1.5797, Test Accuracy: 21.0784\n",
      "Epoch 69, Loss: 1.8637, Accuracy: 26.8634, Test Loss: 1.5796, Test Accuracy: 21.0386\n",
      "Epoch 70, Loss: 1.8592, Accuracy: 26.8844, Test Loss: 1.5794, Test Accuracy: 21.0159\n",
      "Epoch 71, Loss: 1.8551, Accuracy: 26.8913, Test Loss: 1.5793, Test Accuracy: 21.0172\n",
      "Epoch 72, Loss: 1.8510, Accuracy: 26.8948, Test Loss: 1.5791, Test Accuracy: 21.0185\n",
      "Epoch 73, Loss: 1.8469, Accuracy: 26.9048, Test Loss: 1.5790, Test Accuracy: 21.0198\n",
      "Epoch 74, Loss: 1.8429, Accuracy: 26.9273, Test Loss: 1.5788, Test Accuracy: 21.0210\n",
      "Epoch 75, Loss: 1.8394, Accuracy: 26.9238, Test Loss: 1.5787, Test Accuracy: 21.0222\n",
      "Epoch 76, Loss: 1.8357, Accuracy: 26.9392, Test Loss: 1.5785, Test Accuracy: 21.0234\n",
      "Epoch 77, Loss: 1.8320, Accuracy: 26.9419, Test Loss: 1.5784, Test Accuracy: 21.0245\n",
      "Epoch 78, Loss: 1.8285, Accuracy: 26.9414, Test Loss: 1.5782, Test Accuracy: 21.0256\n",
      "Epoch 79, Loss: 1.8250, Accuracy: 26.9439, Test Loss: 1.5781, Test Accuracy: 21.0267\n",
      "Epoch 80, Loss: 1.8215, Accuracy: 26.9435, Test Loss: 1.5780, Test Accuracy: 21.0278\n",
      "Epoch 81, Loss: 1.8182, Accuracy: 26.9459, Test Loss: 1.5778, Test Accuracy: 21.0288\n",
      "Epoch 82, Loss: 1.8150, Accuracy: 26.9483, Test Loss: 1.5777, Test Accuracy: 21.0298\n",
      "Epoch 83, Loss: 1.8117, Accuracy: 26.9564, Test Loss: 1.5776, Test Accuracy: 21.0308\n",
      "Epoch 84, Loss: 1.8088, Accuracy: 26.9671, Test Loss: 1.5775, Test Accuracy: 21.0317\n",
      "Epoch 85, Loss: 1.8059, Accuracy: 26.9916, Test Loss: 1.5774, Test Accuracy: 21.0327\n",
      "Epoch 86, Loss: 1.8029, Accuracy: 27.0072, Test Loss: 1.5773, Test Accuracy: 21.0336\n",
      "Epoch 87, Loss: 1.8000, Accuracy: 27.0252, Test Loss: 1.5771, Test Accuracy: 21.0345\n",
      "Epoch 88, Loss: 1.7974, Accuracy: 27.0346, Test Loss: 1.5770, Test Accuracy: 21.0354\n",
      "Epoch 89, Loss: 1.7947, Accuracy: 27.0305, Test Loss: 1.5769, Test Accuracy: 21.0362\n",
      "Epoch 90, Loss: 1.7925, Accuracy: 27.0370, Test Loss: 1.5768, Test Accuracy: 21.0370\n",
      "Epoch 91, Loss: 1.7898, Accuracy: 27.0330, Test Loss: 1.5767, Test Accuracy: 21.0379\n",
      "Epoch 92, Loss: 1.7874, Accuracy: 27.0342, Test Loss: 1.5766, Test Accuracy: 21.0386\n",
      "Epoch 93, Loss: 1.7850, Accuracy: 27.0533, Test Loss: 1.5765, Test Accuracy: 21.0394\n",
      "Epoch 94, Loss: 1.7828, Accuracy: 27.0669, Test Loss: 1.5765, Test Accuracy: 21.0402\n",
      "Epoch 95, Loss: 1.7804, Accuracy: 27.0652, Test Loss: 1.5764, Test Accuracy: 21.0409\n",
      "Epoch 96, Loss: 1.7780, Accuracy: 27.0635, Test Loss: 1.5763, Test Accuracy: 21.0417\n",
      "Epoch 97, Loss: 1.7760, Accuracy: 27.0594, Test Loss: 1.5762, Test Accuracy: 21.0424\n",
      "Epoch 98, Loss: 1.7738, Accuracy: 27.0554, Test Loss: 1.5762, Test Accuracy: 21.0431\n",
      "Epoch 99, Loss: 1.7717, Accuracy: 27.0491, Test Loss: 1.5761, Test Accuracy: 21.0438\n",
      "Epoch 100, Loss: 1.7695, Accuracy: 27.0500, Test Loss: 1.5760, Test Accuracy: 21.0444\n",
      "Epoch 101, Loss: 1.7674, Accuracy: 27.0627, Test Loss: 1.5759, Test Accuracy: 21.0451\n",
      "Epoch 102, Loss: 1.7653, Accuracy: 27.0635, Test Loss: 1.5759, Test Accuracy: 21.0458\n",
      "Epoch 103, Loss: 1.7633, Accuracy: 27.0643, Test Loss: 1.5758, Test Accuracy: 21.0464\n",
      "Epoch 104, Loss: 1.7613, Accuracy: 27.0650, Test Loss: 1.5757, Test Accuracy: 21.0470\n",
      "Epoch 105, Loss: 1.7593, Accuracy: 27.0703, Test Loss: 1.5757, Test Accuracy: 21.0476\n",
      "Epoch 106, Loss: 1.7571, Accuracy: 27.0800, Test Loss: 1.5756, Test Accuracy: 21.0482\n",
      "Epoch 107, Loss: 1.7552, Accuracy: 27.0850, Test Loss: 1.5755, Test Accuracy: 21.0488\n",
      "Epoch 108, Loss: 1.7534, Accuracy: 27.0855, Test Loss: 1.5755, Test Accuracy: 21.0494\n",
      "Epoch 109, Loss: 1.7516, Accuracy: 27.0904, Test Loss: 1.5754, Test Accuracy: 21.0499\n",
      "Epoch 110, Loss: 1.7497, Accuracy: 27.0952, Test Loss: 1.5754, Test Accuracy: 21.0505\n",
      "Epoch 111, Loss: 1.7480, Accuracy: 27.1021, Test Loss: 1.5753, Test Accuracy: 21.0511\n",
      "Epoch 112, Loss: 1.7462, Accuracy: 27.1003, Test Loss: 1.5752, Test Accuracy: 21.0516\n",
      "Epoch 113, Loss: 1.7446, Accuracy: 27.1007, Test Loss: 1.5752, Test Accuracy: 21.0521\n",
      "Epoch 114, Loss: 1.7430, Accuracy: 27.0990, Test Loss: 1.5751, Test Accuracy: 21.0526\n",
      "Epoch 115, Loss: 1.7415, Accuracy: 27.1014, Test Loss: 1.5751, Test Accuracy: 21.0531\n",
      "Epoch 116, Loss: 1.7397, Accuracy: 27.1059, Test Loss: 1.5750, Test Accuracy: 21.0536\n",
      "Epoch 117, Loss: 1.7384, Accuracy: 27.1103, Test Loss: 1.5750, Test Accuracy: 21.0541\n",
      "Epoch 118, Loss: 1.7369, Accuracy: 27.1106, Test Loss: 1.5749, Test Accuracy: 21.0546\n",
      "Epoch 119, Loss: 1.7355, Accuracy: 27.1068, Test Loss: 1.5749, Test Accuracy: 21.0551\n",
      "Epoch 120, Loss: 1.7341, Accuracy: 27.1032, Test Loss: 1.5748, Test Accuracy: 21.0556\n",
      "Epoch 121, Loss: 1.7328, Accuracy: 27.0996, Test Loss: 1.5748, Test Accuracy: 21.0560\n",
      "Epoch 122, Loss: 1.7314, Accuracy: 27.0980, Test Loss: 1.5747, Test Accuracy: 21.0565\n",
      "Epoch 123, Loss: 1.7300, Accuracy: 27.0964, Test Loss: 1.5747, Test Accuracy: 21.0569\n",
      "Epoch 124, Loss: 1.7288, Accuracy: 27.0929, Test Loss: 1.5746, Test Accuracy: 21.0573\n",
      "Epoch 125, Loss: 1.7274, Accuracy: 27.0914, Test Loss: 1.5746, Test Accuracy: 21.0578\n",
      "Epoch 126, Loss: 1.7260, Accuracy: 27.0881, Test Loss: 1.5745, Test Accuracy: 21.0582\n",
      "Epoch 127, Loss: 1.7247, Accuracy: 27.0847, Test Loss: 1.5745, Test Accuracy: 21.0586\n",
      "Epoch 128, Loss: 1.7235, Accuracy: 27.0815, Test Loss: 1.5744, Test Accuracy: 21.0590\n",
      "Epoch 129, Loss: 1.7222, Accuracy: 27.0783, Test Loss: 1.5744, Test Accuracy: 21.0594\n",
      "Epoch 130, Loss: 1.7209, Accuracy: 27.0769, Test Loss: 1.5743, Test Accuracy: 21.0598\n",
      "Epoch 131, Loss: 1.7197, Accuracy: 27.0756, Test Loss: 1.5743, Test Accuracy: 21.0602\n",
      "Epoch 132, Loss: 1.7186, Accuracy: 27.0725, Test Loss: 1.5742, Test Accuracy: 21.0606\n",
      "Epoch 133, Loss: 1.7174, Accuracy: 27.0695, Test Loss: 1.5742, Test Accuracy: 21.0610\n",
      "Epoch 134, Loss: 1.7164, Accuracy: 27.0718, Test Loss: 1.5742, Test Accuracy: 21.0614\n",
      "Epoch 135, Loss: 1.7152, Accuracy: 27.0705, Test Loss: 1.5741, Test Accuracy: 21.0617\n",
      "Epoch 136, Loss: 1.7141, Accuracy: 27.0676, Test Loss: 1.5741, Test Accuracy: 21.0621\n",
      "Epoch 137, Loss: 1.7132, Accuracy: 27.0647, Test Loss: 1.5740, Test Accuracy: 21.0624\n",
      "Epoch 138, Loss: 1.7121, Accuracy: 27.0618, Test Loss: 1.5740, Test Accuracy: 21.0628\n",
      "Epoch 139, Loss: 1.7109, Accuracy: 27.0589, Test Loss: 1.5739, Test Accuracy: 21.0631\n",
      "Epoch 140, Loss: 1.7099, Accuracy: 27.0561, Test Loss: 1.5739, Test Accuracy: 21.0635\n",
      "Epoch 141, Loss: 1.7088, Accuracy: 27.0534, Test Loss: 1.5739, Test Accuracy: 21.0638\n",
      "Epoch 142, Loss: 1.7078, Accuracy: 27.0506, Test Loss: 1.5738, Test Accuracy: 21.0642\n",
      "Epoch 143, Loss: 1.7068, Accuracy: 27.0480, Test Loss: 1.5738, Test Accuracy: 21.0645\n",
      "Epoch 144, Loss: 1.7058, Accuracy: 27.0453, Test Loss: 1.5737, Test Accuracy: 21.0648\n",
      "Epoch 145, Loss: 1.7047, Accuracy: 27.0427, Test Loss: 1.5737, Test Accuracy: 21.0651\n",
      "Epoch 146, Loss: 1.7037, Accuracy: 27.0401, Test Loss: 1.5737, Test Accuracy: 21.0654\n",
      "Epoch 147, Loss: 1.7027, Accuracy: 27.0392, Test Loss: 1.5736, Test Accuracy: 21.0658\n",
      "Epoch 148, Loss: 1.7017, Accuracy: 27.0367, Test Loss: 1.5736, Test Accuracy: 21.0661\n",
      "Epoch 149, Loss: 1.7008, Accuracy: 27.0342, Test Loss: 1.5736, Test Accuracy: 21.0664\n",
      "Epoch 150, Loss: 1.6998, Accuracy: 27.0317, Test Loss: 1.5735, Test Accuracy: 21.0667\n",
      "Epoch 151, Loss: 1.6989, Accuracy: 27.0293, Test Loss: 1.5735, Test Accuracy: 21.0670\n",
      "Epoch 152, Loss: 1.6980, Accuracy: 27.0269, Test Loss: 1.5735, Test Accuracy: 21.0673\n",
      "Epoch 153, Loss: 1.6970, Accuracy: 27.0246, Test Loss: 1.5734, Test Accuracy: 21.0675\n",
      "Epoch 154, Loss: 1.6962, Accuracy: 27.0223, Test Loss: 1.5734, Test Accuracy: 21.0678\n",
      "Epoch 155, Loss: 1.6953, Accuracy: 27.0215, Test Loss: 1.5734, Test Accuracy: 21.0681\n",
      "Epoch 156, Loss: 1.6944, Accuracy: 27.0192, Test Loss: 1.5733, Test Accuracy: 21.0684\n",
      "Epoch 157, Loss: 1.6936, Accuracy: 27.0200, Test Loss: 1.5733, Test Accuracy: 21.0686\n",
      "Epoch 158, Loss: 1.6930, Accuracy: 27.0193, Test Loss: 1.5733, Test Accuracy: 21.0689\n",
      "Epoch 159, Loss: 1.6921, Accuracy: 27.0186, Test Loss: 1.5733, Test Accuracy: 21.0692\n",
      "Epoch 160, Loss: 1.6912, Accuracy: 27.0193, Test Loss: 1.5732, Test Accuracy: 21.0694\n",
      "Epoch 161, Loss: 1.6904, Accuracy: 27.0186, Test Loss: 1.5732, Test Accuracy: 21.0697\n",
      "Epoch 162, Loss: 1.6896, Accuracy: 27.0194, Test Loss: 1.5732, Test Accuracy: 21.0700\n",
      "Epoch 163, Loss: 1.6889, Accuracy: 27.0172, Test Loss: 1.5731, Test Accuracy: 21.0702\n",
      "Epoch 164, Loss: 1.6880, Accuracy: 27.0195, Test Loss: 1.5731, Test Accuracy: 21.0705\n",
      "Epoch 165, Loss: 1.6872, Accuracy: 27.0188, Test Loss: 1.5731, Test Accuracy: 21.0707\n",
      "Epoch 166, Loss: 1.6864, Accuracy: 27.0224, Test Loss: 1.5730, Test Accuracy: 21.0709\n",
      "Epoch 167, Loss: 1.6856, Accuracy: 27.0217, Test Loss: 1.5730, Test Accuracy: 21.0712\n",
      "Epoch 168, Loss: 1.6848, Accuracy: 27.0238, Test Loss: 1.5730, Test Accuracy: 21.0714\n",
      "Epoch 169, Loss: 1.6840, Accuracy: 27.0287, Test Loss: 1.5730, Test Accuracy: 21.0717\n",
      "Epoch 170, Loss: 1.6832, Accuracy: 27.0294, Test Loss: 1.5730, Test Accuracy: 21.0719\n",
      "Epoch 171, Loss: 1.6824, Accuracy: 27.0287, Test Loss: 1.5729, Test Accuracy: 21.0721\n",
      "Epoch 172, Loss: 1.6817, Accuracy: 27.0280, Test Loss: 1.5729, Test Accuracy: 21.0724\n",
      "Epoch 173, Loss: 1.6810, Accuracy: 27.0286, Test Loss: 1.5729, Test Accuracy: 21.0726\n",
      "Epoch 174, Loss: 1.6803, Accuracy: 27.0334, Test Loss: 1.5729, Test Accuracy: 21.0728\n",
      "Epoch 175, Loss: 1.6795, Accuracy: 27.0381, Test Loss: 1.5728, Test Accuracy: 21.0730\n",
      "Epoch 176, Loss: 1.6787, Accuracy: 27.0414, Test Loss: 1.5728, Test Accuracy: 21.0732\n",
      "Epoch 177, Loss: 1.6781, Accuracy: 27.0420, Test Loss: 1.5728, Test Accuracy: 21.0734\n",
      "Epoch 178, Loss: 1.6774, Accuracy: 27.0479, Test Loss: 1.5728, Test Accuracy: 21.0737\n",
      "Epoch 179, Loss: 1.6768, Accuracy: 27.0471, Test Loss: 1.5728, Test Accuracy: 21.0739\n",
      "Epoch 180, Loss: 1.6761, Accuracy: 27.0476, Test Loss: 1.5727, Test Accuracy: 21.0741\n",
      "Epoch 181, Loss: 1.6753, Accuracy: 27.0495, Test Loss: 1.5727, Test Accuracy: 21.0743\n",
      "Epoch 182, Loss: 1.6746, Accuracy: 27.0578, Test Loss: 1.5727, Test Accuracy: 21.0745\n",
      "Epoch 183, Loss: 1.6744, Accuracy: 27.0570, Test Loss: 1.5727, Test Accuracy: 21.0747\n",
      "Epoch 184, Loss: 1.6738, Accuracy: 27.0575, Test Loss: 1.5726, Test Accuracy: 21.0749\n",
      "Epoch 185, Loss: 1.6732, Accuracy: 27.0618, Test Loss: 1.5726, Test Accuracy: 21.0751\n",
      "Epoch 186, Loss: 1.6726, Accuracy: 27.0622, Test Loss: 1.5726, Test Accuracy: 21.0753\n",
      "Epoch 187, Loss: 1.6727, Accuracy: 27.0690, Test Loss: 1.5726, Test Accuracy: 21.0784\n",
      "Epoch 188, Loss: 1.6721, Accuracy: 27.0745, Test Loss: 1.5725, Test Accuracy: 21.0816\n",
      "Epoch 189, Loss: 1.6715, Accuracy: 27.0774, Test Loss: 1.5725, Test Accuracy: 21.0847\n",
      "Epoch 190, Loss: 1.6708, Accuracy: 27.0827, Test Loss: 1.5725, Test Accuracy: 21.0848\n",
      "Epoch 191, Loss: 1.6701, Accuracy: 27.0880, Test Loss: 1.5725, Test Accuracy: 21.0849\n",
      "Epoch 192, Loss: 1.6696, Accuracy: 27.0933, Test Loss: 1.5724, Test Accuracy: 21.0851\n",
      "Epoch 193, Loss: 1.6689, Accuracy: 27.0997, Test Loss: 1.5724, Test Accuracy: 21.0881\n",
      "Epoch 194, Loss: 1.6684, Accuracy: 27.1060, Test Loss: 1.5724, Test Accuracy: 21.0882\n",
      "Epoch 195, Loss: 1.6680, Accuracy: 27.1160, Test Loss: 1.5724, Test Accuracy: 21.0883\n",
      "Epoch 196, Loss: 1.6673, Accuracy: 27.1259, Test Loss: 1.5723, Test Accuracy: 21.0884\n",
      "Epoch 197, Loss: 1.6667, Accuracy: 27.1332, Test Loss: 1.5723, Test Accuracy: 21.0886\n",
      "Epoch 198, Loss: 1.6662, Accuracy: 27.1368, Test Loss: 1.5723, Test Accuracy: 21.0887\n",
      "Epoch 199, Loss: 1.6656, Accuracy: 27.1345, Test Loss: 1.5723, Test Accuracy: 21.0888\n",
      "Epoch 200, Loss: 1.6652, Accuracy: 27.1345, Test Loss: 1.5722, Test Accuracy: 21.0889\n",
      "average of 5 each\n",
      "Epoch 1, Loss: 15.7057, Accuracy: 25.5952, Test Loss: 1.6261, Test Accuracy: 15.9722\n",
      "Epoch 2, Loss: 13.1085, Accuracy: 24.1071, Test Loss: 1.6166, Test Accuracy: 18.7500\n",
      "Epoch 3, Loss: 10.0177, Accuracy: 24.4048, Test Loss: 1.6125, Test Accuracy: 21.7593\n",
      "Epoch 4, Loss: 8.1082, Accuracy: 23.8095, Test Loss: 1.6108, Test Accuracy: 23.4375\n",
      "Epoch 5, Loss: 6.8468, Accuracy: 24.1667, Test Loss: 1.6094, Test Accuracy: 24.4444\n",
      "Epoch 6, Loss: 5.9792, Accuracy: 24.3056, Test Loss: 1.6082, Test Accuracy: 25.1157\n",
      "Epoch 7, Loss: 5.3725, Accuracy: 24.1922, Test Loss: 1.6071, Test Accuracy: 25.5952\n",
      "Epoch 8, Loss: 4.9029, Accuracy: 24.1815, Test Loss: 1.6060, Test Accuracy: 25.9549\n",
      "Epoch 9, Loss: 4.5417, Accuracy: 24.0079, Test Loss: 1.6050, Test Accuracy: 25.6173\n",
      "Epoch 10, Loss: 4.2473, Accuracy: 24.2857, Test Loss: 1.6040, Test Accuracy: 25.3472\n",
      "Epoch 11, Loss: 4.0102, Accuracy: 24.4859, Test Loss: 1.6031, Test Accuracy: 25.1263\n",
      "Epoch 12, Loss: 3.8084, Accuracy: 24.6280, Test Loss: 1.6022, Test Accuracy: 24.9421\n",
      "Epoch 13, Loss: 3.6388, Accuracy: 24.7253, Test Loss: 1.6013, Test Accuracy: 24.7863\n",
      "Epoch 14, Loss: 3.4927, Accuracy: 24.8087, Test Loss: 1.6005, Test Accuracy: 24.6528\n",
      "Epoch 15, Loss: 3.3697, Accuracy: 24.8810, Test Loss: 1.5997, Test Accuracy: 24.5370\n",
      "Epoch 16, Loss: 3.2607, Accuracy: 24.9256, Test Loss: 1.5989, Test Accuracy: 24.4358\n",
      "Epoch 17, Loss: 3.1619, Accuracy: 25.0000, Test Loss: 1.5982, Test Accuracy: 24.3464\n",
      "Epoch 18, Loss: 3.0745, Accuracy: 25.0496, Test Loss: 1.5974, Test Accuracy: 24.2670\n",
      "Epoch 19, Loss: 2.9967, Accuracy: 25.1096, Test Loss: 1.5967, Test Accuracy: 24.1959\n",
      "Epoch 20, Loss: 2.9276, Accuracy: 25.1637, Test Loss: 1.5961, Test Accuracy: 24.1319\n",
      "Epoch 21, Loss: 2.8645, Accuracy: 25.2268, Test Loss: 1.5954, Test Accuracy: 24.0741\n",
      "Epoch 22, Loss: 2.8067, Accuracy: 25.2841, Test Loss: 1.5948, Test Accuracy: 24.0215\n",
      "Epoch 23, Loss: 2.7531, Accuracy: 25.3235, Test Loss: 1.5941, Test Accuracy: 23.9734\n",
      "Epoch 24, Loss: 2.7040, Accuracy: 25.3844, Test Loss: 1.5935, Test Accuracy: 23.9294\n",
      "Epoch 25, Loss: 2.6588, Accuracy: 25.4167, Test Loss: 1.5930, Test Accuracy: 23.8889\n",
      "Epoch 26, Loss: 2.6173, Accuracy: 25.4235, Test Loss: 1.5924, Test Accuracy: 23.8515\n",
      "Epoch 27, Loss: 2.5786, Accuracy: 25.4409, Test Loss: 1.5919, Test Accuracy: 23.8169\n",
      "Epoch 28, Loss: 2.5426, Accuracy: 25.4571, Test Loss: 1.5913, Test Accuracy: 23.7847\n",
      "Epoch 29, Loss: 2.5102, Accuracy: 25.4721, Test Loss: 1.5908, Test Accuracy: 23.7548\n",
      "Epoch 30, Loss: 2.4789, Accuracy: 25.4861, Test Loss: 1.5903, Test Accuracy: 23.7269\n",
      "Epoch 31, Loss: 2.4496, Accuracy: 25.5088, Test Loss: 1.5898, Test Accuracy: 23.7007\n",
      "Epoch 32, Loss: 2.4221, Accuracy: 25.5208, Test Loss: 1.5894, Test Accuracy: 23.6762\n",
      "Epoch 33, Loss: 2.3962, Accuracy: 25.5321, Test Loss: 1.5889, Test Accuracy: 23.6532\n",
      "Epoch 34, Loss: 2.3717, Accuracy: 25.5515, Test Loss: 1.5885, Test Accuracy: 23.6315\n",
      "Epoch 35, Loss: 2.3486, Accuracy: 25.5697, Test Loss: 1.5880, Test Accuracy: 23.6111\n",
      "Epoch 36, Loss: 2.3269, Accuracy: 25.5870, Test Loss: 1.5876, Test Accuracy: 23.5918\n",
      "Epoch 37, Loss: 2.3071, Accuracy: 25.6033, Test Loss: 1.5872, Test Accuracy: 23.5736\n",
      "Epoch 38, Loss: 2.2875, Accuracy: 25.6187, Test Loss: 1.5868, Test Accuracy: 23.5563\n",
      "Epoch 39, Loss: 2.2690, Accuracy: 25.6258, Test Loss: 1.5864, Test Accuracy: 23.5399\n",
      "Epoch 40, Loss: 2.2515, Accuracy: 25.6324, Test Loss: 1.5860, Test Accuracy: 23.5243\n",
      "Epoch 41, Loss: 2.2354, Accuracy: 25.6388, Test Loss: 1.5856, Test Accuracy: 23.5095\n",
      "Epoch 42, Loss: 2.2194, Accuracy: 25.6448, Test Loss: 1.5853, Test Accuracy: 23.4954\n",
      "Epoch 43, Loss: 2.2042, Accuracy: 25.6506, Test Loss: 1.5849, Test Accuracy: 23.4819\n",
      "Epoch 44, Loss: 2.1896, Accuracy: 25.6561, Test Loss: 1.5846, Test Accuracy: 23.4691\n",
      "Epoch 45, Loss: 2.1769, Accuracy: 25.6614, Test Loss: 1.5843, Test Accuracy: 23.4568\n",
      "Epoch 46, Loss: 2.1635, Accuracy: 25.6664, Test Loss: 1.5840, Test Accuracy: 23.4450\n",
      "Epoch 47, Loss: 2.1507, Accuracy: 25.6776, Test Loss: 1.5837, Test Accuracy: 23.4338\n",
      "Epoch 48, Loss: 2.1383, Accuracy: 25.6882, Test Loss: 1.5834, Test Accuracy: 23.4230\n",
      "Epoch 49, Loss: 2.1266, Accuracy: 25.7046, Test Loss: 1.5831, Test Accuracy: 23.4127\n",
      "Epoch 50, Loss: 2.1153, Accuracy: 25.7083, Test Loss: 1.5828, Test Accuracy: 23.4028\n",
      "Epoch 51, Loss: 2.1046, Accuracy: 25.7120, Test Loss: 1.5825, Test Accuracy: 23.3932\n",
      "Epoch 52, Loss: 2.0942, Accuracy: 25.7154, Test Loss: 1.5822, Test Accuracy: 23.3841\n",
      "Epoch 53, Loss: 2.0841, Accuracy: 25.7188, Test Loss: 1.5820, Test Accuracy: 23.3753\n",
      "Epoch 54, Loss: 2.0744, Accuracy: 25.7220, Test Loss: 1.5817, Test Accuracy: 23.3668\n",
      "Epoch 55, Loss: 2.0651, Accuracy: 25.7251, Test Loss: 1.5815, Test Accuracy: 23.3586\n",
      "Epoch 56, Loss: 2.0561, Accuracy: 25.7281, Test Loss: 1.5813, Test Accuracy: 23.3507\n",
      "Epoch 57, Loss: 2.0475, Accuracy: 25.7310, Test Loss: 1.5810, Test Accuracy: 23.3431\n",
      "Epoch 58, Loss: 2.0392, Accuracy: 25.7338, Test Loss: 1.5808, Test Accuracy: 23.3357\n",
      "Epoch 59, Loss: 2.0311, Accuracy: 25.7365, Test Loss: 1.5806, Test Accuracy: 23.3286\n",
      "Epoch 60, Loss: 2.0232, Accuracy: 25.7391, Test Loss: 1.5804, Test Accuracy: 23.3218\n",
      "Epoch 61, Loss: 2.0156, Accuracy: 25.7416, Test Loss: 1.5802, Test Accuracy: 23.3151\n",
      "Epoch 62, Loss: 2.0082, Accuracy: 25.7440, Test Loss: 1.5800, Test Accuracy: 23.3087\n",
      "Epoch 63, Loss: 2.0010, Accuracy: 25.7464, Test Loss: 1.5798, Test Accuracy: 23.3025\n",
      "Epoch 64, Loss: 1.9940, Accuracy: 25.7533, Test Loss: 1.5796, Test Accuracy: 23.2964\n",
      "Epoch 65, Loss: 1.9873, Accuracy: 25.7555, Test Loss: 1.5794, Test Accuracy: 23.2906\n",
      "Epoch 66, Loss: 1.9808, Accuracy: 25.7576, Test Loss: 1.5792, Test Accuracy: 23.2849\n",
      "Epoch 67, Loss: 1.9744, Accuracy: 25.7596, Test Loss: 1.5790, Test Accuracy: 23.2794\n",
      "Epoch 68, Loss: 1.9683, Accuracy: 25.7616, Test Loss: 1.5789, Test Accuracy: 23.2741\n",
      "Epoch 69, Loss: 1.9624, Accuracy: 25.7635, Test Loss: 1.5787, Test Accuracy: 23.2689\n",
      "Epoch 70, Loss: 1.9566, Accuracy: 25.7653, Test Loss: 1.5785, Test Accuracy: 23.2639\n",
      "Epoch 71, Loss: 1.9510, Accuracy: 25.7671, Test Loss: 1.5784, Test Accuracy: 23.2590\n",
      "Epoch 72, Loss: 1.9456, Accuracy: 25.7688, Test Loss: 1.5782, Test Accuracy: 23.2542\n",
      "Epoch 73, Loss: 1.9404, Accuracy: 25.7705, Test Loss: 1.5781, Test Accuracy: 23.2496\n",
      "Epoch 74, Loss: 1.9353, Accuracy: 25.7722, Test Loss: 1.5780, Test Accuracy: 23.2451\n",
      "Epoch 75, Loss: 1.9302, Accuracy: 25.7738, Test Loss: 1.5778, Test Accuracy: 23.2407\n",
      "Epoch 76, Loss: 1.9253, Accuracy: 25.7754, Test Loss: 1.5777, Test Accuracy: 23.2365\n",
      "Epoch 77, Loss: 1.9205, Accuracy: 25.7769, Test Loss: 1.5776, Test Accuracy: 23.2323\n",
      "Epoch 78, Loss: 1.9158, Accuracy: 25.7784, Test Loss: 1.5774, Test Accuracy: 23.2283\n",
      "Epoch 79, Loss: 1.9112, Accuracy: 25.7798, Test Loss: 1.5773, Test Accuracy: 23.2243\n",
      "Epoch 80, Loss: 1.9068, Accuracy: 25.7812, Test Loss: 1.5772, Test Accuracy: 23.2205\n",
      "Epoch 81, Loss: 1.9025, Accuracy: 25.7826, Test Loss: 1.5771, Test Accuracy: 23.2167\n",
      "Epoch 82, Loss: 1.8983, Accuracy: 25.7840, Test Loss: 1.5769, Test Accuracy: 23.2131\n",
      "Epoch 83, Loss: 1.8942, Accuracy: 25.7853, Test Loss: 1.5768, Test Accuracy: 23.2095\n",
      "Epoch 84, Loss: 1.8902, Accuracy: 25.7866, Test Loss: 1.5767, Test Accuracy: 23.2060\n",
      "Epoch 85, Loss: 1.8864, Accuracy: 25.7878, Test Loss: 1.5766, Test Accuracy: 23.2026\n",
      "Epoch 86, Loss: 1.8826, Accuracy: 25.7890, Test Loss: 1.5765, Test Accuracy: 23.1993\n",
      "Epoch 87, Loss: 1.8789, Accuracy: 25.7902, Test Loss: 1.5764, Test Accuracy: 23.1960\n",
      "Epoch 88, Loss: 1.8752, Accuracy: 25.7914, Test Loss: 1.5763, Test Accuracy: 23.1929\n",
      "Epoch 89, Loss: 1.8716, Accuracy: 25.7925, Test Loss: 1.5762, Test Accuracy: 23.1898\n",
      "Epoch 90, Loss: 1.8681, Accuracy: 25.7937, Test Loss: 1.5761, Test Accuracy: 23.1867\n",
      "Epoch 91, Loss: 1.8646, Accuracy: 25.7947, Test Loss: 1.5761, Test Accuracy: 23.1838\n",
      "Epoch 92, Loss: 1.8613, Accuracy: 25.7958, Test Loss: 1.5760, Test Accuracy: 23.1809\n",
      "Epoch 93, Loss: 1.8580, Accuracy: 25.7969, Test Loss: 1.5759, Test Accuracy: 23.1780\n",
      "Epoch 94, Loss: 1.8548, Accuracy: 25.7979, Test Loss: 1.5758, Test Accuracy: 23.1752\n",
      "Epoch 95, Loss: 1.8516, Accuracy: 25.8020, Test Loss: 1.5757, Test Accuracy: 23.1725\n",
      "Epoch 96, Loss: 1.8485, Accuracy: 25.7999, Test Loss: 1.5756, Test Accuracy: 23.1698\n",
      "Epoch 97, Loss: 1.8455, Accuracy: 25.8008, Test Loss: 1.5756, Test Accuracy: 23.1672\n",
      "Epoch 98, Loss: 1.8425, Accuracy: 25.8017, Test Loss: 1.5755, Test Accuracy: 23.1647\n",
      "Epoch 99, Loss: 1.8396, Accuracy: 25.8027, Test Loss: 1.5754, Test Accuracy: 23.1622\n",
      "Epoch 100, Loss: 1.8367, Accuracy: 25.8036, Test Loss: 1.5753, Test Accuracy: 23.1597\n",
      "Epoch 101, Loss: 1.8339, Accuracy: 25.8045, Test Loss: 1.5753, Test Accuracy: 23.1573\n",
      "Epoch 102, Loss: 1.8312, Accuracy: 25.8053, Test Loss: 1.5752, Test Accuracy: 23.1550\n",
      "Epoch 103, Loss: 1.8285, Accuracy: 25.8062, Test Loss: 1.5751, Test Accuracy: 23.1526\n",
      "Epoch 104, Loss: 1.8259, Accuracy: 25.8070, Test Loss: 1.5751, Test Accuracy: 23.1504\n",
      "Epoch 105, Loss: 1.8232, Accuracy: 25.8078, Test Loss: 1.5750, Test Accuracy: 23.1481\n",
      "Epoch 106, Loss: 1.8207, Accuracy: 25.8086, Test Loss: 1.5749, Test Accuracy: 23.1460\n",
      "Epoch 107, Loss: 1.8182, Accuracy: 25.8094, Test Loss: 1.5749, Test Accuracy: 23.1438\n",
      "Epoch 108, Loss: 1.8158, Accuracy: 25.8102, Test Loss: 1.5748, Test Accuracy: 23.1417\n",
      "Epoch 109, Loss: 1.8134, Accuracy: 25.8109, Test Loss: 1.5748, Test Accuracy: 23.1397\n",
      "Epoch 110, Loss: 1.8111, Accuracy: 25.8117, Test Loss: 1.5747, Test Accuracy: 23.1376\n",
      "Epoch 111, Loss: 1.8088, Accuracy: 25.8124, Test Loss: 1.5746, Test Accuracy: 23.1356\n",
      "Epoch 112, Loss: 1.8065, Accuracy: 25.8131, Test Loss: 1.5746, Test Accuracy: 23.1337\n",
      "Epoch 113, Loss: 1.8044, Accuracy: 25.8138, Test Loss: 1.5745, Test Accuracy: 23.1318\n",
      "Epoch 114, Loss: 1.8022, Accuracy: 25.8145, Test Loss: 1.5745, Test Accuracy: 23.1299\n",
      "Epoch 115, Loss: 1.8000, Accuracy: 25.8152, Test Loss: 1.5744, Test Accuracy: 23.1280\n",
      "Epoch 116, Loss: 1.7979, Accuracy: 25.8159, Test Loss: 1.5744, Test Accuracy: 23.1262\n",
      "Epoch 117, Loss: 1.7958, Accuracy: 25.8165, Test Loss: 1.5743, Test Accuracy: 23.1244\n",
      "Epoch 118, Loss: 1.7938, Accuracy: 25.8172, Test Loss: 1.5743, Test Accuracy: 23.1226\n",
      "Epoch 119, Loss: 1.7918, Accuracy: 25.8178, Test Loss: 1.5742, Test Accuracy: 23.1209\n",
      "Epoch 120, Loss: 1.7898, Accuracy: 25.8185, Test Loss: 1.5742, Test Accuracy: 23.1192\n",
      "Epoch 121, Loss: 1.7879, Accuracy: 25.8191, Test Loss: 1.5741, Test Accuracy: 23.1175\n",
      "Epoch 122, Loss: 1.7860, Accuracy: 25.8197, Test Loss: 1.5741, Test Accuracy: 23.1159\n",
      "Epoch 123, Loss: 1.7841, Accuracy: 25.8203, Test Loss: 1.5740, Test Accuracy: 23.1143\n",
      "Epoch 124, Loss: 1.7822, Accuracy: 25.8233, Test Loss: 1.5740, Test Accuracy: 23.1127\n",
      "Epoch 125, Loss: 1.7804, Accuracy: 25.8238, Test Loss: 1.5740, Test Accuracy: 23.1111\n",
      "Epoch 126, Loss: 1.7786, Accuracy: 25.8244, Test Loss: 1.5739, Test Accuracy: 23.1096\n",
      "Epoch 127, Loss: 1.7768, Accuracy: 25.8249, Test Loss: 1.5739, Test Accuracy: 23.1080\n",
      "Epoch 128, Loss: 1.7751, Accuracy: 25.8254, Test Loss: 1.5738, Test Accuracy: 23.1066\n",
      "Epoch 129, Loss: 1.7734, Accuracy: 25.8260, Test Loss: 1.5738, Test Accuracy: 23.1051\n",
      "Epoch 130, Loss: 1.7717, Accuracy: 25.8265, Test Loss: 1.5737, Test Accuracy: 23.1036\n",
      "Epoch 131, Loss: 1.7701, Accuracy: 25.8270, Test Loss: 1.5737, Test Accuracy: 23.1022\n",
      "Epoch 132, Loss: 1.7684, Accuracy: 25.8275, Test Loss: 1.5737, Test Accuracy: 23.1008\n",
      "Epoch 133, Loss: 1.7668, Accuracy: 25.8280, Test Loss: 1.5736, Test Accuracy: 23.0994\n",
      "Epoch 134, Loss: 1.7652, Accuracy: 25.8284, Test Loss: 1.5736, Test Accuracy: 23.0981\n",
      "Epoch 135, Loss: 1.7636, Accuracy: 25.8289, Test Loss: 1.5736, Test Accuracy: 23.0967\n",
      "Epoch 136, Loss: 1.7621, Accuracy: 25.8294, Test Loss: 1.5735, Test Accuracy: 23.0954\n",
      "Epoch 137, Loss: 1.7606, Accuracy: 25.8299, Test Loss: 1.5735, Test Accuracy: 23.0941\n",
      "Epoch 138, Loss: 1.7591, Accuracy: 25.8303, Test Loss: 1.5735, Test Accuracy: 23.0928\n",
      "Epoch 139, Loss: 1.7576, Accuracy: 25.8308, Test Loss: 1.5734, Test Accuracy: 23.0915\n",
      "Epoch 140, Loss: 1.7562, Accuracy: 25.8312, Test Loss: 1.5734, Test Accuracy: 23.0903\n",
      "Epoch 141, Loss: 1.7547, Accuracy: 25.8316, Test Loss: 1.5734, Test Accuracy: 23.0890\n",
      "Epoch 142, Loss: 1.7533, Accuracy: 25.8321, Test Loss: 1.5734, Test Accuracy: 23.0878\n",
      "Epoch 143, Loss: 1.7520, Accuracy: 25.8325, Test Loss: 1.5733, Test Accuracy: 23.0866\n",
      "Epoch 144, Loss: 1.7506, Accuracy: 25.8329, Test Loss: 1.5733, Test Accuracy: 23.0855\n",
      "Epoch 145, Loss: 1.7492, Accuracy: 25.8333, Test Loss: 1.5733, Test Accuracy: 23.0843\n",
      "Epoch 146, Loss: 1.7479, Accuracy: 25.8337, Test Loss: 1.5732, Test Accuracy: 23.0831\n",
      "Epoch 147, Loss: 1.7466, Accuracy: 25.8341, Test Loss: 1.5732, Test Accuracy: 23.0820\n",
      "Epoch 148, Loss: 1.7453, Accuracy: 25.8345, Test Loss: 1.5732, Test Accuracy: 23.0809\n",
      "Epoch 149, Loss: 1.7440, Accuracy: 25.8349, Test Loss: 1.5732, Test Accuracy: 23.0798\n",
      "Epoch 150, Loss: 1.7427, Accuracy: 25.8353, Test Loss: 1.5731, Test Accuracy: 23.0787\n",
      "Epoch 151, Loss: 1.7414, Accuracy: 25.8357, Test Loss: 1.5731, Test Accuracy: 23.0776\n",
      "Epoch 152, Loss: 1.7402, Accuracy: 25.8361, Test Loss: 1.5731, Test Accuracy: 23.0766\n",
      "Epoch 153, Loss: 1.7390, Accuracy: 25.8364, Test Loss: 1.5731, Test Accuracy: 23.0755\n",
      "Epoch 154, Loss: 1.7378, Accuracy: 25.8368, Test Loss: 1.5731, Test Accuracy: 23.0745\n",
      "Epoch 155, Loss: 1.7366, Accuracy: 25.8372, Test Loss: 1.5730, Test Accuracy: 23.0735\n",
      "Epoch 156, Loss: 1.7354, Accuracy: 25.8375, Test Loss: 1.5730, Test Accuracy: 23.0725\n",
      "Epoch 157, Loss: 1.7343, Accuracy: 25.8379, Test Loss: 1.5730, Test Accuracy: 23.0715\n",
      "Epoch 158, Loss: 1.7331, Accuracy: 25.8382, Test Loss: 1.5730, Test Accuracy: 23.0705\n",
      "Epoch 159, Loss: 1.7320, Accuracy: 25.8348, Test Loss: 1.5729, Test Accuracy: 23.0695\n",
      "Epoch 160, Loss: 1.7308, Accuracy: 25.8352, Test Loss: 1.5729, Test Accuracy: 23.0686\n",
      "Epoch 161, Loss: 1.7297, Accuracy: 25.8356, Test Loss: 1.5729, Test Accuracy: 23.0676\n",
      "Epoch 162, Loss: 1.7287, Accuracy: 25.8359, Test Loss: 1.5729, Test Accuracy: 23.0667\n",
      "Epoch 163, Loss: 1.7276, Accuracy: 25.8125, Test Loss: 1.5729, Test Accuracy: 23.0658\n",
      "Epoch 164, Loss: 1.7265, Accuracy: 25.8130, Test Loss: 1.5729, Test Accuracy: 23.0649\n",
      "Epoch 165, Loss: 1.7255, Accuracy: 25.8135, Test Loss: 1.5728, Test Accuracy: 23.0640\n",
      "Epoch 166, Loss: 1.7244, Accuracy: 25.8140, Test Loss: 1.5728, Test Accuracy: 23.0631\n",
      "Epoch 167, Loss: 1.7234, Accuracy: 25.8144, Test Loss: 1.5728, Test Accuracy: 23.0622\n",
      "Epoch 168, Loss: 1.7224, Accuracy: 25.8149, Test Loss: 1.5728, Test Accuracy: 23.0613\n",
      "Epoch 169, Loss: 1.7214, Accuracy: 25.8154, Test Loss: 1.5728, Test Accuracy: 23.0605\n",
      "Epoch 170, Loss: 1.7205, Accuracy: 25.8158, Test Loss: 1.5727, Test Accuracy: 23.0596\n",
      "Epoch 171, Loss: 1.7195, Accuracy: 25.8163, Test Loss: 1.5727, Test Accuracy: 23.0588\n",
      "Epoch 172, Loss: 1.7185, Accuracy: 25.8167, Test Loss: 1.5727, Test Accuracy: 23.0580\n",
      "Epoch 173, Loss: 1.7176, Accuracy: 25.8172, Test Loss: 1.5727, Test Accuracy: 23.0572\n",
      "Epoch 174, Loss: 1.7166, Accuracy: 25.8176, Test Loss: 1.5727, Test Accuracy: 23.0564\n",
      "Epoch 175, Loss: 1.7157, Accuracy: 25.8180, Test Loss: 1.5727, Test Accuracy: 23.0556\n",
      "Epoch 176, Loss: 1.7148, Accuracy: 25.8185, Test Loss: 1.5727, Test Accuracy: 23.0548\n",
      "Epoch 177, Loss: 1.7139, Accuracy: 25.8189, Test Loss: 1.5726, Test Accuracy: 23.0540\n",
      "Epoch 178, Loss: 1.7130, Accuracy: 25.8193, Test Loss: 1.5726, Test Accuracy: 23.0532\n",
      "Epoch 179, Loss: 1.7121, Accuracy: 25.8197, Test Loss: 1.5726, Test Accuracy: 23.0525\n",
      "Epoch 180, Loss: 1.7112, Accuracy: 25.8201, Test Loss: 1.5726, Test Accuracy: 23.0517\n",
      "Epoch 181, Loss: 1.7103, Accuracy: 25.8008, Test Loss: 1.5726, Test Accuracy: 23.0510\n",
      "Epoch 182, Loss: 1.7095, Accuracy: 25.8013, Test Loss: 1.5726, Test Accuracy: 23.0502\n",
      "Epoch 183, Loss: 1.7086, Accuracy: 25.8018, Test Loss: 1.5725, Test Accuracy: 23.0495\n",
      "Epoch 184, Loss: 1.7078, Accuracy: 25.8023, Test Loss: 1.5725, Test Accuracy: 23.0488\n",
      "Epoch 185, Loss: 1.7069, Accuracy: 25.8028, Test Loss: 1.5725, Test Accuracy: 23.0480\n",
      "Epoch 186, Loss: 1.7061, Accuracy: 25.8032, Test Loss: 1.5725, Test Accuracy: 23.0473\n",
      "Epoch 187, Loss: 1.7053, Accuracy: 25.8037, Test Loss: 1.5725, Test Accuracy: 23.0466\n",
      "Epoch 188, Loss: 1.7046, Accuracy: 25.8042, Test Loss: 1.5725, Test Accuracy: 23.0460\n",
      "Epoch 189, Loss: 1.7038, Accuracy: 25.8047, Test Loss: 1.5725, Test Accuracy: 23.0453\n",
      "Epoch 190, Loss: 1.7030, Accuracy: 25.8051, Test Loss: 1.5725, Test Accuracy: 23.0446\n",
      "Epoch 191, Loss: 1.7022, Accuracy: 25.8056, Test Loss: 1.5724, Test Accuracy: 23.0439\n",
      "Epoch 192, Loss: 1.7014, Accuracy: 25.8061, Test Loss: 1.5724, Test Accuracy: 23.0433\n",
      "Epoch 193, Loss: 1.7007, Accuracy: 25.8065, Test Loss: 1.5724, Test Accuracy: 23.0426\n",
      "Epoch 194, Loss: 1.6999, Accuracy: 25.8069, Test Loss: 1.5724, Test Accuracy: 23.0420\n",
      "Epoch 195, Loss: 1.6992, Accuracy: 25.8074, Test Loss: 1.5724, Test Accuracy: 23.0413\n",
      "Epoch 196, Loss: 1.6984, Accuracy: 25.8078, Test Loss: 1.5724, Test Accuracy: 23.0407\n",
      "Epoch 197, Loss: 1.6977, Accuracy: 25.8083, Test Loss: 1.5724, Test Accuracy: 23.0400\n",
      "Epoch 198, Loss: 1.6970, Accuracy: 25.8087, Test Loss: 1.5724, Test Accuracy: 23.0394\n",
      "Epoch 199, Loss: 1.6962, Accuracy: 25.8091, Test Loss: 1.5723, Test Accuracy: 23.0388\n",
      "Epoch 200, Loss: 1.6955, Accuracy: 25.8095, Test Loss: 1.5723, Test Accuracy: 23.0382\n",
      "average of 6 each\n",
      "Epoch 1, Loss: 27.7637, Accuracy: 19.6429, Test Loss: 1.5951, Test Accuracy: 19.1667\n",
      "Epoch 2, Loss: 20.4529, Accuracy: 18.9286, Test Loss: 1.5965, Test Accuracy: 22.0833\n",
      "Epoch 3, Loss: 15.7167, Accuracy: 21.7857, Test Loss: 1.5979, Test Accuracy: 23.0556\n",
      "Epoch 4, Loss: 12.5563, Accuracy: 23.7500, Test Loss: 1.5997, Test Accuracy: 23.5417\n",
      "Epoch 5, Loss: 10.4236, Accuracy: 25.2143, Test Loss: 1.6005, Test Accuracy: 23.8333\n",
      "Epoch 6, Loss: 8.9778, Accuracy: 25.0595, Test Loss: 1.6009, Test Accuracy: 24.0278\n",
      "Epoch 7, Loss: 7.9242, Accuracy: 25.5612, Test Loss: 1.6009, Test Accuracy: 24.1667\n",
      "Epoch 8, Loss: 7.1373, Accuracy: 25.6250, Test Loss: 1.6007, Test Accuracy: 24.2708\n",
      "Epoch 9, Loss: 6.5247, Accuracy: 25.5556, Test Loss: 1.6004, Test Accuracy: 24.3519\n",
      "Epoch 10, Loss: 6.0319, Accuracy: 25.6429, Test Loss: 1.5999, Test Accuracy: 24.4167\n",
      "Epoch 11, Loss: 5.6313, Accuracy: 25.6494, Test Loss: 1.5994, Test Accuracy: 24.4697\n",
      "Epoch 12, Loss: 5.2989, Accuracy: 25.6250, Test Loss: 1.5989, Test Accuracy: 24.5139\n",
      "Epoch 13, Loss: 5.0137, Accuracy: 25.6319, Test Loss: 1.5983, Test Accuracy: 24.5513\n",
      "Epoch 14, Loss: 4.7686, Accuracy: 25.6633, Test Loss: 1.5977, Test Accuracy: 24.5833\n",
      "Epoch 15, Loss: 4.5590, Accuracy: 25.6905, Test Loss: 1.5971, Test Accuracy: 24.6111\n",
      "Epoch 16, Loss: 4.3740, Accuracy: 25.7366, Test Loss: 1.5965, Test Accuracy: 24.6354\n",
      "Epoch 17, Loss: 4.2109, Accuracy: 25.6513, Test Loss: 1.5959, Test Accuracy: 24.6569\n",
      "Epoch 18, Loss: 4.0653, Accuracy: 25.6349, Test Loss: 1.5952, Test Accuracy: 24.6759\n",
      "Epoch 19, Loss: 3.9346, Accuracy: 25.6579, Test Loss: 1.5946, Test Accuracy: 24.6930\n",
      "Epoch 20, Loss: 3.8181, Accuracy: 25.6429, Test Loss: 1.5940, Test Accuracy: 24.7083\n",
      "Epoch 21, Loss: 3.7133, Accuracy: 25.6803, Test Loss: 1.5934, Test Accuracy: 24.7222\n",
      "Epoch 22, Loss: 3.6164, Accuracy: 25.6818, Test Loss: 1.5927, Test Accuracy: 24.7348\n",
      "Epoch 23, Loss: 3.5286, Accuracy: 25.6366, Test Loss: 1.5921, Test Accuracy: 24.7464\n",
      "Epoch 24, Loss: 3.4473, Accuracy: 25.6548, Test Loss: 1.5915, Test Accuracy: 24.7569\n",
      "Epoch 25, Loss: 3.3729, Accuracy: 25.6000, Test Loss: 1.5909, Test Accuracy: 24.7667\n",
      "Epoch 26, Loss: 3.3039, Accuracy: 25.6181, Test Loss: 1.5903, Test Accuracy: 24.7756\n",
      "Epoch 27, Loss: 3.2397, Accuracy: 25.6217, Test Loss: 1.5897, Test Accuracy: 24.7840\n",
      "Epoch 28, Loss: 3.1812, Accuracy: 25.5995, Test Loss: 1.5891, Test Accuracy: 24.7917\n",
      "Epoch 29, Loss: 3.1259, Accuracy: 25.6034, Test Loss: 1.5886, Test Accuracy: 24.7989\n",
      "Epoch 30, Loss: 3.0748, Accuracy: 25.5952, Test Loss: 1.5880, Test Accuracy: 24.8056\n",
      "Epoch 31, Loss: 3.0265, Accuracy: 25.5760, Test Loss: 1.5874, Test Accuracy: 24.8118\n",
      "Epoch 32, Loss: 2.9808, Accuracy: 25.5915, Test Loss: 1.5869, Test Accuracy: 24.8177\n",
      "Epoch 33, Loss: 2.9380, Accuracy: 25.5952, Test Loss: 1.5864, Test Accuracy: 24.8232\n",
      "Epoch 34, Loss: 2.8978, Accuracy: 25.5987, Test Loss: 1.5858, Test Accuracy: 24.8284\n",
      "Epoch 35, Loss: 2.8602, Accuracy: 25.5816, Test Loss: 1.5853, Test Accuracy: 24.8333\n",
      "Epoch 36, Loss: 2.8261, Accuracy: 25.5754, Test Loss: 1.5848, Test Accuracy: 24.8380\n",
      "Epoch 37, Loss: 2.7921, Accuracy: 25.5888, Test Loss: 1.5843, Test Accuracy: 24.8423\n",
      "Epoch 38, Loss: 2.7607, Accuracy: 25.5827, Test Loss: 1.5838, Test Accuracy: 24.8465\n",
      "Epoch 39, Loss: 2.7309, Accuracy: 25.6136, Test Loss: 1.5833, Test Accuracy: 24.8504\n",
      "Epoch 40, Loss: 2.7024, Accuracy: 25.5893, Test Loss: 1.5828, Test Accuracy: 24.8542\n",
      "Epoch 41, Loss: 2.6752, Accuracy: 25.5836, Test Loss: 1.5823, Test Accuracy: 24.8577\n",
      "Epoch 42, Loss: 2.6490, Accuracy: 25.5697, Test Loss: 1.5819, Test Accuracy: 24.8611\n",
      "Epoch 43, Loss: 2.6240, Accuracy: 25.5565, Test Loss: 1.5814, Test Accuracy: 24.8643\n",
      "Epoch 44, Loss: 2.6001, Accuracy: 25.5438, Test Loss: 1.5809, Test Accuracy: 24.8674\n",
      "Epoch 45, Loss: 2.5773, Accuracy: 25.5317, Test Loss: 1.5805, Test Accuracy: 24.8704\n",
      "Epoch 46, Loss: 2.5556, Accuracy: 25.5202, Test Loss: 1.5801, Test Accuracy: 24.8732\n",
      "Epoch 47, Loss: 2.5346, Accuracy: 25.5167, Test Loss: 1.5796, Test Accuracy: 24.8759\n",
      "Epoch 48, Loss: 2.5145, Accuracy: 25.5208, Test Loss: 1.5792, Test Accuracy: 24.8785\n",
      "Epoch 49, Loss: 2.4952, Accuracy: 25.5102, Test Loss: 1.5788, Test Accuracy: 24.8810\n",
      "Epoch 50, Loss: 2.4766, Accuracy: 25.5143, Test Loss: 1.5784, Test Accuracy: 24.8833\n",
      "Epoch 51, Loss: 2.4586, Accuracy: 25.5182, Test Loss: 1.5780, Test Accuracy: 24.8856\n",
      "Epoch 52, Loss: 2.4433, Accuracy: 25.5151, Test Loss: 1.5776, Test Accuracy: 24.8878\n",
      "Epoch 53, Loss: 2.4266, Accuracy: 25.5189, Test Loss: 1.5772, Test Accuracy: 24.8899\n",
      "Epoch 54, Loss: 2.4109, Accuracy: 25.5159, Test Loss: 1.5768, Test Accuracy: 24.8920\n",
      "Epoch 55, Loss: 2.3957, Accuracy: 25.5065, Test Loss: 1.5764, Test Accuracy: 24.8939\n",
      "Epoch 56, Loss: 2.3809, Accuracy: 25.4974, Test Loss: 1.5761, Test Accuracy: 24.8958\n",
      "Epoch 57, Loss: 2.3667, Accuracy: 25.4887, Test Loss: 1.5757, Test Accuracy: 24.8977\n",
      "Epoch 58, Loss: 2.3529, Accuracy: 25.4865, Test Loss: 1.5754, Test Accuracy: 24.8994\n",
      "Epoch 59, Loss: 2.3395, Accuracy: 25.4782, Test Loss: 1.5752, Test Accuracy: 24.9011\n",
      "Epoch 60, Loss: 2.3285, Accuracy: 25.4762, Test Loss: 1.5749, Test Accuracy: 24.9028\n",
      "Epoch 61, Loss: 2.3160, Accuracy: 25.4684, Test Loss: 1.5745, Test Accuracy: 24.9044\n",
      "Epoch 62, Loss: 2.3039, Accuracy: 25.4666, Test Loss: 1.5742, Test Accuracy: 24.9059\n",
      "Epoch 63, Loss: 2.2923, Accuracy: 25.4592, Test Loss: 1.5739, Test Accuracy: 24.9074\n",
      "Epoch 64, Loss: 2.2810, Accuracy: 25.4576, Test Loss: 1.5735, Test Accuracy: 24.9089\n",
      "Epoch 65, Loss: 2.2700, Accuracy: 25.4505, Test Loss: 1.5732, Test Accuracy: 24.9103\n",
      "Epoch 66, Loss: 2.2595, Accuracy: 25.4437, Test Loss: 1.5729, Test Accuracy: 24.9116\n",
      "Epoch 67, Loss: 2.2491, Accuracy: 25.4424, Test Loss: 1.5726, Test Accuracy: 24.9129\n",
      "Epoch 68, Loss: 2.2391, Accuracy: 25.4412, Test Loss: 1.5723, Test Accuracy: 24.9142\n",
      "Epoch 69, Loss: 2.2292, Accuracy: 25.4555, Test Loss: 1.5720, Test Accuracy: 24.9155\n",
      "Epoch 70, Loss: 2.2199, Accuracy: 25.4388, Test Loss: 1.5717, Test Accuracy: 24.9167\n",
      "Epoch 71, Loss: 2.2108, Accuracy: 25.4326, Test Loss: 1.5714, Test Accuracy: 24.9178\n",
      "Epoch 72, Loss: 2.2018, Accuracy: 25.4315, Test Loss: 1.5712, Test Accuracy: 24.9190\n",
      "Epoch 73, Loss: 2.1931, Accuracy: 25.4256, Test Loss: 1.5709, Test Accuracy: 24.9201\n",
      "Epoch 74, Loss: 2.1847, Accuracy: 25.4151, Test Loss: 1.5706, Test Accuracy: 24.9212\n",
      "Epoch 75, Loss: 2.1765, Accuracy: 25.4095, Test Loss: 1.5703, Test Accuracy: 24.9222\n",
      "Epoch 76, Loss: 2.1685, Accuracy: 25.4088, Test Loss: 1.5701, Test Accuracy: 24.9232\n",
      "Epoch 77, Loss: 2.1606, Accuracy: 25.4082, Test Loss: 1.5698, Test Accuracy: 24.9242\n",
      "Epoch 78, Loss: 2.1530, Accuracy: 25.4075, Test Loss: 1.5696, Test Accuracy: 24.9252\n",
      "Epoch 79, Loss: 2.1457, Accuracy: 25.4069, Test Loss: 1.5693, Test Accuracy: 24.9262\n",
      "Epoch 80, Loss: 2.1383, Accuracy: 25.4152, Test Loss: 1.5691, Test Accuracy: 24.9271\n",
      "Epoch 81, Loss: 2.1316, Accuracy: 25.4189, Test Loss: 1.5688, Test Accuracy: 24.9280\n",
      "Epoch 82, Loss: 2.1247, Accuracy: 25.4138, Test Loss: 1.5686, Test Accuracy: 24.9289\n",
      "Epoch 83, Loss: 2.1180, Accuracy: 25.4174, Test Loss: 1.5684, Test Accuracy: 24.9297\n",
      "Epoch 84, Loss: 2.1114, Accuracy: 25.4124, Test Loss: 1.5681, Test Accuracy: 24.9306\n",
      "Epoch 85, Loss: 2.1050, Accuracy: 25.4118, Test Loss: 1.5679, Test Accuracy: 24.9314\n",
      "Epoch 86, Loss: 2.0988, Accuracy: 25.4111, Test Loss: 1.5677, Test Accuracy: 24.9322\n",
      "Epoch 87, Loss: 2.0926, Accuracy: 25.4064, Test Loss: 1.5675, Test Accuracy: 24.9330\n",
      "Epoch 88, Loss: 2.0867, Accuracy: 25.4018, Test Loss: 1.5672, Test Accuracy: 24.9337\n",
      "Epoch 89, Loss: 2.0808, Accuracy: 25.3973, Test Loss: 1.5670, Test Accuracy: 24.9345\n",
      "Epoch 90, Loss: 2.0751, Accuracy: 25.3929, Test Loss: 1.5668, Test Accuracy: 24.9352\n",
      "Epoch 91, Loss: 2.0696, Accuracy: 25.3885, Test Loss: 1.5666, Test Accuracy: 24.9359\n",
      "Epoch 92, Loss: 2.0641, Accuracy: 25.3882, Test Loss: 1.5664, Test Accuracy: 24.9366\n",
      "Epoch 93, Loss: 2.0587, Accuracy: 25.3840, Test Loss: 1.5662, Test Accuracy: 24.9373\n",
      "Epoch 94, Loss: 2.0535, Accuracy: 25.3837, Test Loss: 1.5660, Test Accuracy: 24.9379\n",
      "Epoch 95, Loss: 2.0486, Accuracy: 25.3835, Test Loss: 1.5658, Test Accuracy: 24.9386\n",
      "Epoch 96, Loss: 2.0436, Accuracy: 25.3795, Test Loss: 1.5656, Test Accuracy: 24.9392\n",
      "Epoch 97, Loss: 2.0388, Accuracy: 25.3719, Test Loss: 1.5654, Test Accuracy: 24.9399\n",
      "Epoch 98, Loss: 2.0340, Accuracy: 25.3681, Test Loss: 1.5652, Test Accuracy: 24.9405\n",
      "Epoch 99, Loss: 2.0292, Accuracy: 25.3644, Test Loss: 1.5651, Test Accuracy: 24.9411\n",
      "Epoch 100, Loss: 2.0246, Accuracy: 25.3607, Test Loss: 1.5649, Test Accuracy: 24.9417\n",
      "Epoch 101, Loss: 2.0201, Accuracy: 25.3571, Test Loss: 1.5647, Test Accuracy: 24.9422\n",
      "Epoch 102, Loss: 2.0156, Accuracy: 25.3536, Test Loss: 1.5645, Test Accuracy: 24.9428\n",
      "Epoch 103, Loss: 2.0112, Accuracy: 25.3502, Test Loss: 1.5644, Test Accuracy: 24.9434\n",
      "Epoch 104, Loss: 2.0076, Accuracy: 25.3468, Test Loss: 1.5642, Test Accuracy: 24.9439\n",
      "Epoch 105, Loss: 2.0034, Accuracy: 25.3435, Test Loss: 1.5640, Test Accuracy: 24.9444\n",
      "Epoch 106, Loss: 1.9993, Accuracy: 25.3437, Test Loss: 1.5639, Test Accuracy: 24.9450\n",
      "Epoch 107, Loss: 1.9952, Accuracy: 25.3405, Test Loss: 1.5637, Test Accuracy: 24.9455\n",
      "Epoch 108, Loss: 1.9913, Accuracy: 25.3373, Test Loss: 1.5635, Test Accuracy: 24.9460\n",
      "Epoch 109, Loss: 1.9873, Accuracy: 25.3342, Test Loss: 1.5634, Test Accuracy: 24.9465\n",
      "Epoch 110, Loss: 1.9835, Accuracy: 25.3312, Test Loss: 1.5632, Test Accuracy: 24.9470\n",
      "Epoch 111, Loss: 1.9797, Accuracy: 25.3282, Test Loss: 1.5631, Test Accuracy: 24.9474\n",
      "Epoch 112, Loss: 1.9760, Accuracy: 25.3284, Test Loss: 1.5629, Test Accuracy: 24.9479\n",
      "Epoch 113, Loss: 1.9725, Accuracy: 25.3255, Test Loss: 1.5628, Test Accuracy: 24.9484\n",
      "Epoch 114, Loss: 1.9690, Accuracy: 25.3227, Test Loss: 1.5626, Test Accuracy: 24.9488\n",
      "Epoch 115, Loss: 1.9655, Accuracy: 25.3199, Test Loss: 1.5625, Test Accuracy: 24.9493\n",
      "Epoch 116, Loss: 1.9620, Accuracy: 25.3171, Test Loss: 1.5623, Test Accuracy: 24.9497\n",
      "Epoch 117, Loss: 1.9587, Accuracy: 25.3144, Test Loss: 1.5622, Test Accuracy: 24.9501\n",
      "Epoch 118, Loss: 1.9554, Accuracy: 25.3117, Test Loss: 1.5620, Test Accuracy: 24.9506\n",
      "Epoch 119, Loss: 1.9521, Accuracy: 25.3091, Test Loss: 1.5619, Test Accuracy: 24.9510\n",
      "Epoch 120, Loss: 1.9489, Accuracy: 25.3065, Test Loss: 1.5618, Test Accuracy: 24.9514\n",
      "Epoch 121, Loss: 1.9457, Accuracy: 25.3070, Test Loss: 1.5616, Test Accuracy: 24.9518\n",
      "Epoch 122, Loss: 1.9428, Accuracy: 25.3015, Test Loss: 1.5615, Test Accuracy: 24.9522\n",
      "Epoch 123, Loss: 1.9398, Accuracy: 25.2991, Test Loss: 1.5614, Test Accuracy: 24.9526\n",
      "Epoch 124, Loss: 1.9368, Accuracy: 25.2967, Test Loss: 1.5613, Test Accuracy: 24.9530\n",
      "Epoch 125, Loss: 1.9338, Accuracy: 25.2971, Test Loss: 1.5611, Test Accuracy: 24.9533\n",
      "Epoch 126, Loss: 1.9309, Accuracy: 25.2976, Test Loss: 1.5610, Test Accuracy: 24.9537\n",
      "Epoch 127, Loss: 1.9281, Accuracy: 25.3009, Test Loss: 1.5609, Test Accuracy: 24.9541\n",
      "Epoch 128, Loss: 1.9252, Accuracy: 25.3013, Test Loss: 1.5608, Test Accuracy: 24.9544\n",
      "Epoch 129, Loss: 1.9224, Accuracy: 25.3018, Test Loss: 1.5606, Test Accuracy: 24.9548\n",
      "Epoch 130, Loss: 1.9197, Accuracy: 25.3049, Test Loss: 1.5605, Test Accuracy: 24.9551\n",
      "Epoch 131, Loss: 1.9172, Accuracy: 25.2972, Test Loss: 1.5604, Test Accuracy: 24.9555\n",
      "Epoch 132, Loss: 1.9146, Accuracy: 25.2922, Test Loss: 1.5603, Test Accuracy: 24.9558\n",
      "Epoch 133, Loss: 1.9120, Accuracy: 25.2900, Test Loss: 1.5602, Test Accuracy: 24.9561\n",
      "Epoch 134, Loss: 1.9094, Accuracy: 25.2878, Test Loss: 1.5601, Test Accuracy: 24.9565\n",
      "Epoch 135, Loss: 1.9069, Accuracy: 25.2857, Test Loss: 1.5600, Test Accuracy: 24.9568\n",
      "Epoch 136, Loss: 1.9043, Accuracy: 25.2862, Test Loss: 1.5599, Test Accuracy: 24.9571\n",
      "Epoch 137, Loss: 1.9018, Accuracy: 25.2842, Test Loss: 1.5598, Test Accuracy: 24.9574\n",
      "Epoch 138, Loss: 1.8994, Accuracy: 25.2847, Test Loss: 1.5596, Test Accuracy: 24.9577\n",
      "Epoch 139, Loss: 1.8982, Accuracy: 25.2878, Test Loss: 1.5595, Test Accuracy: 24.9580\n",
      "Epoch 140, Loss: 1.8958, Accuracy: 25.2857, Test Loss: 1.5594, Test Accuracy: 24.9583\n",
      "Epoch 141, Loss: 1.8935, Accuracy: 25.2837, Test Loss: 1.5593, Test Accuracy: 24.9586\n",
      "Epoch 142, Loss: 1.8912, Accuracy: 25.2817, Test Loss: 1.5592, Test Accuracy: 24.9589\n",
      "Epoch 143, Loss: 1.8889, Accuracy: 25.2797, Test Loss: 1.5591, Test Accuracy: 24.9592\n",
      "Epoch 144, Loss: 1.8867, Accuracy: 25.2778, Test Loss: 1.5590, Test Accuracy: 24.9595\n",
      "Epoch 145, Loss: 1.8845, Accuracy: 25.2759, Test Loss: 1.5589, Test Accuracy: 24.9598\n",
      "Epoch 146, Loss: 1.8824, Accuracy: 25.2740, Test Loss: 1.5588, Test Accuracy: 24.9600\n",
      "Epoch 147, Loss: 1.8802, Accuracy: 25.2721, Test Loss: 1.5587, Test Accuracy: 24.9603\n",
      "Epoch 148, Loss: 1.8781, Accuracy: 25.2703, Test Loss: 1.5586, Test Accuracy: 24.9606\n",
      "Epoch 149, Loss: 1.8760, Accuracy: 25.2685, Test Loss: 1.5585, Test Accuracy: 24.9608\n",
      "Epoch 150, Loss: 1.8740, Accuracy: 25.2667, Test Loss: 1.5584, Test Accuracy: 24.9611\n",
      "Epoch 151, Loss: 1.8719, Accuracy: 25.2649, Test Loss: 1.5584, Test Accuracy: 24.9614\n",
      "Epoch 152, Loss: 1.8699, Accuracy: 25.2632, Test Loss: 1.5583, Test Accuracy: 24.9616\n",
      "Epoch 153, Loss: 1.8679, Accuracy: 25.2614, Test Loss: 1.5582, Test Accuracy: 24.9619\n",
      "Epoch 154, Loss: 1.8660, Accuracy: 25.2597, Test Loss: 1.5581, Test Accuracy: 24.9621\n",
      "Epoch 155, Loss: 1.8640, Accuracy: 25.2581, Test Loss: 1.5580, Test Accuracy: 24.9624\n",
      "Epoch 156, Loss: 1.8621, Accuracy: 25.2564, Test Loss: 1.5579, Test Accuracy: 24.9626\n",
      "Epoch 157, Loss: 1.8602, Accuracy: 25.2548, Test Loss: 1.5578, Test Accuracy: 24.9628\n",
      "Epoch 158, Loss: 1.8584, Accuracy: 25.2532, Test Loss: 1.5577, Test Accuracy: 24.9631\n",
      "Epoch 159, Loss: 1.8565, Accuracy: 25.2516, Test Loss: 1.5577, Test Accuracy: 24.9633\n",
      "Epoch 160, Loss: 1.8547, Accuracy: 25.2522, Test Loss: 1.5576, Test Accuracy: 24.9635\n",
      "Epoch 161, Loss: 1.8529, Accuracy: 25.2507, Test Loss: 1.5575, Test Accuracy: 24.9638\n",
      "Epoch 162, Loss: 1.8511, Accuracy: 25.2491, Test Loss: 1.5574, Test Accuracy: 24.9640\n",
      "Epoch 163, Loss: 1.8493, Accuracy: 25.2498, Test Loss: 1.5573, Test Accuracy: 24.9642\n",
      "Epoch 164, Loss: 1.8476, Accuracy: 25.2461, Test Loss: 1.5572, Test Accuracy: 24.9644\n",
      "Epoch 165, Loss: 1.8459, Accuracy: 25.2446, Test Loss: 1.5572, Test Accuracy: 24.9646\n",
      "Epoch 166, Loss: 1.8443, Accuracy: 25.2431, Test Loss: 1.5571, Test Accuracy: 24.9649\n",
      "Epoch 167, Loss: 1.8426, Accuracy: 25.2417, Test Loss: 1.5570, Test Accuracy: 24.9651\n",
      "Epoch 168, Loss: 1.8410, Accuracy: 25.2402, Test Loss: 1.5569, Test Accuracy: 24.9653\n",
      "Epoch 169, Loss: 1.8393, Accuracy: 25.2388, Test Loss: 1.5569, Test Accuracy: 24.9655\n",
      "Epoch 170, Loss: 1.8377, Accuracy: 25.2374, Test Loss: 1.5568, Test Accuracy: 24.9657\n",
      "Epoch 171, Loss: 1.8361, Accuracy: 25.2381, Test Loss: 1.5567, Test Accuracy: 24.9659\n",
      "Epoch 172, Loss: 1.8346, Accuracy: 25.2367, Test Loss: 1.5566, Test Accuracy: 24.9661\n",
      "Epoch 173, Loss: 1.8330, Accuracy: 25.2415, Test Loss: 1.5566, Test Accuracy: 24.9663\n",
      "Epoch 174, Loss: 1.8321, Accuracy: 25.2422, Test Loss: 1.5565, Test Accuracy: 24.9665\n",
      "Epoch 175, Loss: 1.8306, Accuracy: 25.2408, Test Loss: 1.5564, Test Accuracy: 24.9667\n",
      "Epoch 176, Loss: 1.8290, Accuracy: 25.2394, Test Loss: 1.5564, Test Accuracy: 24.9669\n",
      "Epoch 177, Loss: 1.8275, Accuracy: 25.2401, Test Loss: 1.5563, Test Accuracy: 24.9670\n",
      "Epoch 178, Loss: 1.8262, Accuracy: 25.2408, Test Loss: 1.5562, Test Accuracy: 24.9672\n",
      "Epoch 179, Loss: 1.8249, Accuracy: 25.2574, Test Loss: 1.5561, Test Accuracy: 24.9674\n",
      "Epoch 180, Loss: 1.8235, Accuracy: 25.2579, Test Loss: 1.5561, Test Accuracy: 24.9676\n",
      "Epoch 181, Loss: 1.8221, Accuracy: 25.2605, Test Loss: 1.5560, Test Accuracy: 24.9678\n",
      "Epoch 182, Loss: 1.8207, Accuracy: 25.2590, Test Loss: 1.5559, Test Accuracy: 24.9679\n",
      "Epoch 183, Loss: 1.8192, Accuracy: 25.2596, Test Loss: 1.5559, Test Accuracy: 24.9681\n",
      "Epoch 184, Loss: 1.8181, Accuracy: 25.2582, Test Loss: 1.5558, Test Accuracy: 24.9683\n",
      "Epoch 185, Loss: 1.8168, Accuracy: 25.2587, Test Loss: 1.5558, Test Accuracy: 24.9685\n",
      "Epoch 186, Loss: 1.8154, Accuracy: 25.2611, Test Loss: 1.5557, Test Accuracy: 24.9686\n",
      "Epoch 187, Loss: 1.8141, Accuracy: 25.2636, Test Loss: 1.5556, Test Accuracy: 24.9688\n",
      "Epoch 188, Loss: 1.8128, Accuracy: 25.2660, Test Loss: 1.5556, Test Accuracy: 24.9690\n",
      "Epoch 189, Loss: 1.8115, Accuracy: 25.2645, Test Loss: 1.5555, Test Accuracy: 24.9691\n",
      "Epoch 190, Loss: 1.8102, Accuracy: 25.2650, Test Loss: 1.5554, Test Accuracy: 24.9693\n",
      "Epoch 191, Loss: 1.8091, Accuracy: 25.2618, Test Loss: 1.5554, Test Accuracy: 24.9695\n",
      "Epoch 192, Loss: 1.8078, Accuracy: 25.2623, Test Loss: 1.5553, Test Accuracy: 24.9696\n",
      "Epoch 193, Loss: 1.8065, Accuracy: 25.2609, Test Loss: 1.5553, Test Accuracy: 24.9698\n",
      "Epoch 194, Loss: 1.8053, Accuracy: 25.2596, Test Loss: 1.5552, Test Accuracy: 24.9699\n",
      "Epoch 195, Loss: 1.8040, Accuracy: 25.2582, Test Loss: 1.5551, Test Accuracy: 24.9701\n",
      "Epoch 196, Loss: 1.8029, Accuracy: 25.2551, Test Loss: 1.5551, Test Accuracy: 24.9702\n",
      "Epoch 197, Loss: 1.8016, Accuracy: 25.2538, Test Loss: 1.5550, Test Accuracy: 24.9704\n",
      "Epoch 198, Loss: 1.8005, Accuracy: 25.2525, Test Loss: 1.5550, Test Accuracy: 24.9705\n",
      "Epoch 199, Loss: 1.7993, Accuracy: 25.2531, Test Loss: 1.5549, Test Accuracy: 24.9707\n",
      "Epoch 200, Loss: 1.7981, Accuracy: 25.2518, Test Loss: 1.5549, Test Accuracy: 24.9708\n",
      "average of 7 each\n",
      "Epoch 1, Loss: 26.3270, Accuracy: 21.6667, Test Loss: 1.5913, Test Accuracy: 23.0769\n",
      "Epoch 2, Loss: 20.0884, Accuracy: 21.0417, Test Loss: 1.6031, Test Accuracy: 18.2692\n",
      "Epoch 3, Loss: 16.3831, Accuracy: 21.3889, Test Loss: 1.6049, Test Accuracy: 19.5513\n",
      "Epoch 4, Loss: 13.2602, Accuracy: 22.8125, Test Loss: 1.6055, Test Accuracy: 20.1923\n",
      "Epoch 5, Loss: 11.1423, Accuracy: 22.3333, Test Loss: 1.6057, Test Accuracy: 20.5769\n",
      "Epoch 6, Loss: 9.6021, Accuracy: 22.9861, Test Loss: 1.6056, Test Accuracy: 20.8333\n",
      "Epoch 7, Loss: 8.4747, Accuracy: 23.5119, Test Loss: 1.6054, Test Accuracy: 21.0165\n",
      "Epoch 8, Loss: 7.6250, Accuracy: 23.8542, Test Loss: 1.6051, Test Accuracy: 21.1538\n",
      "Epoch 9, Loss: 6.9587, Accuracy: 24.2130, Test Loss: 1.6047, Test Accuracy: 21.2607\n",
      "Epoch 10, Loss: 6.4230, Accuracy: 24.3750, Test Loss: 1.6043, Test Accuracy: 21.3462\n",
      "Epoch 11, Loss: 5.9844, Accuracy: 24.5455, Test Loss: 1.6039, Test Accuracy: 21.4161\n",
      "Epoch 12, Loss: 5.6186, Accuracy: 24.6875, Test Loss: 1.6034, Test Accuracy: 21.4744\n",
      "Epoch 13, Loss: 5.3129, Accuracy: 24.7756, Test Loss: 1.6030, Test Accuracy: 21.5237\n",
      "Epoch 14, Loss: 5.0491, Accuracy: 24.9107, Test Loss: 1.6025, Test Accuracy: 21.5659\n",
      "Epoch 15, Loss: 4.8227, Accuracy: 25.0000, Test Loss: 1.6020, Test Accuracy: 21.6026\n",
      "Epoch 16, Loss: 4.6208, Accuracy: 25.0781, Test Loss: 1.6016, Test Accuracy: 21.6346\n",
      "Epoch 17, Loss: 4.4441, Accuracy: 25.1226, Test Loss: 1.6011, Test Accuracy: 21.6629\n",
      "Epoch 18, Loss: 4.2869, Accuracy: 25.2083, Test Loss: 1.6006, Test Accuracy: 21.6880\n",
      "Epoch 19, Loss: 4.1466, Accuracy: 25.2412, Test Loss: 1.6002, Test Accuracy: 21.7105\n",
      "Epoch 20, Loss: 4.0183, Accuracy: 25.3125, Test Loss: 1.5997, Test Accuracy: 21.7308\n",
      "Epoch 21, Loss: 3.9024, Accuracy: 25.3571, Test Loss: 1.5993, Test Accuracy: 21.7491\n",
      "Epoch 22, Loss: 3.7967, Accuracy: 25.3977, Test Loss: 1.5989, Test Accuracy: 21.7657\n",
      "Epoch 23, Loss: 3.7004, Accuracy: 25.4348, Test Loss: 1.5984, Test Accuracy: 21.7809\n",
      "Epoch 24, Loss: 3.6121, Accuracy: 25.4687, Test Loss: 1.5980, Test Accuracy: 21.7949\n",
      "Epoch 25, Loss: 3.5342, Accuracy: 25.5167, Test Loss: 1.5976, Test Accuracy: 21.8077\n",
      "Epoch 26, Loss: 3.4590, Accuracy: 25.5449, Test Loss: 1.5972, Test Accuracy: 21.8195\n",
      "Epoch 27, Loss: 3.3899, Accuracy: 25.5710, Test Loss: 1.5968, Test Accuracy: 21.8305\n",
      "Epoch 28, Loss: 3.3250, Accuracy: 25.6101, Test Loss: 1.5964, Test Accuracy: 21.8407\n",
      "Epoch 29, Loss: 3.2671, Accuracy: 25.6322, Test Loss: 1.5960, Test Accuracy: 21.8501\n",
      "Epoch 30, Loss: 3.2114, Accuracy: 25.6667, Test Loss: 1.5956, Test Accuracy: 21.8590\n",
      "Epoch 31, Loss: 3.1584, Accuracy: 25.6989, Test Loss: 1.5952, Test Accuracy: 21.8672\n",
      "Epoch 32, Loss: 3.1091, Accuracy: 25.7422, Test Loss: 1.5949, Test Accuracy: 21.8750\n",
      "Epoch 33, Loss: 3.0639, Accuracy: 25.7576, Test Loss: 1.5945, Test Accuracy: 21.8823\n",
      "Epoch 34, Loss: 3.0212, Accuracy: 25.7721, Test Loss: 1.5942, Test Accuracy: 21.8891\n",
      "Epoch 35, Loss: 2.9798, Accuracy: 25.7857, Test Loss: 1.5938, Test Accuracy: 21.8956\n",
      "Epoch 36, Loss: 2.9407, Accuracy: 25.7986, Test Loss: 1.5935, Test Accuracy: 21.9017\n",
      "Epoch 37, Loss: 2.9036, Accuracy: 25.8108, Test Loss: 1.5931, Test Accuracy: 21.9075\n",
      "Epoch 38, Loss: 2.8687, Accuracy: 25.8224, Test Loss: 1.5928, Test Accuracy: 21.9130\n",
      "Epoch 39, Loss: 2.8354, Accuracy: 25.8333, Test Loss: 1.5925, Test Accuracy: 21.9181\n",
      "Epoch 40, Loss: 2.8039, Accuracy: 25.8542, Test Loss: 1.5922, Test Accuracy: 21.9231\n",
      "Epoch 41, Loss: 2.7738, Accuracy: 25.8638, Test Loss: 1.5919, Test Accuracy: 21.9278\n",
      "Epoch 42, Loss: 2.7451, Accuracy: 25.8730, Test Loss: 1.5916, Test Accuracy: 21.9322\n",
      "Epoch 43, Loss: 2.7177, Accuracy: 25.8818, Test Loss: 1.5913, Test Accuracy: 21.9365\n",
      "Epoch 44, Loss: 2.6915, Accuracy: 25.8902, Test Loss: 1.5910, Test Accuracy: 21.9406\n",
      "Epoch 45, Loss: 2.6665, Accuracy: 25.8981, Test Loss: 1.5908, Test Accuracy: 21.9444\n",
      "Epoch 46, Loss: 2.6426, Accuracy: 25.9058, Test Loss: 1.5905, Test Accuracy: 21.9482\n",
      "Epoch 47, Loss: 2.6196, Accuracy: 25.9220, Test Loss: 1.5902, Test Accuracy: 21.9517\n",
      "Epoch 48, Loss: 2.5977, Accuracy: 25.9288, Test Loss: 1.5900, Test Accuracy: 21.9551\n",
      "Epoch 49, Loss: 2.5765, Accuracy: 25.9354, Test Loss: 1.5897, Test Accuracy: 21.9584\n",
      "Epoch 50, Loss: 2.5562, Accuracy: 25.9417, Test Loss: 1.5895, Test Accuracy: 21.9615\n",
      "Epoch 51, Loss: 2.5366, Accuracy: 25.9477, Test Loss: 1.5892, Test Accuracy: 21.9646\n",
      "Epoch 52, Loss: 2.5179, Accuracy: 25.9535, Test Loss: 1.5890, Test Accuracy: 21.9675\n",
      "Epoch 53, Loss: 2.4998, Accuracy: 25.9591, Test Loss: 1.5888, Test Accuracy: 21.9702\n",
      "Epoch 54, Loss: 2.4825, Accuracy: 25.9645, Test Loss: 1.5885, Test Accuracy: 21.9729\n",
      "Epoch 55, Loss: 2.4657, Accuracy: 25.9697, Test Loss: 1.5883, Test Accuracy: 21.9755\n",
      "Epoch 56, Loss: 2.4495, Accuracy: 25.9747, Test Loss: 1.5881, Test Accuracy: 21.9780\n",
      "Epoch 57, Loss: 2.4342, Accuracy: 25.9868, Test Loss: 1.5879, Test Accuracy: 21.9804\n",
      "Epoch 58, Loss: 2.4203, Accuracy: 25.9914, Test Loss: 1.5877, Test Accuracy: 21.9828\n",
      "Epoch 59, Loss: 2.4057, Accuracy: 26.0028, Test Loss: 1.5875, Test Accuracy: 21.9850\n",
      "Epoch 60, Loss: 2.3917, Accuracy: 26.0069, Test Loss: 1.5873, Test Accuracy: 21.9872\n",
      "Epoch 61, Loss: 2.3781, Accuracy: 26.0109, Test Loss: 1.5871, Test Accuracy: 21.9893\n",
      "Epoch 62, Loss: 2.3649, Accuracy: 26.0148, Test Loss: 1.5869, Test Accuracy: 21.9913\n",
      "Epoch 63, Loss: 2.3521, Accuracy: 26.0185, Test Loss: 1.5867, Test Accuracy: 21.9933\n",
      "Epoch 64, Loss: 2.3397, Accuracy: 26.0221, Test Loss: 1.5866, Test Accuracy: 21.9952\n",
      "Epoch 65, Loss: 2.3277, Accuracy: 26.0256, Test Loss: 1.5864, Test Accuracy: 21.9970\n",
      "Epoch 66, Loss: 2.3160, Accuracy: 26.0290, Test Loss: 1.5862, Test Accuracy: 21.9988\n",
      "Epoch 67, Loss: 2.3048, Accuracy: 26.0323, Test Loss: 1.5860, Test Accuracy: 22.0006\n",
      "Epoch 68, Loss: 2.2937, Accuracy: 26.0355, Test Loss: 1.5859, Test Accuracy: 22.0023\n",
      "Epoch 69, Loss: 2.2836, Accuracy: 26.0326, Test Loss: 1.5857, Test Accuracy: 22.0039\n",
      "Epoch 70, Loss: 2.2735, Accuracy: 26.0357, Test Loss: 1.5856, Test Accuracy: 22.0055\n",
      "Epoch 71, Loss: 2.2633, Accuracy: 26.0446, Test Loss: 1.5854, Test Accuracy: 22.0070\n",
      "Epoch 72, Loss: 2.2536, Accuracy: 26.0475, Test Loss: 1.5853, Test Accuracy: 22.0085\n",
      "Epoch 73, Loss: 2.2440, Accuracy: 26.0502, Test Loss: 1.5851, Test Accuracy: 22.0100\n",
      "Epoch 74, Loss: 2.2347, Accuracy: 26.0529, Test Loss: 1.5850, Test Accuracy: 22.0114\n",
      "Epoch 75, Loss: 2.2257, Accuracy: 26.0556, Test Loss: 1.5848, Test Accuracy: 22.0128\n",
      "Epoch 76, Loss: 2.2168, Accuracy: 26.0581, Test Loss: 1.5847, Test Accuracy: 22.0142\n",
      "Epoch 77, Loss: 2.2082, Accuracy: 26.0606, Test Loss: 1.5846, Test Accuracy: 22.0155\n",
      "Epoch 78, Loss: 2.2007, Accuracy: 26.0630, Test Loss: 1.5844, Test Accuracy: 22.0168\n",
      "Epoch 79, Loss: 2.1926, Accuracy: 26.0654, Test Loss: 1.5843, Test Accuracy: 22.0180\n",
      "Epoch 80, Loss: 2.1847, Accuracy: 26.0677, Test Loss: 1.5842, Test Accuracy: 22.0192\n",
      "Epoch 81, Loss: 2.1768, Accuracy: 26.0751, Test Loss: 1.5841, Test Accuracy: 22.0204\n",
      "Epoch 82, Loss: 2.1692, Accuracy: 26.0772, Test Loss: 1.5839, Test Accuracy: 22.0216\n",
      "Epoch 83, Loss: 2.1618, Accuracy: 26.0793, Test Loss: 1.5838, Test Accuracy: 22.0227\n",
      "Epoch 84, Loss: 2.1547, Accuracy: 26.0814, Test Loss: 1.5837, Test Accuracy: 22.0238\n",
      "Epoch 85, Loss: 2.1477, Accuracy: 26.0833, Test Loss: 1.5836, Test Accuracy: 22.0249\n",
      "Epoch 86, Loss: 2.1408, Accuracy: 26.0853, Test Loss: 1.5835, Test Accuracy: 22.0259\n",
      "Epoch 87, Loss: 2.1341, Accuracy: 26.0872, Test Loss: 1.5834, Test Accuracy: 22.0270\n",
      "Epoch 88, Loss: 2.1274, Accuracy: 26.0938, Test Loss: 1.5833, Test Accuracy: 22.0280\n",
      "Epoch 89, Loss: 2.1211, Accuracy: 26.0955, Test Loss: 1.5832, Test Accuracy: 22.0290\n",
      "Epoch 90, Loss: 2.1148, Accuracy: 26.0972, Test Loss: 1.5831, Test Accuracy: 22.0299\n",
      "Epoch 91, Loss: 2.1094, Accuracy: 26.0989, Test Loss: 1.5830, Test Accuracy: 22.0309\n",
      "Epoch 92, Loss: 2.1035, Accuracy: 26.1005, Test Loss: 1.5829, Test Accuracy: 22.0318\n",
      "Epoch 93, Loss: 2.0976, Accuracy: 26.1021, Test Loss: 1.5828, Test Accuracy: 22.0327\n",
      "Epoch 94, Loss: 2.0918, Accuracy: 26.1037, Test Loss: 1.5827, Test Accuracy: 22.0336\n",
      "Epoch 95, Loss: 2.0862, Accuracy: 26.1053, Test Loss: 1.5826, Test Accuracy: 22.0344\n",
      "Epoch 96, Loss: 2.0807, Accuracy: 26.1068, Test Loss: 1.5825, Test Accuracy: 22.0353\n",
      "Epoch 97, Loss: 2.0752, Accuracy: 26.1082, Test Loss: 1.5825, Test Accuracy: 22.0361\n",
      "Epoch 98, Loss: 2.0699, Accuracy: 26.1097, Test Loss: 1.5824, Test Accuracy: 22.0369\n",
      "Epoch 99, Loss: 2.0650, Accuracy: 26.1111, Test Loss: 1.5823, Test Accuracy: 22.0377\n",
      "Epoch 100, Loss: 2.0599, Accuracy: 26.1125, Test Loss: 1.5822, Test Accuracy: 22.0385\n",
      "Epoch 101, Loss: 2.0550, Accuracy: 26.1139, Test Loss: 1.5821, Test Accuracy: 22.0392\n",
      "Epoch 102, Loss: 2.0500, Accuracy: 26.1152, Test Loss: 1.5821, Test Accuracy: 22.0400\n",
      "Epoch 103, Loss: 2.0452, Accuracy: 26.1165, Test Loss: 1.5820, Test Accuracy: 22.0407\n",
      "Epoch 104, Loss: 2.0405, Accuracy: 26.1178, Test Loss: 1.5819, Test Accuracy: 22.0414\n",
      "Epoch 105, Loss: 2.0358, Accuracy: 26.1190, Test Loss: 1.5818, Test Accuracy: 22.0421\n",
      "Epoch 106, Loss: 2.0312, Accuracy: 26.1203, Test Loss: 1.5818, Test Accuracy: 22.0428\n",
      "Epoch 107, Loss: 2.0268, Accuracy: 26.1215, Test Loss: 1.5817, Test Accuracy: 22.0435\n",
      "Epoch 108, Loss: 2.0224, Accuracy: 26.1227, Test Loss: 1.5816, Test Accuracy: 22.0442\n",
      "Epoch 109, Loss: 2.0182, Accuracy: 26.1239, Test Loss: 1.5816, Test Accuracy: 22.0448\n",
      "Epoch 110, Loss: 2.0140, Accuracy: 26.1250, Test Loss: 1.5815, Test Accuracy: 22.0455\n",
      "Epoch 111, Loss: 2.0098, Accuracy: 26.1261, Test Loss: 1.5814, Test Accuracy: 22.0461\n",
      "Epoch 112, Loss: 2.0057, Accuracy: 26.1272, Test Loss: 1.5814, Test Accuracy: 22.0467\n",
      "Epoch 113, Loss: 2.0017, Accuracy: 26.1283, Test Loss: 1.5813, Test Accuracy: 22.0473\n",
      "Epoch 114, Loss: 1.9977, Accuracy: 26.1294, Test Loss: 1.5813, Test Accuracy: 22.0479\n",
      "Epoch 115, Loss: 1.9938, Accuracy: 26.1304, Test Loss: 1.5812, Test Accuracy: 22.0485\n",
      "Epoch 116, Loss: 1.9900, Accuracy: 26.1315, Test Loss: 1.5811, Test Accuracy: 22.0491\n",
      "Epoch 117, Loss: 1.9863, Accuracy: 26.1325, Test Loss: 1.5811, Test Accuracy: 22.0496\n",
      "Epoch 118, Loss: 1.9826, Accuracy: 26.1335, Test Loss: 1.5810, Test Accuracy: 22.0502\n",
      "Epoch 119, Loss: 1.9789, Accuracy: 26.1345, Test Loss: 1.5810, Test Accuracy: 22.0507\n",
      "Epoch 120, Loss: 1.9753, Accuracy: 26.1354, Test Loss: 1.5809, Test Accuracy: 22.0513\n",
      "Epoch 121, Loss: 1.9718, Accuracy: 26.1364, Test Loss: 1.5809, Test Accuracy: 22.0518\n",
      "Epoch 122, Loss: 1.9683, Accuracy: 26.1373, Test Loss: 1.5808, Test Accuracy: 22.0523\n",
      "Epoch 123, Loss: 1.9650, Accuracy: 26.1382, Test Loss: 1.5808, Test Accuracy: 22.0528\n",
      "Epoch 124, Loss: 1.9616, Accuracy: 26.1391, Test Loss: 1.5807, Test Accuracy: 22.0534\n",
      "Epoch 125, Loss: 1.9584, Accuracy: 26.1400, Test Loss: 1.5807, Test Accuracy: 22.0538\n",
      "Epoch 126, Loss: 1.9551, Accuracy: 26.1409, Test Loss: 1.5806, Test Accuracy: 22.0543\n",
      "Epoch 127, Loss: 1.9519, Accuracy: 26.1417, Test Loss: 1.5806, Test Accuracy: 22.0548\n",
      "Epoch 128, Loss: 1.9488, Accuracy: 26.1426, Test Loss: 1.5806, Test Accuracy: 22.0553\n",
      "Epoch 129, Loss: 1.9457, Accuracy: 26.1434, Test Loss: 1.5805, Test Accuracy: 22.0558\n",
      "Epoch 130, Loss: 1.9426, Accuracy: 26.1442, Test Loss: 1.5805, Test Accuracy: 22.0562\n",
      "Epoch 131, Loss: 1.9396, Accuracy: 26.1450, Test Loss: 1.5804, Test Accuracy: 22.0567\n",
      "Epoch 132, Loss: 1.9366, Accuracy: 26.1458, Test Loss: 1.5804, Test Accuracy: 22.0571\n",
      "Epoch 133, Loss: 1.9337, Accuracy: 26.1466, Test Loss: 1.5804, Test Accuracy: 22.0575\n",
      "Epoch 134, Loss: 1.9310, Accuracy: 26.1474, Test Loss: 1.5803, Test Accuracy: 22.0580\n",
      "Epoch 135, Loss: 1.9282, Accuracy: 26.1481, Test Loss: 1.5803, Test Accuracy: 22.0584\n",
      "Epoch 136, Loss: 1.9254, Accuracy: 26.1489, Test Loss: 1.5802, Test Accuracy: 22.0588\n",
      "Epoch 137, Loss: 1.9227, Accuracy: 26.1496, Test Loss: 1.5802, Test Accuracy: 22.0592\n",
      "Epoch 138, Loss: 1.9200, Accuracy: 26.1504, Test Loss: 1.5802, Test Accuracy: 22.0596\n",
      "Epoch 139, Loss: 1.9173, Accuracy: 26.1511, Test Loss: 1.5801, Test Accuracy: 22.0600\n",
      "Epoch 140, Loss: 1.9147, Accuracy: 26.1518, Test Loss: 1.5801, Test Accuracy: 22.0604\n",
      "Epoch 141, Loss: 1.9122, Accuracy: 26.1525, Test Loss: 1.5801, Test Accuracy: 22.0608\n",
      "Epoch 142, Loss: 1.9096, Accuracy: 26.1532, Test Loss: 1.5800, Test Accuracy: 22.0612\n",
      "Epoch 143, Loss: 1.9072, Accuracy: 26.1538, Test Loss: 1.5800, Test Accuracy: 22.0616\n",
      "Epoch 144, Loss: 1.9046, Accuracy: 26.1545, Test Loss: 1.5800, Test Accuracy: 22.0620\n",
      "Epoch 145, Loss: 1.9022, Accuracy: 26.1552, Test Loss: 1.5800, Test Accuracy: 22.0623\n",
      "Epoch 146, Loss: 1.8998, Accuracy: 26.1558, Test Loss: 1.5799, Test Accuracy: 22.0627\n",
      "Epoch 147, Loss: 1.8974, Accuracy: 26.1565, Test Loss: 1.5799, Test Accuracy: 22.0631\n",
      "Epoch 148, Loss: 1.8951, Accuracy: 26.1571, Test Loss: 1.5799, Test Accuracy: 22.0634\n",
      "Epoch 149, Loss: 1.8928, Accuracy: 26.1577, Test Loss: 1.5798, Test Accuracy: 22.0638\n",
      "Epoch 150, Loss: 1.8905, Accuracy: 26.1583, Test Loss: 1.5798, Test Accuracy: 22.0641\n",
      "Epoch 151, Loss: 1.8883, Accuracy: 26.1589, Test Loss: 1.5798, Test Accuracy: 22.0644\n",
      "Epoch 152, Loss: 1.8861, Accuracy: 26.1595, Test Loss: 1.5798, Test Accuracy: 22.0648\n",
      "Epoch 153, Loss: 1.8839, Accuracy: 26.1601, Test Loss: 1.5797, Test Accuracy: 22.0651\n",
      "Epoch 154, Loss: 1.8817, Accuracy: 26.1607, Test Loss: 1.5797, Test Accuracy: 22.0654\n",
      "Epoch 155, Loss: 1.8796, Accuracy: 26.1613, Test Loss: 1.5797, Test Accuracy: 22.0658\n",
      "Epoch 156, Loss: 1.8775, Accuracy: 26.1619, Test Loss: 1.5797, Test Accuracy: 22.0661\n",
      "Epoch 157, Loss: 1.8755, Accuracy: 26.1624, Test Loss: 1.5796, Test Accuracy: 22.0664\n",
      "Epoch 158, Loss: 1.8734, Accuracy: 26.1630, Test Loss: 1.5796, Test Accuracy: 22.0667\n",
      "Epoch 159, Loss: 1.8714, Accuracy: 26.1635, Test Loss: 1.5796, Test Accuracy: 22.0670\n",
      "Epoch 160, Loss: 1.8694, Accuracy: 26.1641, Test Loss: 1.5796, Test Accuracy: 22.0673\n",
      "Epoch 161, Loss: 1.8674, Accuracy: 26.1646, Test Loss: 1.5795, Test Accuracy: 22.0676\n",
      "Epoch 162, Loss: 1.8655, Accuracy: 26.1651, Test Loss: 1.5795, Test Accuracy: 22.0679\n",
      "Epoch 163, Loss: 1.8635, Accuracy: 26.1656, Test Loss: 1.5795, Test Accuracy: 22.0682\n",
      "Epoch 164, Loss: 1.8617, Accuracy: 26.1662, Test Loss: 1.5795, Test Accuracy: 22.0685\n",
      "Epoch 165, Loss: 1.8598, Accuracy: 26.1667, Test Loss: 1.5795, Test Accuracy: 22.0688\n",
      "Epoch 166, Loss: 1.8580, Accuracy: 26.1672, Test Loss: 1.5794, Test Accuracy: 22.0690\n",
      "Epoch 167, Loss: 1.8561, Accuracy: 26.1677, Test Loss: 1.5794, Test Accuracy: 22.0693\n",
      "Epoch 168, Loss: 1.8544, Accuracy: 26.1706, Test Loss: 1.5794, Test Accuracy: 22.0696\n",
      "Epoch 169, Loss: 1.8525, Accuracy: 26.1711, Test Loss: 1.5794, Test Accuracy: 22.0699\n",
      "Epoch 170, Loss: 1.8507, Accuracy: 26.1716, Test Loss: 1.5794, Test Accuracy: 22.0701\n",
      "Epoch 171, Loss: 1.8490, Accuracy: 26.1720, Test Loss: 1.5793, Test Accuracy: 22.0704\n",
      "Epoch 172, Loss: 1.8473, Accuracy: 26.1725, Test Loss: 1.5793, Test Accuracy: 22.0707\n",
      "Epoch 173, Loss: 1.8456, Accuracy: 26.1729, Test Loss: 1.5793, Test Accuracy: 22.0709\n",
      "Epoch 174, Loss: 1.8439, Accuracy: 26.1734, Test Loss: 1.5793, Test Accuracy: 22.0712\n",
      "Epoch 175, Loss: 1.8422, Accuracy: 26.1738, Test Loss: 1.5793, Test Accuracy: 22.0714\n",
      "Epoch 176, Loss: 1.8405, Accuracy: 26.1742, Test Loss: 1.5792, Test Accuracy: 22.0717\n",
      "Epoch 177, Loss: 1.8389, Accuracy: 26.1747, Test Loss: 1.5792, Test Accuracy: 22.0719\n",
      "Epoch 178, Loss: 1.8374, Accuracy: 26.1751, Test Loss: 1.5792, Test Accuracy: 22.0722\n",
      "Epoch 179, Loss: 1.8358, Accuracy: 26.1755, Test Loss: 1.5792, Test Accuracy: 22.0724\n",
      "Epoch 180, Loss: 1.8342, Accuracy: 26.1759, Test Loss: 1.5792, Test Accuracy: 22.0726\n",
      "Epoch 181, Loss: 1.8326, Accuracy: 26.1763, Test Loss: 1.5792, Test Accuracy: 22.0729\n",
      "Epoch 182, Loss: 1.8310, Accuracy: 26.1767, Test Loss: 1.5792, Test Accuracy: 22.0731\n",
      "Epoch 183, Loss: 1.8295, Accuracy: 26.1771, Test Loss: 1.5791, Test Accuracy: 22.0734\n",
      "Epoch 184, Loss: 1.8280, Accuracy: 26.1775, Test Loss: 1.5791, Test Accuracy: 22.0736\n",
      "Epoch 185, Loss: 1.8265, Accuracy: 26.1779, Test Loss: 1.5791, Test Accuracy: 22.0738\n",
      "Epoch 186, Loss: 1.8250, Accuracy: 26.1783, Test Loss: 1.5791, Test Accuracy: 22.0740\n",
      "Epoch 187, Loss: 1.8235, Accuracy: 26.1787, Test Loss: 1.5791, Test Accuracy: 22.0742\n",
      "Epoch 188, Loss: 1.8221, Accuracy: 26.1791, Test Loss: 1.5791, Test Accuracy: 22.0745\n",
      "Epoch 189, Loss: 1.8207, Accuracy: 26.1795, Test Loss: 1.5791, Test Accuracy: 22.0747\n",
      "Epoch 190, Loss: 1.8193, Accuracy: 26.1798, Test Loss: 1.5790, Test Accuracy: 22.0749\n",
      "Epoch 191, Loss: 1.8179, Accuracy: 26.1802, Test Loss: 1.5790, Test Accuracy: 22.0751\n",
      "Epoch 192, Loss: 1.8165, Accuracy: 26.1806, Test Loss: 1.5790, Test Accuracy: 22.0753\n",
      "Epoch 193, Loss: 1.8151, Accuracy: 26.1809, Test Loss: 1.5790, Test Accuracy: 22.0755\n",
      "Epoch 194, Loss: 1.8138, Accuracy: 26.1813, Test Loss: 1.5790, Test Accuracy: 22.0757\n",
      "Epoch 195, Loss: 1.8124, Accuracy: 26.1816, Test Loss: 1.5790, Test Accuracy: 22.0759\n",
      "Epoch 196, Loss: 1.8111, Accuracy: 26.1820, Test Loss: 1.5790, Test Accuracy: 22.0761\n",
      "Epoch 197, Loss: 1.8097, Accuracy: 26.1823, Test Loss: 1.5790, Test Accuracy: 22.0763\n",
      "Epoch 198, Loss: 1.8084, Accuracy: 26.1827, Test Loss: 1.5789, Test Accuracy: 22.0765\n",
      "Epoch 199, Loss: 1.8071, Accuracy: 26.1830, Test Loss: 1.5789, Test Accuracy: 22.0767\n",
      "Epoch 200, Loss: 1.8058, Accuracy: 26.1833, Test Loss: 1.5789, Test Accuracy: 22.0769\n",
      "average of 8 each\n",
      "Epoch 1, Loss: 24.3802, Accuracy: 20.4762, Test Loss: 1.6093, Test Accuracy: 24.1758\n",
      "Epoch 2, Loss: 20.4876, Accuracy: 19.7619, Test Loss: 1.6030, Test Accuracy: 18.1319\n",
      "Epoch 3, Loss: 17.0463, Accuracy: 20.6349, Test Loss: 1.6022, Test Accuracy: 19.0476\n",
      "Epoch 4, Loss: 14.0927, Accuracy: 21.6667, Test Loss: 1.6026, Test Accuracy: 20.8791\n",
      "Epoch 5, Loss: 11.9532, Accuracy: 22.0000, Test Loss: 1.6034, Test Accuracy: 20.6593\n",
      "Epoch 6, Loss: 10.3250, Accuracy: 22.9365, Test Loss: 1.6039, Test Accuracy: 21.0623\n",
      "Epoch 7, Loss: 9.0985, Accuracy: 23.1293, Test Loss: 1.6040, Test Accuracy: 21.3501\n",
      "Epoch 8, Loss: 8.1661, Accuracy: 23.6905, Test Loss: 1.6041, Test Accuracy: 21.5659\n",
      "Epoch 9, Loss: 7.4525, Accuracy: 23.8095, Test Loss: 1.6040, Test Accuracy: 21.7338\n",
      "Epoch 10, Loss: 6.8947, Accuracy: 23.9524, Test Loss: 1.6038, Test Accuracy: 21.8681\n",
      "Epoch 11, Loss: 6.4268, Accuracy: 24.1991, Test Loss: 1.6035, Test Accuracy: 21.9780\n",
      "Epoch 12, Loss: 6.0293, Accuracy: 24.4048, Test Loss: 1.6032, Test Accuracy: 22.0696\n",
      "Epoch 13, Loss: 5.6908, Accuracy: 24.5788, Test Loss: 1.6029, Test Accuracy: 22.1471\n",
      "Epoch 14, Loss: 5.3988, Accuracy: 24.6259, Test Loss: 1.6025, Test Accuracy: 22.2135\n",
      "Epoch 15, Loss: 5.1491, Accuracy: 24.6032, Test Loss: 1.6021, Test Accuracy: 22.2711\n",
      "Epoch 16, Loss: 4.9282, Accuracy: 24.7024, Test Loss: 1.6016, Test Accuracy: 22.3214\n",
      "Epoch 17, Loss: 4.7326, Accuracy: 24.7339, Test Loss: 1.6012, Test Accuracy: 22.3659\n",
      "Epoch 18, Loss: 4.5584, Accuracy: 24.7884, Test Loss: 1.6007, Test Accuracy: 22.4054\n",
      "Epoch 19, Loss: 4.4024, Accuracy: 24.8371, Test Loss: 1.6003, Test Accuracy: 22.4407\n",
      "Epoch 20, Loss: 4.2623, Accuracy: 24.9048, Test Loss: 1.5998, Test Accuracy: 22.4725\n",
      "Epoch 21, Loss: 4.1413, Accuracy: 24.9887, Test Loss: 1.5993, Test Accuracy: 22.5013\n",
      "Epoch 22, Loss: 4.0254, Accuracy: 25.0216, Test Loss: 1.5989, Test Accuracy: 22.5275\n",
      "Epoch 23, Loss: 3.9190, Accuracy: 25.0725, Test Loss: 1.5984, Test Accuracy: 22.5514\n",
      "Epoch 24, Loss: 3.8216, Accuracy: 25.1587, Test Loss: 1.5979, Test Accuracy: 22.5733\n",
      "Epoch 25, Loss: 3.7364, Accuracy: 25.1429, Test Loss: 1.5974, Test Accuracy: 22.5934\n",
      "Epoch 26, Loss: 3.6534, Accuracy: 25.2198, Test Loss: 1.5970, Test Accuracy: 22.6120\n",
      "Epoch 27, Loss: 3.5775, Accuracy: 25.2557, Test Loss: 1.5965, Test Accuracy: 22.6292\n",
      "Epoch 28, Loss: 3.5062, Accuracy: 25.2721, Test Loss: 1.5961, Test Accuracy: 22.6452\n",
      "Epoch 29, Loss: 3.4405, Accuracy: 25.3038, Test Loss: 1.5957, Test Accuracy: 22.6601\n",
      "Epoch 30, Loss: 3.3786, Accuracy: 25.3333, Test Loss: 1.5952, Test Accuracy: 22.6740\n",
      "Epoch 31, Loss: 3.3209, Accuracy: 25.3456, Test Loss: 1.5948, Test Accuracy: 22.6870\n",
      "Epoch 32, Loss: 3.2668, Accuracy: 25.3571, Test Loss: 1.5943, Test Accuracy: 22.6992\n",
      "Epoch 33, Loss: 3.2160, Accuracy: 25.3680, Test Loss: 1.5939, Test Accuracy: 22.7106\n",
      "Epoch 34, Loss: 3.1679, Accuracy: 25.4062, Test Loss: 1.5935, Test Accuracy: 22.7214\n",
      "Epoch 35, Loss: 3.1231, Accuracy: 25.4422, Test Loss: 1.5931, Test Accuracy: 22.7316\n",
      "Epoch 36, Loss: 3.0800, Accuracy: 25.4894, Test Loss: 1.5927, Test Accuracy: 22.7411\n",
      "Epoch 37, Loss: 3.0393, Accuracy: 25.5212, Test Loss: 1.5922, Test Accuracy: 22.7502\n",
      "Epoch 38, Loss: 3.0012, Accuracy: 25.5138, Test Loss: 1.5918, Test Accuracy: 22.7588\n",
      "Epoch 39, Loss: 2.9647, Accuracy: 25.5311, Test Loss: 1.5914, Test Accuracy: 22.7670\n",
      "Epoch 40, Loss: 2.9301, Accuracy: 25.5476, Test Loss: 1.5910, Test Accuracy: 22.7747\n",
      "Epoch 41, Loss: 2.8972, Accuracy: 25.5633, Test Loss: 1.5906, Test Accuracy: 22.7821\n",
      "Epoch 42, Loss: 2.8663, Accuracy: 25.5782, Test Loss: 1.5902, Test Accuracy: 22.7891\n",
      "Epoch 43, Loss: 2.8364, Accuracy: 25.5814, Test Loss: 1.5898, Test Accuracy: 22.7958\n",
      "Epoch 44, Loss: 2.8079, Accuracy: 25.5844, Test Loss: 1.5894, Test Accuracy: 22.8022\n",
      "Epoch 45, Loss: 2.7806, Accuracy: 25.5979, Test Loss: 1.5891, Test Accuracy: 22.8083\n",
      "Epoch 46, Loss: 2.7545, Accuracy: 25.6108, Test Loss: 1.5887, Test Accuracy: 22.8141\n",
      "Epoch 47, Loss: 2.7296, Accuracy: 25.6231, Test Loss: 1.5883, Test Accuracy: 22.8197\n",
      "Epoch 48, Loss: 2.7056, Accuracy: 25.6349, Test Loss: 1.5879, Test Accuracy: 22.8251\n",
      "Epoch 49, Loss: 2.6826, Accuracy: 25.6365, Test Loss: 1.5876, Test Accuracy: 22.8302\n",
      "Epoch 50, Loss: 2.6606, Accuracy: 25.6381, Test Loss: 1.5872, Test Accuracy: 22.8352\n",
      "Epoch 51, Loss: 2.6394, Accuracy: 25.6396, Test Loss: 1.5868, Test Accuracy: 22.8399\n",
      "Epoch 52, Loss: 2.6191, Accuracy: 25.6410, Test Loss: 1.5865, Test Accuracy: 22.8445\n",
      "Epoch 53, Loss: 2.5994, Accuracy: 25.6514, Test Loss: 1.5861, Test Accuracy: 22.8488\n",
      "Epoch 54, Loss: 2.5806, Accuracy: 25.6526, Test Loss: 1.5858, Test Accuracy: 22.8531\n",
      "Epoch 55, Loss: 2.5623, Accuracy: 25.6623, Test Loss: 1.5855, Test Accuracy: 22.8571\n",
      "Epoch 56, Loss: 2.5447, Accuracy: 25.6633, Test Loss: 1.5851, Test Accuracy: 22.8611\n",
      "Epoch 57, Loss: 2.5277, Accuracy: 25.6642, Test Loss: 1.5848, Test Accuracy: 22.8649\n",
      "Epoch 58, Loss: 2.5113, Accuracy: 25.6650, Test Loss: 1.5845, Test Accuracy: 22.8685\n",
      "Epoch 59, Loss: 2.4954, Accuracy: 25.6659, Test Loss: 1.5842, Test Accuracy: 22.8720\n",
      "Epoch 60, Loss: 2.4801, Accuracy: 25.6667, Test Loss: 1.5838, Test Accuracy: 22.8755\n",
      "Epoch 61, Loss: 2.4652, Accuracy: 25.6753, Test Loss: 1.5835, Test Accuracy: 22.8788\n",
      "Epoch 62, Loss: 2.4508, Accuracy: 25.6759, Test Loss: 1.5832, Test Accuracy: 22.8820\n",
      "Epoch 63, Loss: 2.4369, Accuracy: 25.6765, Test Loss: 1.5829, Test Accuracy: 22.8851\n",
      "Epoch 64, Loss: 2.4233, Accuracy: 25.6845, Test Loss: 1.5826, Test Accuracy: 22.8881\n",
      "Epoch 65, Loss: 2.4102, Accuracy: 25.6850, Test Loss: 1.5823, Test Accuracy: 22.8910\n",
      "Epoch 66, Loss: 2.3976, Accuracy: 25.6854, Test Loss: 1.5820, Test Accuracy: 22.8938\n",
      "Epoch 67, Loss: 2.3853, Accuracy: 25.6930, Test Loss: 1.5817, Test Accuracy: 22.8965\n",
      "Epoch 68, Loss: 2.3734, Accuracy: 25.7003, Test Loss: 1.5814, Test Accuracy: 22.8992\n",
      "Epoch 69, Loss: 2.3626, Accuracy: 25.7005, Test Loss: 1.5811, Test Accuracy: 22.9017\n",
      "Epoch 70, Loss: 2.3512, Accuracy: 25.7075, Test Loss: 1.5808, Test Accuracy: 22.9042\n",
      "Epoch 71, Loss: 2.3403, Accuracy: 25.7076, Test Loss: 1.5805, Test Accuracy: 22.9067\n",
      "Epoch 72, Loss: 2.3296, Accuracy: 25.7077, Test Loss: 1.5803, Test Accuracy: 22.9090\n",
      "Epoch 73, Loss: 2.3190, Accuracy: 25.7208, Test Loss: 1.5800, Test Accuracy: 22.9113\n",
      "Epoch 74, Loss: 2.3087, Accuracy: 25.7336, Test Loss: 1.5797, Test Accuracy: 22.9136\n",
      "Epoch 75, Loss: 2.2990, Accuracy: 25.7460, Test Loss: 1.5795, Test Accuracy: 22.9158\n",
      "Epoch 76, Loss: 2.2894, Accuracy: 25.7581, Test Loss: 1.5792, Test Accuracy: 22.9179\n",
      "Epoch 77, Loss: 2.2800, Accuracy: 25.7699, Test Loss: 1.5789, Test Accuracy: 22.9199\n",
      "Epoch 78, Loss: 2.2710, Accuracy: 25.7631, Test Loss: 1.5787, Test Accuracy: 22.9219\n",
      "Epoch 79, Loss: 2.2622, Accuracy: 25.7685, Test Loss: 1.5784, Test Accuracy: 22.9239\n",
      "Epoch 80, Loss: 2.2535, Accuracy: 25.7679, Test Loss: 1.5782, Test Accuracy: 22.9258\n",
      "Epoch 81, Loss: 2.2451, Accuracy: 25.7731, Test Loss: 1.5779, Test Accuracy: 22.9277\n",
      "Epoch 82, Loss: 2.2369, Accuracy: 25.7782, Test Loss: 1.5777, Test Accuracy: 22.9295\n",
      "Epoch 83, Loss: 2.2288, Accuracy: 25.7831, Test Loss: 1.5774, Test Accuracy: 22.9313\n",
      "Epoch 84, Loss: 2.2209, Accuracy: 25.7880, Test Loss: 1.5772, Test Accuracy: 22.9330\n",
      "Epoch 85, Loss: 2.2131, Accuracy: 25.8039, Test Loss: 1.5769, Test Accuracy: 22.9347\n",
      "Epoch 86, Loss: 2.2056, Accuracy: 25.8140, Test Loss: 1.5767, Test Accuracy: 22.9364\n",
      "Epoch 87, Loss: 2.1985, Accuracy: 25.8128, Test Loss: 1.5765, Test Accuracy: 22.9380\n",
      "Epoch 88, Loss: 2.1913, Accuracy: 25.8171, Test Loss: 1.5762, Test Accuracy: 22.9396\n",
      "Epoch 89, Loss: 2.1843, Accuracy: 25.8266, Test Loss: 1.5760, Test Accuracy: 22.9411\n",
      "Epoch 90, Loss: 2.1774, Accuracy: 25.8307, Test Loss: 1.5758, Test Accuracy: 22.9426\n",
      "Epoch 91, Loss: 2.1707, Accuracy: 25.8346, Test Loss: 1.5756, Test Accuracy: 22.9441\n",
      "Epoch 92, Loss: 2.1644, Accuracy: 25.8333, Test Loss: 1.5754, Test Accuracy: 22.9455\n",
      "Epoch 93, Loss: 2.1579, Accuracy: 25.8372, Test Loss: 1.5752, Test Accuracy: 22.9469\n",
      "Epoch 94, Loss: 2.1517, Accuracy: 25.8409, Test Loss: 1.5749, Test Accuracy: 22.9483\n",
      "Epoch 95, Loss: 2.1456, Accuracy: 25.8396, Test Loss: 1.5747, Test Accuracy: 22.9497\n",
      "Epoch 96, Loss: 2.1396, Accuracy: 25.8383, Test Loss: 1.5745, Test Accuracy: 22.9510\n",
      "Epoch 97, Loss: 2.1338, Accuracy: 25.8370, Test Loss: 1.5743, Test Accuracy: 22.9523\n",
      "Epoch 98, Loss: 2.1281, Accuracy: 25.8406, Test Loss: 1.5741, Test Accuracy: 22.9536\n",
      "Epoch 99, Loss: 2.1224, Accuracy: 25.8442, Test Loss: 1.5739, Test Accuracy: 22.9548\n",
      "Epoch 100, Loss: 2.1170, Accuracy: 25.8476, Test Loss: 1.5737, Test Accuracy: 22.9560\n",
      "Epoch 101, Loss: 2.1115, Accuracy: 25.8510, Test Loss: 1.5735, Test Accuracy: 22.9572\n",
      "Epoch 102, Loss: 2.1063, Accuracy: 25.8497, Test Loss: 1.5734, Test Accuracy: 22.9584\n",
      "Epoch 103, Loss: 2.1011, Accuracy: 25.8530, Test Loss: 1.5732, Test Accuracy: 22.9596\n",
      "Epoch 104, Loss: 2.0960, Accuracy: 25.8516, Test Loss: 1.5730, Test Accuracy: 22.9607\n",
      "Epoch 105, Loss: 2.0909, Accuracy: 25.8594, Test Loss: 1.5728, Test Accuracy: 22.9618\n",
      "Epoch 106, Loss: 2.0860, Accuracy: 25.8580, Test Loss: 1.5726, Test Accuracy: 22.9629\n",
      "Epoch 107, Loss: 2.0811, Accuracy: 25.8611, Test Loss: 1.5724, Test Accuracy: 22.9640\n",
      "Epoch 108, Loss: 2.0764, Accuracy: 25.8642, Test Loss: 1.5723, Test Accuracy: 22.9650\n",
      "Epoch 109, Loss: 2.0717, Accuracy: 25.8628, Test Loss: 1.5721, Test Accuracy: 22.9660\n",
      "Epoch 110, Loss: 2.0671, Accuracy: 25.8658, Test Loss: 1.5719, Test Accuracy: 22.9670\n",
      "Epoch 111, Loss: 2.0627, Accuracy: 25.8687, Test Loss: 1.5717, Test Accuracy: 22.9680\n",
      "Epoch 112, Loss: 2.0582, Accuracy: 25.8801, Test Loss: 1.5716, Test Accuracy: 22.9690\n",
      "Epoch 113, Loss: 2.0540, Accuracy: 25.8786, Test Loss: 1.5714, Test Accuracy: 22.9700\n",
      "Epoch 114, Loss: 2.0498, Accuracy: 25.8897, Test Loss: 1.5713, Test Accuracy: 22.9709\n",
      "Epoch 115, Loss: 2.0456, Accuracy: 25.8923, Test Loss: 1.5711, Test Accuracy: 22.9718\n",
      "Epoch 116, Loss: 2.0412, Accuracy: 25.9072, Test Loss: 1.5709, Test Accuracy: 22.9727\n",
      "Epoch 117, Loss: 2.0371, Accuracy: 25.9178, Test Loss: 1.5708, Test Accuracy: 22.9736\n",
      "Epoch 118, Loss: 2.0332, Accuracy: 25.9161, Test Loss: 1.5706, Test Accuracy: 22.9745\n",
      "Epoch 119, Loss: 2.0292, Accuracy: 25.9184, Test Loss: 1.5705, Test Accuracy: 22.9753\n",
      "Epoch 120, Loss: 2.0253, Accuracy: 25.9246, Test Loss: 1.5703, Test Accuracy: 22.9762\n",
      "Epoch 121, Loss: 2.0216, Accuracy: 25.9229, Test Loss: 1.5702, Test Accuracy: 22.9770\n",
      "Epoch 122, Loss: 2.0182, Accuracy: 25.9251, Test Loss: 1.5700, Test Accuracy: 22.9778\n",
      "Epoch 123, Loss: 2.0145, Accuracy: 25.9233, Test Loss: 1.5699, Test Accuracy: 22.9786\n",
      "Epoch 124, Loss: 2.0110, Accuracy: 25.9217, Test Loss: 1.5697, Test Accuracy: 22.9794\n",
      "Epoch 125, Loss: 2.0075, Accuracy: 25.9200, Test Loss: 1.5696, Test Accuracy: 22.9802\n",
      "Epoch 126, Loss: 2.0040, Accuracy: 25.9184, Test Loss: 1.5694, Test Accuracy: 22.9810\n",
      "Epoch 127, Loss: 2.0005, Accuracy: 25.9168, Test Loss: 1.5693, Test Accuracy: 22.9817\n",
      "Epoch 128, Loss: 1.9972, Accuracy: 25.9152, Test Loss: 1.5692, Test Accuracy: 22.9825\n",
      "Epoch 129, Loss: 1.9938, Accuracy: 25.9136, Test Loss: 1.5690, Test Accuracy: 22.9832\n",
      "Epoch 130, Loss: 1.9905, Accuracy: 25.9158, Test Loss: 1.5689, Test Accuracy: 22.9839\n",
      "Epoch 131, Loss: 1.9873, Accuracy: 25.9142, Test Loss: 1.5688, Test Accuracy: 22.9846\n",
      "Epoch 132, Loss: 1.9842, Accuracy: 25.9127, Test Loss: 1.5686, Test Accuracy: 22.9853\n",
      "Epoch 133, Loss: 1.9811, Accuracy: 25.9112, Test Loss: 1.5685, Test Accuracy: 22.9860\n",
      "Epoch 134, Loss: 1.9781, Accuracy: 25.9097, Test Loss: 1.5684, Test Accuracy: 22.9867\n",
      "Epoch 135, Loss: 1.9750, Accuracy: 25.9083, Test Loss: 1.5683, Test Accuracy: 22.9874\n",
      "Epoch 136, Loss: 1.9721, Accuracy: 25.9069, Test Loss: 1.5681, Test Accuracy: 22.9880\n",
      "Epoch 137, Loss: 1.9691, Accuracy: 25.9055, Test Loss: 1.5680, Test Accuracy: 22.9887\n",
      "Epoch 138, Loss: 1.9662, Accuracy: 25.9041, Test Loss: 1.5679, Test Accuracy: 22.9893\n",
      "Epoch 139, Loss: 1.9633, Accuracy: 25.9061, Test Loss: 1.5678, Test Accuracy: 22.9900\n",
      "Epoch 140, Loss: 1.9605, Accuracy: 25.9048, Test Loss: 1.5677, Test Accuracy: 22.9906\n",
      "Epoch 141, Loss: 1.9577, Accuracy: 25.9068, Test Loss: 1.5675, Test Accuracy: 22.9912\n",
      "Epoch 142, Loss: 1.9550, Accuracy: 25.9121, Test Loss: 1.5674, Test Accuracy: 22.9918\n",
      "Epoch 143, Loss: 1.9521, Accuracy: 25.9241, Test Loss: 1.5673, Test Accuracy: 22.9924\n",
      "Epoch 144, Loss: 1.9495, Accuracy: 25.9358, Test Loss: 1.5672, Test Accuracy: 22.9930\n",
      "Epoch 145, Loss: 1.9467, Accuracy: 25.9475, Test Loss: 1.5671, Test Accuracy: 22.9936\n",
      "Epoch 146, Loss: 1.9440, Accuracy: 25.9687, Test Loss: 1.5670, Test Accuracy: 22.9941\n",
      "Epoch 147, Loss: 1.9414, Accuracy: 25.9734, Test Loss: 1.5669, Test Accuracy: 22.9947\n",
      "Epoch 148, Loss: 1.9388, Accuracy: 25.9781, Test Loss: 1.5668, Test Accuracy: 22.9952\n",
      "Epoch 149, Loss: 1.9363, Accuracy: 25.9764, Test Loss: 1.5666, Test Accuracy: 22.9958\n",
      "Epoch 150, Loss: 1.9340, Accuracy: 25.9746, Test Loss: 1.5665, Test Accuracy: 22.9963\n",
      "Epoch 151, Loss: 1.9316, Accuracy: 25.9792, Test Loss: 1.5664, Test Accuracy: 22.9969\n",
      "Epoch 152, Loss: 1.9292, Accuracy: 25.9806, Test Loss: 1.5663, Test Accuracy: 22.9974\n",
      "Epoch 153, Loss: 1.9268, Accuracy: 25.9788, Test Loss: 1.5662, Test Accuracy: 22.9979\n",
      "Epoch 154, Loss: 1.9245, Accuracy: 25.9802, Test Loss: 1.5661, Test Accuracy: 22.9984\n",
      "Epoch 155, Loss: 1.9222, Accuracy: 25.9816, Test Loss: 1.5660, Test Accuracy: 22.9989\n",
      "Epoch 156, Loss: 1.9199, Accuracy: 25.9829, Test Loss: 1.5659, Test Accuracy: 22.9994\n",
      "Epoch 157, Loss: 1.9182, Accuracy: 25.9964, Test Loss: 1.5658, Test Accuracy: 22.9999\n",
      "Epoch 158, Loss: 1.9160, Accuracy: 26.0006, Test Loss: 1.5657, Test Accuracy: 23.0004\n",
      "Epoch 159, Loss: 1.9137, Accuracy: 26.0018, Test Loss: 1.5656, Test Accuracy: 23.0009\n",
      "Epoch 160, Loss: 1.9115, Accuracy: 26.0060, Test Loss: 1.5655, Test Accuracy: 23.0014\n",
      "Epoch 161, Loss: 1.9094, Accuracy: 26.0130, Test Loss: 1.5654, Test Accuracy: 23.0018\n",
      "Epoch 162, Loss: 1.9071, Accuracy: 26.0170, Test Loss: 1.5654, Test Accuracy: 23.0023\n",
      "Epoch 163, Loss: 1.9051, Accuracy: 26.0327, Test Loss: 1.5653, Test Accuracy: 23.0028\n",
      "Epoch 164, Loss: 1.9032, Accuracy: 26.0337, Test Loss: 1.5652, Test Accuracy: 23.0032\n",
      "Epoch 165, Loss: 1.9016, Accuracy: 26.0346, Test Loss: 1.5651, Test Accuracy: 23.0037\n",
      "Epoch 166, Loss: 1.8997, Accuracy: 26.0442, Test Loss: 1.5650, Test Accuracy: 23.0041\n",
      "Epoch 167, Loss: 1.8977, Accuracy: 26.0479, Test Loss: 1.5649, Test Accuracy: 23.0045\n",
      "Epoch 168, Loss: 1.8957, Accuracy: 26.0516, Test Loss: 1.5648, Test Accuracy: 23.0050\n",
      "Epoch 169, Loss: 1.8938, Accuracy: 26.0524, Test Loss: 1.5647, Test Accuracy: 23.0054\n",
      "Epoch 170, Loss: 1.8919, Accuracy: 26.0532, Test Loss: 1.5646, Test Accuracy: 23.0058\n",
      "Epoch 171, Loss: 1.8900, Accuracy: 26.0568, Test Loss: 1.5645, Test Accuracy: 23.0062\n",
      "Epoch 172, Loss: 1.8881, Accuracy: 26.0576, Test Loss: 1.5645, Test Accuracy: 23.0066\n",
      "Epoch 173, Loss: 1.8862, Accuracy: 26.0584, Test Loss: 1.5644, Test Accuracy: 23.0070\n",
      "Epoch 174, Loss: 1.8843, Accuracy: 26.0619, Test Loss: 1.5643, Test Accuracy: 23.0075\n",
      "Epoch 175, Loss: 1.8825, Accuracy: 26.0626, Test Loss: 1.5642, Test Accuracy: 23.0078\n",
      "Epoch 176, Loss: 1.8808, Accuracy: 26.0606, Test Loss: 1.5641, Test Accuracy: 23.0082\n",
      "Epoch 177, Loss: 1.8790, Accuracy: 26.0613, Test Loss: 1.5640, Test Accuracy: 23.0086\n",
      "Epoch 178, Loss: 1.8773, Accuracy: 26.0594, Test Loss: 1.5640, Test Accuracy: 23.0090\n",
      "Epoch 179, Loss: 1.8756, Accuracy: 26.0575, Test Loss: 1.5639, Test Accuracy: 23.0094\n",
      "Epoch 180, Loss: 1.8739, Accuracy: 26.0556, Test Loss: 1.5638, Test Accuracy: 23.0098\n",
      "Epoch 181, Loss: 1.8722, Accuracy: 26.0537, Test Loss: 1.5637, Test Accuracy: 23.0101\n",
      "Epoch 182, Loss: 1.8705, Accuracy: 26.0518, Test Loss: 1.5637, Test Accuracy: 23.0105\n",
      "Epoch 183, Loss: 1.8689, Accuracy: 26.0500, Test Loss: 1.5636, Test Accuracy: 23.0109\n",
      "Epoch 184, Loss: 1.8672, Accuracy: 26.0481, Test Loss: 1.5635, Test Accuracy: 23.0112\n",
      "Epoch 185, Loss: 1.8656, Accuracy: 26.0463, Test Loss: 1.5634, Test Accuracy: 23.0116\n",
      "Epoch 186, Loss: 1.8639, Accuracy: 26.0445, Test Loss: 1.5633, Test Accuracy: 23.0119\n",
      "Epoch 187, Loss: 1.8624, Accuracy: 26.0402, Test Loss: 1.5633, Test Accuracy: 23.0123\n",
      "Epoch 188, Loss: 1.8609, Accuracy: 26.0410, Test Loss: 1.5632, Test Accuracy: 23.0126\n",
      "Epoch 189, Loss: 1.8594, Accuracy: 26.0393, Test Loss: 1.5631, Test Accuracy: 23.0130\n",
      "Epoch 190, Loss: 1.8579, Accuracy: 26.0376, Test Loss: 1.5630, Test Accuracy: 23.0133\n",
      "Epoch 191, Loss: 1.8564, Accuracy: 26.0359, Test Loss: 1.5630, Test Accuracy: 23.0136\n",
      "Epoch 192, Loss: 1.8548, Accuracy: 26.0317, Test Loss: 1.5629, Test Accuracy: 23.0140\n",
      "Epoch 193, Loss: 1.8533, Accuracy: 26.0301, Test Loss: 1.5628, Test Accuracy: 23.0143\n",
      "Epoch 194, Loss: 1.8519, Accuracy: 26.0285, Test Loss: 1.5628, Test Accuracy: 23.0146\n",
      "Epoch 195, Loss: 1.8504, Accuracy: 26.0269, Test Loss: 1.5627, Test Accuracy: 23.0149\n",
      "Epoch 196, Loss: 1.8490, Accuracy: 26.0253, Test Loss: 1.5626, Test Accuracy: 23.0153\n",
      "Epoch 197, Loss: 1.8475, Accuracy: 26.0237, Test Loss: 1.5626, Test Accuracy: 23.0156\n",
      "Epoch 198, Loss: 1.8462, Accuracy: 26.0221, Test Loss: 1.5625, Test Accuracy: 23.0159\n",
      "Epoch 199, Loss: 1.8448, Accuracy: 26.0206, Test Loss: 1.5624, Test Accuracy: 23.0162\n",
      "Epoch 200, Loss: 1.8434, Accuracy: 26.0238, Test Loss: 1.5623, Test Accuracy: 23.0165\n",
      "average of 9 each\n",
      "Epoch 1, Loss: 19.7635, Accuracy: 21.8085, Test Loss: 1.6613, Test Accuracy: 11.1111\n",
      "Epoch 2, Loss: 16.3027, Accuracy: 23.1383, Test Loss: 1.6674, Test Accuracy: 11.7284\n",
      "Epoch 3, Loss: 13.7535, Accuracy: 23.2270, Test Loss: 1.6685, Test Accuracy: 11.1111\n",
      "Epoch 4, Loss: 11.7193, Accuracy: 22.2074, Test Loss: 1.6604, Test Accuracy: 11.4198\n",
      "Epoch 5, Loss: 10.0654, Accuracy: 23.6170, Test Loss: 1.6498, Test Accuracy: 14.0741\n",
      "Epoch 6, Loss: 8.7762, Accuracy: 23.8475, Test Loss: 1.6425, Test Accuracy: 15.2263\n",
      "Epoch 7, Loss: 7.8034, Accuracy: 23.7082, Test Loss: 1.6370, Test Accuracy: 16.7549\n",
      "Epoch 8, Loss: 7.0478, Accuracy: 23.6037, Test Loss: 1.6327, Test Accuracy: 17.9012\n",
      "Epoch 9, Loss: 6.4429, Accuracy: 23.6407, Test Loss: 1.6293, Test Accuracy: 18.7929\n",
      "Epoch 10, Loss: 5.9673, Accuracy: 23.6702, Test Loss: 1.6264, Test Accuracy: 19.5062\n",
      "Epoch 11, Loss: 5.5755, Accuracy: 23.7911, Test Loss: 1.6239, Test Accuracy: 20.0898\n",
      "Epoch 12, Loss: 5.2443, Accuracy: 23.8475, Test Loss: 1.6218, Test Accuracy: 20.5761\n",
      "Epoch 13, Loss: 4.9633, Accuracy: 23.9362, Test Loss: 1.6198, Test Accuracy: 20.9877\n",
      "Epoch 14, Loss: 4.7210, Accuracy: 23.9742, Test Loss: 1.6181, Test Accuracy: 21.3404\n",
      "Epoch 15, Loss: 4.5125, Accuracy: 24.0071, Test Loss: 1.6165, Test Accuracy: 21.6461\n",
      "Epoch 16, Loss: 4.3302, Accuracy: 24.0359, Test Loss: 1.6151, Test Accuracy: 21.9136\n",
      "Epoch 17, Loss: 4.1686, Accuracy: 24.0613, Test Loss: 1.6137, Test Accuracy: 22.1496\n",
      "Epoch 18, Loss: 4.0269, Accuracy: 24.0839, Test Loss: 1.6125, Test Accuracy: 22.3594\n",
      "Epoch 19, Loss: 3.9013, Accuracy: 24.1881, Test Loss: 1.6113, Test Accuracy: 22.4821\n",
      "Epoch 20, Loss: 3.7859, Accuracy: 24.3085, Test Loss: 1.6101, Test Accuracy: 22.5926\n",
      "Epoch 21, Loss: 3.6814, Accuracy: 24.4428, Test Loss: 1.6091, Test Accuracy: 22.6925\n",
      "Epoch 22, Loss: 3.5872, Accuracy: 24.6373, Test Loss: 1.6081, Test Accuracy: 22.7834\n",
      "Epoch 23, Loss: 3.5056, Accuracy: 24.7919, Test Loss: 1.6071, Test Accuracy: 22.8663\n",
      "Epoch 24, Loss: 3.4263, Accuracy: 24.8227, Test Loss: 1.6062, Test Accuracy: 22.9424\n",
      "Epoch 25, Loss: 3.3561, Accuracy: 24.9787, Test Loss: 1.6053, Test Accuracy: 23.0123\n",
      "Epoch 26, Loss: 3.2879, Accuracy: 25.0818, Test Loss: 1.6044, Test Accuracy: 23.0769\n",
      "Epoch 27, Loss: 3.2254, Accuracy: 25.0985, Test Loss: 1.6036, Test Accuracy: 23.1367\n",
      "Epoch 28, Loss: 3.1656, Accuracy: 25.1900, Test Loss: 1.6028, Test Accuracy: 23.1922\n",
      "Epoch 29, Loss: 3.1113, Accuracy: 25.3852, Test Loss: 1.6020, Test Accuracy: 23.2439\n",
      "Epoch 30, Loss: 3.0626, Accuracy: 25.4255, Test Loss: 1.6013, Test Accuracy: 23.2922\n",
      "Epoch 31, Loss: 3.0145, Accuracy: 25.5319, Test Loss: 1.6006, Test Accuracy: 23.3373\n",
      "Epoch 32, Loss: 2.9707, Accuracy: 25.5319, Test Loss: 1.5998, Test Accuracy: 23.3796\n",
      "Epoch 33, Loss: 2.9282, Accuracy: 25.5642, Test Loss: 1.5991, Test Accuracy: 23.4194\n",
      "Epoch 34, Loss: 2.8907, Accuracy: 25.5945, Test Loss: 1.5985, Test Accuracy: 23.4568\n",
      "Epoch 35, Loss: 2.8534, Accuracy: 25.5775, Test Loss: 1.5978, Test Accuracy: 23.4921\n",
      "Epoch 36, Loss: 2.8188, Accuracy: 25.5762, Test Loss: 1.5971, Test Accuracy: 23.5254\n",
      "Epoch 37, Loss: 2.7856, Accuracy: 25.5463, Test Loss: 1.5965, Test Accuracy: 23.5569\n",
      "Epoch 38, Loss: 2.7542, Accuracy: 25.5459, Test Loss: 1.5959, Test Accuracy: 23.5867\n",
      "Epoch 39, Loss: 2.7241, Accuracy: 25.5456, Test Loss: 1.5953, Test Accuracy: 23.6151\n",
      "Epoch 40, Loss: 2.6955, Accuracy: 25.5452, Test Loss: 1.5947, Test Accuracy: 23.6420\n",
      "Epoch 41, Loss: 2.6690, Accuracy: 25.5449, Test Loss: 1.5941, Test Accuracy: 23.6676\n",
      "Epoch 42, Loss: 2.6428, Accuracy: 25.5699, Test Loss: 1.5935, Test Accuracy: 23.6919\n",
      "Epoch 43, Loss: 2.6180, Accuracy: 25.5690, Test Loss: 1.5929, Test Accuracy: 23.7152\n",
      "Epoch 44, Loss: 2.5944, Accuracy: 25.5682, Test Loss: 1.5924, Test Accuracy: 23.7374\n",
      "Epoch 45, Loss: 2.5715, Accuracy: 25.6028, Test Loss: 1.5918, Test Accuracy: 23.7586\n",
      "Epoch 46, Loss: 2.5504, Accuracy: 25.6244, Test Loss: 1.5913, Test Accuracy: 23.7789\n",
      "Epoch 47, Loss: 2.5297, Accuracy: 25.6451, Test Loss: 1.5907, Test Accuracy: 23.7983\n",
      "Epoch 48, Loss: 2.5098, Accuracy: 25.6871, Test Loss: 1.5902, Test Accuracy: 23.8169\n",
      "Epoch 49, Loss: 2.4902, Accuracy: 25.7490, Test Loss: 1.5897, Test Accuracy: 23.8347\n",
      "Epoch 50, Loss: 2.4719, Accuracy: 25.7553, Test Loss: 1.5892, Test Accuracy: 23.8519\n",
      "Epoch 51, Loss: 2.4546, Accuracy: 25.7822, Test Loss: 1.5887, Test Accuracy: 23.8683\n",
      "Epoch 52, Loss: 2.4376, Accuracy: 25.7979, Test Loss: 1.5882, Test Accuracy: 23.8841\n",
      "Epoch 53, Loss: 2.4210, Accuracy: 25.8230, Test Loss: 1.5877, Test Accuracy: 23.8994\n",
      "Epoch 54, Loss: 2.4054, Accuracy: 25.8373, Test Loss: 1.5872, Test Accuracy: 23.9140\n",
      "Epoch 55, Loss: 2.3901, Accuracy: 25.8511, Test Loss: 1.5868, Test Accuracy: 23.9282\n",
      "Epoch 56, Loss: 2.3757, Accuracy: 25.8359, Test Loss: 1.5863, Test Accuracy: 23.9418\n",
      "Epoch 57, Loss: 2.3615, Accuracy: 25.8305, Test Loss: 1.5858, Test Accuracy: 23.9549\n",
      "Epoch 58, Loss: 2.3484, Accuracy: 25.8437, Test Loss: 1.5854, Test Accuracy: 23.9676\n",
      "Epoch 59, Loss: 2.3350, Accuracy: 25.8835, Test Loss: 1.5849, Test Accuracy: 23.9799\n",
      "Epoch 60, Loss: 2.3221, Accuracy: 25.8954, Test Loss: 1.5845, Test Accuracy: 23.9918\n",
      "Epoch 61, Loss: 2.3098, Accuracy: 25.9069, Test Loss: 1.5841, Test Accuracy: 24.0032\n",
      "Epoch 62, Loss: 2.2988, Accuracy: 25.9008, Test Loss: 1.5836, Test Accuracy: 24.0143\n",
      "Epoch 63, Loss: 2.2873, Accuracy: 25.8781, Test Loss: 1.5832, Test Accuracy: 24.0251\n",
      "Epoch 64, Loss: 2.2762, Accuracy: 25.8644, Test Loss: 1.5828, Test Accuracy: 24.0355\n",
      "Epoch 65, Loss: 2.2650, Accuracy: 25.8920, Test Loss: 1.5824, Test Accuracy: 24.0456\n",
      "Epoch 66, Loss: 2.2545, Accuracy: 25.8946, Test Loss: 1.5820, Test Accuracy: 24.0554\n",
      "Epoch 67, Loss: 2.2442, Accuracy: 25.8971, Test Loss: 1.5816, Test Accuracy: 24.0649\n",
      "Epoch 68, Loss: 2.2340, Accuracy: 25.9152, Test Loss: 1.5812, Test Accuracy: 24.0741\n",
      "Epoch 69, Loss: 2.2243, Accuracy: 25.9251, Test Loss: 1.5808, Test Accuracy: 24.0830\n",
      "Epoch 70, Loss: 2.2157, Accuracy: 25.9271, Test Loss: 1.5804, Test Accuracy: 24.0917\n",
      "Epoch 71, Loss: 2.2066, Accuracy: 25.9290, Test Loss: 1.5800, Test Accuracy: 24.1002\n",
      "Epoch 72, Loss: 2.1978, Accuracy: 25.9309, Test Loss: 1.5797, Test Accuracy: 24.1084\n",
      "Epoch 73, Loss: 2.1888, Accuracy: 25.9472, Test Loss: 1.5793, Test Accuracy: 24.1164\n",
      "Epoch 74, Loss: 2.1803, Accuracy: 25.9704, Test Loss: 1.5789, Test Accuracy: 24.1241\n",
      "Epoch 75, Loss: 2.1718, Accuracy: 25.9858, Test Loss: 1.5786, Test Accuracy: 24.1317\n",
      "Epoch 76, Loss: 2.1640, Accuracy: 26.0288, Test Loss: 1.5782, Test Accuracy: 24.1391\n",
      "Epoch 77, Loss: 2.1558, Accuracy: 26.0638, Test Loss: 1.5778, Test Accuracy: 24.1462\n",
      "Epoch 78, Loss: 2.1490, Accuracy: 26.0843, Test Loss: 1.5775, Test Accuracy: 24.1532\n",
      "Epoch 79, Loss: 2.1421, Accuracy: 26.0638, Test Loss: 1.5771, Test Accuracy: 24.1600\n",
      "Epoch 80, Loss: 2.1345, Accuracy: 26.0838, Test Loss: 1.5768, Test Accuracy: 24.1667\n",
      "Epoch 81, Loss: 2.1278, Accuracy: 26.0704, Test Loss: 1.5765, Test Accuracy: 24.1731\n",
      "Epoch 82, Loss: 2.1208, Accuracy: 26.0833, Test Loss: 1.5761, Test Accuracy: 24.1795\n",
      "Epoch 83, Loss: 2.1138, Accuracy: 26.1087, Test Loss: 1.5758, Test Accuracy: 24.1856\n",
      "Epoch 84, Loss: 2.1072, Accuracy: 26.1145, Test Loss: 1.5755, Test Accuracy: 24.1917\n",
      "Epoch 85, Loss: 2.1011, Accuracy: 26.1076, Test Loss: 1.5752, Test Accuracy: 24.1975\n",
      "Epoch 86, Loss: 2.0947, Accuracy: 26.1195, Test Loss: 1.5748, Test Accuracy: 24.2033\n",
      "Epoch 87, Loss: 2.0883, Accuracy: 26.1433, Test Loss: 1.5745, Test Accuracy: 24.2089\n",
      "Epoch 88, Loss: 2.0826, Accuracy: 26.1364, Test Loss: 1.5742, Test Accuracy: 24.2144\n",
      "Epoch 89, Loss: 2.0767, Accuracy: 26.1355, Test Loss: 1.5739, Test Accuracy: 24.2197\n",
      "Epoch 90, Loss: 2.0715, Accuracy: 26.1466, Test Loss: 1.5736, Test Accuracy: 24.2250\n",
      "Epoch 91, Loss: 2.0659, Accuracy: 26.1574, Test Loss: 1.5733, Test Accuracy: 24.2301\n",
      "Epoch 92, Loss: 2.0605, Accuracy: 26.1448, Test Loss: 1.5730, Test Accuracy: 24.2351\n",
      "Epoch 93, Loss: 2.0550, Accuracy: 26.1553, Test Loss: 1.5727, Test Accuracy: 24.2400\n",
      "Epoch 94, Loss: 2.0496, Accuracy: 26.1600, Test Loss: 1.5724, Test Accuracy: 24.2448\n",
      "Epoch 95, Loss: 2.0447, Accuracy: 26.1590, Test Loss: 1.5721, Test Accuracy: 24.2495\n",
      "Epoch 96, Loss: 2.0398, Accuracy: 26.1580, Test Loss: 1.5718, Test Accuracy: 24.2541\n",
      "Epoch 97, Loss: 2.0348, Accuracy: 26.1625, Test Loss: 1.5716, Test Accuracy: 24.2586\n",
      "Epoch 98, Loss: 2.0302, Accuracy: 26.1778, Test Loss: 1.5713, Test Accuracy: 24.2630\n",
      "Epoch 99, Loss: 2.0254, Accuracy: 26.1874, Test Loss: 1.5710, Test Accuracy: 24.2674\n",
      "Epoch 100, Loss: 2.0207, Accuracy: 26.1968, Test Loss: 1.5707, Test Accuracy: 24.2716\n",
      "Epoch 101, Loss: 2.0165, Accuracy: 26.1850, Test Loss: 1.5705, Test Accuracy: 24.2758\n",
      "Epoch 102, Loss: 2.0122, Accuracy: 26.1629, Test Loss: 1.5702, Test Accuracy: 24.2798\n",
      "Epoch 103, Loss: 2.0077, Accuracy: 26.1723, Test Loss: 1.5699, Test Accuracy: 24.2838\n",
      "Epoch 104, Loss: 2.0035, Accuracy: 26.1712, Test Loss: 1.5697, Test Accuracy: 24.2878\n",
      "Epoch 105, Loss: 1.9993, Accuracy: 26.1702, Test Loss: 1.5694, Test Accuracy: 24.2916\n",
      "Epoch 106, Loss: 1.9951, Accuracy: 26.1692, Test Loss: 1.5692, Test Accuracy: 24.2954\n",
      "Epoch 107, Loss: 1.9911, Accuracy: 26.1682, Test Loss: 1.5689, Test Accuracy: 24.2991\n",
      "Epoch 108, Loss: 1.9872, Accuracy: 26.1673, Test Loss: 1.5687, Test Accuracy: 24.3027\n",
      "Epoch 109, Loss: 1.9832, Accuracy: 26.1712, Test Loss: 1.5684, Test Accuracy: 24.3063\n",
      "Epoch 110, Loss: 1.9794, Accuracy: 26.1702, Test Loss: 1.5682, Test Accuracy: 24.3098\n",
      "Epoch 111, Loss: 1.9755, Accuracy: 26.1788, Test Loss: 1.5679, Test Accuracy: 24.3132\n",
      "Epoch 112, Loss: 1.9718, Accuracy: 26.1921, Test Loss: 1.5677, Test Accuracy: 24.3166\n",
      "Epoch 113, Loss: 1.9681, Accuracy: 26.2050, Test Loss: 1.5675, Test Accuracy: 24.3199\n",
      "Epoch 114, Loss: 1.9642, Accuracy: 26.2085, Test Loss: 1.5672, Test Accuracy: 24.3232\n",
      "Epoch 115, Loss: 1.9604, Accuracy: 26.2257, Test Loss: 1.5670, Test Accuracy: 24.3264\n",
      "Epoch 116, Loss: 1.9568, Accuracy: 26.2381, Test Loss: 1.5668, Test Accuracy: 24.3295\n",
      "Epoch 117, Loss: 1.9535, Accuracy: 26.2457, Test Loss: 1.5665, Test Accuracy: 24.3326\n",
      "Epoch 118, Loss: 1.9500, Accuracy: 26.2577, Test Loss: 1.5663, Test Accuracy: 24.3356\n",
      "Epoch 119, Loss: 1.9466, Accuracy: 26.2650, Test Loss: 1.5661, Test Accuracy: 24.3386\n",
      "Epoch 120, Loss: 1.9435, Accuracy: 26.2589, Test Loss: 1.5659, Test Accuracy: 24.3416\n",
      "Epoch 121, Loss: 1.9413, Accuracy: 26.2573, Test Loss: 1.5656, Test Accuracy: 24.3445\n",
      "Epoch 122, Loss: 1.9381, Accuracy: 26.2644, Test Loss: 1.5654, Test Accuracy: 24.3473\n",
      "Epoch 123, Loss: 1.9352, Accuracy: 26.2541, Test Loss: 1.5652, Test Accuracy: 24.3501\n",
      "Epoch 124, Loss: 1.9321, Accuracy: 26.2569, Test Loss: 1.5650, Test Accuracy: 24.3528\n",
      "Epoch 125, Loss: 1.9291, Accuracy: 26.2511, Test Loss: 1.5648, Test Accuracy: 24.3556\n",
      "Epoch 126, Loss: 1.9260, Accuracy: 26.2622, Test Loss: 1.5646, Test Accuracy: 24.3582\n",
      "Epoch 127, Loss: 1.9229, Accuracy: 26.2691, Test Loss: 1.5644, Test Accuracy: 24.3608\n",
      "Epoch 128, Loss: 1.9199, Accuracy: 26.2841, Test Loss: 1.5642, Test Accuracy: 24.3634\n",
      "Epoch 129, Loss: 1.9170, Accuracy: 26.2906, Test Loss: 1.5640, Test Accuracy: 24.3660\n",
      "Epoch 130, Loss: 1.9144, Accuracy: 26.2930, Test Loss: 1.5638, Test Accuracy: 24.3685\n",
      "Epoch 131, Loss: 1.9116, Accuracy: 26.3034, Test Loss: 1.5636, Test Accuracy: 24.3709\n",
      "Epoch 132, Loss: 1.9089, Accuracy: 26.3137, Test Loss: 1.5634, Test Accuracy: 24.3734\n",
      "Epoch 133, Loss: 1.9064, Accuracy: 26.3118, Test Loss: 1.5632, Test Accuracy: 24.3758\n",
      "Epoch 134, Loss: 1.9043, Accuracy: 26.3179, Test Loss: 1.5630, Test Accuracy: 24.3781\n",
      "Epoch 135, Loss: 1.9017, Accuracy: 26.3239, Test Loss: 1.5628, Test Accuracy: 24.3804\n",
      "Epoch 136, Loss: 1.8991, Accuracy: 26.3337, Test Loss: 1.5626, Test Accuracy: 24.3827\n",
      "Epoch 137, Loss: 1.8966, Accuracy: 26.3356, Test Loss: 1.5624, Test Accuracy: 24.3850\n",
      "Epoch 138, Loss: 1.8942, Accuracy: 26.3336, Test Loss: 1.5623, Test Accuracy: 24.3872\n",
      "Epoch 139, Loss: 1.8915, Accuracy: 26.3508, Test Loss: 1.5621, Test Accuracy: 24.3894\n",
      "Epoch 140, Loss: 1.8892, Accuracy: 26.3488, Test Loss: 1.5619, Test Accuracy: 24.3915\n",
      "Epoch 141, Loss: 1.8869, Accuracy: 26.3468, Test Loss: 1.5617, Test Accuracy: 24.3937\n",
      "Epoch 142, Loss: 1.8845, Accuracy: 26.3523, Test Loss: 1.5615, Test Accuracy: 24.3958\n",
      "Epoch 143, Loss: 1.8821, Accuracy: 26.3540, Test Loss: 1.5614, Test Accuracy: 24.3978\n",
      "Epoch 144, Loss: 1.8798, Accuracy: 26.3556, Test Loss: 1.5612, Test Accuracy: 24.3999\n",
      "Epoch 145, Loss: 1.8776, Accuracy: 26.3500, Test Loss: 1.5610, Test Accuracy: 24.4019\n",
      "Epoch 146, Loss: 1.8753, Accuracy: 26.3516, Test Loss: 1.5608, Test Accuracy: 24.4039\n",
      "Epoch 147, Loss: 1.8731, Accuracy: 26.3533, Test Loss: 1.5607, Test Accuracy: 24.4058\n",
      "Epoch 148, Loss: 1.8710, Accuracy: 26.3549, Test Loss: 1.5605, Test Accuracy: 24.4077\n",
      "Epoch 149, Loss: 1.8689, Accuracy: 26.3566, Test Loss: 1.5603, Test Accuracy: 24.4096\n",
      "Epoch 150, Loss: 1.8667, Accuracy: 26.3688, Test Loss: 1.5602, Test Accuracy: 24.4115\n",
      "Epoch 151, Loss: 1.8645, Accuracy: 26.3738, Test Loss: 1.5600, Test Accuracy: 24.4134\n",
      "Epoch 152, Loss: 1.8624, Accuracy: 26.3788, Test Loss: 1.5598, Test Accuracy: 24.4152\n",
      "Epoch 153, Loss: 1.8603, Accuracy: 26.3906, Test Loss: 1.5597, Test Accuracy: 24.4170\n",
      "Epoch 154, Loss: 1.8582, Accuracy: 26.4023, Test Loss: 1.5595, Test Accuracy: 24.4188\n",
      "Epoch 155, Loss: 1.8561, Accuracy: 26.4070, Test Loss: 1.5594, Test Accuracy: 24.4205\n",
      "Epoch 156, Loss: 1.8540, Accuracy: 26.4150, Test Loss: 1.5592, Test Accuracy: 24.4223\n",
      "Epoch 157, Loss: 1.8519, Accuracy: 26.4230, Test Loss: 1.5591, Test Accuracy: 24.4240\n",
      "Epoch 158, Loss: 1.8497, Accuracy: 26.4443, Test Loss: 1.5589, Test Accuracy: 24.4257\n",
      "Epoch 159, Loss: 1.8477, Accuracy: 26.4485, Test Loss: 1.5587, Test Accuracy: 24.4274\n",
      "Epoch 160, Loss: 1.8458, Accuracy: 26.4561, Test Loss: 1.5586, Test Accuracy: 24.4290\n",
      "Epoch 161, Loss: 1.8438, Accuracy: 26.4702, Test Loss: 1.5584, Test Accuracy: 24.4306\n",
      "Epoch 162, Loss: 1.8425, Accuracy: 26.4611, Test Loss: 1.5583, Test Accuracy: 24.4323\n",
      "Epoch 163, Loss: 1.8408, Accuracy: 26.4554, Test Loss: 1.5581, Test Accuracy: 24.4338\n",
      "Epoch 164, Loss: 1.8388, Accuracy: 26.4725, Test Loss: 1.5580, Test Accuracy: 24.4354\n",
      "Epoch 165, Loss: 1.8369, Accuracy: 26.4829, Test Loss: 1.5578, Test Accuracy: 24.4370\n",
      "Epoch 166, Loss: 1.8351, Accuracy: 26.4932, Test Loss: 1.5577, Test Accuracy: 24.4385\n",
      "Epoch 167, Loss: 1.8333, Accuracy: 26.4970, Test Loss: 1.5576, Test Accuracy: 24.4400\n",
      "Epoch 168, Loss: 1.8320, Accuracy: 26.4944, Test Loss: 1.5574, Test Accuracy: 24.4415\n",
      "Epoch 169, Loss: 1.8302, Accuracy: 26.4982, Test Loss: 1.5573, Test Accuracy: 24.4430\n",
      "Epoch 170, Loss: 1.8285, Accuracy: 26.5081, Test Loss: 1.5571, Test Accuracy: 24.4444\n",
      "Epoch 171, Loss: 1.8268, Accuracy: 26.5118, Test Loss: 1.5570, Test Accuracy: 24.4459\n",
      "Epoch 172, Loss: 1.8251, Accuracy: 26.5246, Test Loss: 1.5569, Test Accuracy: 24.4473\n",
      "Epoch 173, Loss: 1.8235, Accuracy: 26.5281, Test Loss: 1.5567, Test Accuracy: 24.4487\n",
      "Epoch 174, Loss: 1.8218, Accuracy: 26.5407, Test Loss: 1.5566, Test Accuracy: 24.4501\n",
      "Epoch 175, Loss: 1.8202, Accuracy: 26.5441, Test Loss: 1.5565, Test Accuracy: 24.4515\n",
      "Epoch 176, Loss: 1.8186, Accuracy: 26.5534, Test Loss: 1.5563, Test Accuracy: 24.4529\n",
      "Epoch 177, Loss: 1.8171, Accuracy: 26.5657, Test Loss: 1.5562, Test Accuracy: 24.4542\n",
      "Epoch 178, Loss: 1.8156, Accuracy: 26.5599, Test Loss: 1.5561, Test Accuracy: 24.4555\n",
      "Epoch 179, Loss: 1.8142, Accuracy: 26.5571, Test Loss: 1.5559, Test Accuracy: 24.4569\n",
      "Epoch 180, Loss: 1.8128, Accuracy: 26.5544, Test Loss: 1.5558, Test Accuracy: 24.4582\n",
      "Epoch 181, Loss: 1.8113, Accuracy: 26.5575, Test Loss: 1.5557, Test Accuracy: 24.4594\n",
      "Epoch 182, Loss: 1.8099, Accuracy: 26.5577, Test Loss: 1.5556, Test Accuracy: 24.4607\n",
      "Epoch 183, Loss: 1.8085, Accuracy: 26.5551, Test Loss: 1.5554, Test Accuracy: 24.4620\n",
      "Epoch 184, Loss: 1.8072, Accuracy: 26.5524, Test Loss: 1.5553, Test Accuracy: 24.4632\n",
      "Epoch 185, Loss: 1.8058, Accuracy: 26.5584, Test Loss: 1.5552, Test Accuracy: 24.4645\n",
      "Epoch 186, Loss: 1.8043, Accuracy: 26.5614, Test Loss: 1.5551, Test Accuracy: 24.4657\n",
      "Epoch 187, Loss: 1.8030, Accuracy: 26.5616, Test Loss: 1.5549, Test Accuracy: 24.4669\n",
      "Epoch 188, Loss: 1.8017, Accuracy: 26.5618, Test Loss: 1.5548, Test Accuracy: 24.4681\n",
      "Epoch 189, Loss: 1.8003, Accuracy: 26.5704, Test Loss: 1.5547, Test Accuracy: 24.4693\n",
      "Epoch 190, Loss: 1.7989, Accuracy: 26.5789, Test Loss: 1.5546, Test Accuracy: 24.4704\n",
      "Epoch 191, Loss: 1.7975, Accuracy: 26.5874, Test Loss: 1.5545, Test Accuracy: 24.4716\n",
      "Epoch 192, Loss: 1.7962, Accuracy: 26.5902, Test Loss: 1.5544, Test Accuracy: 24.4727\n",
      "Epoch 193, Loss: 1.7955, Accuracy: 26.5820, Test Loss: 1.5542, Test Accuracy: 24.4739\n",
      "Epoch 194, Loss: 1.7944, Accuracy: 26.5766, Test Loss: 1.5541, Test Accuracy: 24.4750\n",
      "Epoch 195, Loss: 1.7932, Accuracy: 26.5821, Test Loss: 1.5540, Test Accuracy: 24.4761\n",
      "Epoch 196, Loss: 1.7921, Accuracy: 26.5822, Test Loss: 1.5539, Test Accuracy: 24.4772\n",
      "Epoch 197, Loss: 1.7908, Accuracy: 26.5849, Test Loss: 1.5538, Test Accuracy: 24.4783\n",
      "Epoch 198, Loss: 1.7896, Accuracy: 26.5877, Test Loss: 1.5537, Test Accuracy: 24.4794\n",
      "Epoch 199, Loss: 1.7889, Accuracy: 26.5851, Test Loss: 1.5536, Test Accuracy: 24.4804\n",
      "Epoch 200, Loss: 1.7878, Accuracy: 26.5851, Test Loss: 1.5535, Test Accuracy: 24.4815\n",
      "average of 10 each\n",
      "Epoch 1, Loss: 29.6764, Accuracy: 20.2381, Test Loss: 1.5771, Test Accuracy: 19.4444\n",
      "Epoch 2, Loss: 24.5930, Accuracy: 21.7262, Test Loss: 1.5808, Test Accuracy: 19.4444\n",
      "Epoch 3, Loss: 20.1538, Accuracy: 22.4206, Test Loss: 1.5927, Test Accuracy: 19.4444\n",
      "Epoch 4, Loss: 17.1039, Accuracy: 22.4702, Test Loss: 1.6059, Test Accuracy: 19.4444\n",
      "Epoch 5, Loss: 14.6346, Accuracy: 22.2619, Test Loss: 1.6080, Test Accuracy: 19.4444\n",
      "Epoch 6, Loss: 12.6845, Accuracy: 23.8095, Test Loss: 1.6082, Test Accuracy: 19.4444\n",
      "Epoch 7, Loss: 11.1866, Accuracy: 24.3197, Test Loss: 1.6083, Test Accuracy: 19.4444\n",
      "Epoch 8, Loss: 10.0203, Accuracy: 24.3304, Test Loss: 1.6083, Test Accuracy: 19.4444\n",
      "Epoch 9, Loss: 9.0846, Accuracy: 24.5370, Test Loss: 1.6083, Test Accuracy: 19.4444\n",
      "Epoch 10, Loss: 8.3471, Accuracy: 24.9405, Test Loss: 1.6081, Test Accuracy: 19.4444\n",
      "Epoch 11, Loss: 7.7412, Accuracy: 25.1082, Test Loss: 1.6079, Test Accuracy: 19.4444\n",
      "Epoch 12, Loss: 7.2308, Accuracy: 25.2976, Test Loss: 1.6077, Test Accuracy: 19.4444\n",
      "Epoch 13, Loss: 6.7997, Accuracy: 25.4121, Test Loss: 1.6073, Test Accuracy: 19.4444\n",
      "Epoch 14, Loss: 6.4296, Accuracy: 25.6803, Test Loss: 1.6070, Test Accuracy: 19.4444\n",
      "Epoch 15, Loss: 6.1090, Accuracy: 25.8333, Test Loss: 1.6066, Test Accuracy: 19.4444\n",
      "Epoch 16, Loss: 5.8271, Accuracy: 25.9673, Test Loss: 1.6062, Test Accuracy: 19.4444\n",
      "Epoch 17, Loss: 5.5811, Accuracy: 25.9804, Test Loss: 1.6058, Test Accuracy: 19.4444\n",
      "Epoch 18, Loss: 5.3603, Accuracy: 26.0251, Test Loss: 1.6054, Test Accuracy: 19.4444\n",
      "Epoch 19, Loss: 5.1638, Accuracy: 26.1278, Test Loss: 1.6049, Test Accuracy: 19.4444\n",
      "Epoch 20, Loss: 4.9853, Accuracy: 26.1905, Test Loss: 1.6045, Test Accuracy: 19.4444\n",
      "Epoch 21, Loss: 4.8234, Accuracy: 26.2755, Test Loss: 1.6040, Test Accuracy: 19.4444\n",
      "Epoch 22, Loss: 4.6775, Accuracy: 26.3799, Test Loss: 1.6036, Test Accuracy: 19.4444\n",
      "Epoch 23, Loss: 4.5441, Accuracy: 26.4234, Test Loss: 1.6032, Test Accuracy: 19.4444\n",
      "Epoch 24, Loss: 4.4203, Accuracy: 26.4881, Test Loss: 1.6028, Test Accuracy: 19.4444\n",
      "Epoch 25, Loss: 4.3072, Accuracy: 26.5000, Test Loss: 1.6023, Test Accuracy: 19.4444\n",
      "Epoch 26, Loss: 4.2043, Accuracy: 26.5110, Test Loss: 1.6019, Test Accuracy: 19.4444\n",
      "Epoch 27, Loss: 4.1073, Accuracy: 26.5212, Test Loss: 1.6015, Test Accuracy: 19.4444\n",
      "Epoch 28, Loss: 4.0180, Accuracy: 26.5944, Test Loss: 1.6011, Test Accuracy: 19.4444\n",
      "Epoch 29, Loss: 3.9335, Accuracy: 26.6626, Test Loss: 1.6006, Test Accuracy: 19.4444\n",
      "Epoch 30, Loss: 3.8556, Accuracy: 26.7064, Test Loss: 1.6002, Test Accuracy: 19.4444\n",
      "Epoch 31, Loss: 3.7833, Accuracy: 26.7665, Test Loss: 1.5998, Test Accuracy: 19.4444\n",
      "Epoch 32, Loss: 3.7145, Accuracy: 26.8043, Test Loss: 1.5994, Test Accuracy: 19.4444\n",
      "Epoch 33, Loss: 3.6515, Accuracy: 26.8038, Test Loss: 1.5990, Test Accuracy: 19.4444\n",
      "Epoch 34, Loss: 3.5909, Accuracy: 26.8382, Test Loss: 1.5986, Test Accuracy: 19.4444\n",
      "Epoch 35, Loss: 3.5338, Accuracy: 26.8707, Test Loss: 1.5981, Test Accuracy: 19.4444\n",
      "Epoch 36, Loss: 3.4794, Accuracy: 26.9180, Test Loss: 1.5977, Test Accuracy: 19.4444\n",
      "Epoch 37, Loss: 3.4282, Accuracy: 26.9466, Test Loss: 1.5973, Test Accuracy: 19.4444\n",
      "Epoch 38, Loss: 3.3829, Accuracy: 26.9737, Test Loss: 1.5969, Test Accuracy: 19.4444\n",
      "Epoch 39, Loss: 3.3366, Accuracy: 26.9841, Test Loss: 1.5965, Test Accuracy: 19.4444\n",
      "Epoch 40, Loss: 3.2927, Accuracy: 26.9940, Test Loss: 1.5961, Test Accuracy: 19.4444\n",
      "Epoch 41, Loss: 3.2520, Accuracy: 27.0035, Test Loss: 1.5957, Test Accuracy: 19.4444\n",
      "Epoch 42, Loss: 3.2133, Accuracy: 27.0125, Test Loss: 1.5953, Test Accuracy: 19.4444\n",
      "Epoch 43, Loss: 3.1758, Accuracy: 27.0072, Test Loss: 1.5949, Test Accuracy: 19.4444\n",
      "Epoch 44, Loss: 3.1399, Accuracy: 27.0292, Test Loss: 1.5946, Test Accuracy: 19.4444\n",
      "Epoch 45, Loss: 3.1050, Accuracy: 27.0503, Test Loss: 1.5942, Test Accuracy: 19.4444\n",
      "Epoch 46, Loss: 3.0718, Accuracy: 27.0575, Test Loss: 1.5938, Test Accuracy: 19.4444\n",
      "Epoch 47, Loss: 3.0406, Accuracy: 27.0517, Test Loss: 1.5934, Test Accuracy: 19.4444\n",
      "Epoch 48, Loss: 3.0104, Accuracy: 27.0585, Test Loss: 1.5931, Test Accuracy: 19.4444\n",
      "Epoch 49, Loss: 2.9815, Accuracy: 27.0651, Test Loss: 1.5927, Test Accuracy: 19.4444\n",
      "Epoch 50, Loss: 2.9533, Accuracy: 27.0595, Test Loss: 1.5923, Test Accuracy: 19.4444\n",
      "Epoch 51, Loss: 2.9263, Accuracy: 27.0542, Test Loss: 1.5920, Test Accuracy: 19.4444\n",
      "Epoch 52, Loss: 2.9003, Accuracy: 27.0604, Test Loss: 1.5916, Test Accuracy: 19.4444\n",
      "Epoch 53, Loss: 2.8753, Accuracy: 27.0665, Test Loss: 1.5912, Test Accuracy: 19.4444\n",
      "Epoch 54, Loss: 2.8513, Accuracy: 27.0723, Test Loss: 1.5909, Test Accuracy: 19.4444\n",
      "Epoch 55, Loss: 2.8280, Accuracy: 27.0779, Test Loss: 1.5905, Test Accuracy: 19.4444\n",
      "Epoch 56, Loss: 2.8057, Accuracy: 27.0833, Test Loss: 1.5902, Test Accuracy: 19.4444\n",
      "Epoch 57, Loss: 2.7841, Accuracy: 27.0886, Test Loss: 1.5898, Test Accuracy: 19.4444\n",
      "Epoch 58, Loss: 2.7633, Accuracy: 27.0936, Test Loss: 1.5895, Test Accuracy: 19.4444\n",
      "Epoch 59, Loss: 2.7432, Accuracy: 27.0985, Test Loss: 1.5892, Test Accuracy: 19.4444\n",
      "Epoch 60, Loss: 2.7237, Accuracy: 27.1032, Test Loss: 1.5888, Test Accuracy: 19.4444\n",
      "Epoch 61, Loss: 2.7048, Accuracy: 27.1077, Test Loss: 1.5885, Test Accuracy: 19.4444\n",
      "Epoch 62, Loss: 2.6863, Accuracy: 27.1121, Test Loss: 1.5881, Test Accuracy: 19.4444\n",
      "Epoch 63, Loss: 2.6687, Accuracy: 27.1164, Test Loss: 1.5878, Test Accuracy: 19.4444\n",
      "Epoch 64, Loss: 2.6516, Accuracy: 27.1205, Test Loss: 1.5875, Test Accuracy: 19.4444\n",
      "Epoch 65, Loss: 2.6353, Accuracy: 27.1245, Test Loss: 1.5872, Test Accuracy: 19.4444\n",
      "Epoch 66, Loss: 2.6191, Accuracy: 27.1284, Test Loss: 1.5868, Test Accuracy: 19.4444\n",
      "Epoch 67, Loss: 2.6036, Accuracy: 27.1322, Test Loss: 1.5865, Test Accuracy: 19.4444\n",
      "Epoch 68, Loss: 2.5888, Accuracy: 27.1359, Test Loss: 1.5862, Test Accuracy: 19.4444\n",
      "Epoch 69, Loss: 2.5739, Accuracy: 27.1394, Test Loss: 1.5859, Test Accuracy: 19.4444\n",
      "Epoch 70, Loss: 2.5598, Accuracy: 27.1429, Test Loss: 1.5855, Test Accuracy: 19.4444\n",
      "Epoch 71, Loss: 2.5458, Accuracy: 27.1462, Test Loss: 1.5852, Test Accuracy: 19.4444\n",
      "Epoch 72, Loss: 2.5322, Accuracy: 27.1495, Test Loss: 1.5849, Test Accuracy: 19.4444\n",
      "Epoch 73, Loss: 2.5189, Accuracy: 27.1526, Test Loss: 1.5846, Test Accuracy: 19.4444\n",
      "Epoch 74, Loss: 2.5062, Accuracy: 27.1638, Test Loss: 1.5843, Test Accuracy: 19.4444\n",
      "Epoch 75, Loss: 2.4938, Accuracy: 27.1587, Test Loss: 1.5840, Test Accuracy: 19.4444\n",
      "Epoch 76, Loss: 2.4815, Accuracy: 27.1617, Test Loss: 1.5837, Test Accuracy: 19.4444\n",
      "Epoch 77, Loss: 2.4697, Accuracy: 27.1800, Test Loss: 1.5834, Test Accuracy: 19.4444\n",
      "Epoch 78, Loss: 2.4582, Accuracy: 27.1825, Test Loss: 1.5831, Test Accuracy: 19.4444\n",
      "Epoch 79, Loss: 2.4470, Accuracy: 27.1851, Test Loss: 1.5828, Test Accuracy: 19.4444\n",
      "Epoch 80, Loss: 2.4359, Accuracy: 27.1949, Test Loss: 1.5825, Test Accuracy: 19.4444\n",
      "Epoch 81, Loss: 2.4253, Accuracy: 27.1825, Test Loss: 1.5822, Test Accuracy: 19.4444\n",
      "Epoch 82, Loss: 2.4148, Accuracy: 27.1850, Test Loss: 1.5819, Test Accuracy: 19.4444\n",
      "Epoch 83, Loss: 2.4048, Accuracy: 27.1873, Test Loss: 1.5816, Test Accuracy: 19.4444\n",
      "Epoch 84, Loss: 2.3947, Accuracy: 27.2038, Test Loss: 1.5813, Test Accuracy: 19.4444\n",
      "Epoch 85, Loss: 2.3853, Accuracy: 27.2059, Test Loss: 1.5811, Test Accuracy: 19.4444\n",
      "Epoch 86, Loss: 2.3758, Accuracy: 27.2079, Test Loss: 1.5808, Test Accuracy: 19.4444\n",
      "Epoch 87, Loss: 2.3666, Accuracy: 27.2167, Test Loss: 1.5805, Test Accuracy: 19.4444\n",
      "Epoch 88, Loss: 2.3582, Accuracy: 27.2186, Test Loss: 1.5803, Test Accuracy: 19.4444\n",
      "Epoch 89, Loss: 2.3494, Accuracy: 27.2271, Test Loss: 1.5800, Test Accuracy: 19.4444\n",
      "Epoch 90, Loss: 2.3407, Accuracy: 27.2354, Test Loss: 1.5798, Test Accuracy: 19.4444\n",
      "Epoch 91, Loss: 2.3323, Accuracy: 27.2370, Test Loss: 1.5795, Test Accuracy: 19.4444\n",
      "Epoch 92, Loss: 2.3242, Accuracy: 27.2451, Test Loss: 1.5793, Test Accuracy: 19.4444\n",
      "Epoch 93, Loss: 2.3168, Accuracy: 27.2465, Test Loss: 1.5790, Test Accuracy: 19.4444\n",
      "Epoch 94, Loss: 2.3088, Accuracy: 27.2480, Test Loss: 1.5788, Test Accuracy: 19.4444\n",
      "Epoch 95, Loss: 2.3010, Accuracy: 27.2494, Test Loss: 1.5785, Test Accuracy: 19.4444\n",
      "Epoch 96, Loss: 2.2933, Accuracy: 27.2507, Test Loss: 1.5783, Test Accuracy: 19.4444\n",
      "Epoch 97, Loss: 2.2858, Accuracy: 27.2521, Test Loss: 1.5781, Test Accuracy: 19.4444\n",
      "Epoch 98, Loss: 2.2784, Accuracy: 27.2534, Test Loss: 1.5778, Test Accuracy: 19.4444\n",
      "Epoch 99, Loss: 2.2713, Accuracy: 27.2547, Test Loss: 1.5776, Test Accuracy: 19.4444\n",
      "Epoch 100, Loss: 2.2642, Accuracy: 27.2560, Test Loss: 1.5774, Test Accuracy: 19.4444\n",
      "Epoch 101, Loss: 2.2572, Accuracy: 27.2572, Test Loss: 1.5771, Test Accuracy: 19.4444\n",
      "Epoch 102, Loss: 2.2505, Accuracy: 27.2584, Test Loss: 1.5769, Test Accuracy: 19.4444\n",
      "Epoch 103, Loss: 2.2437, Accuracy: 27.2596, Test Loss: 1.5767, Test Accuracy: 19.4444\n",
      "Epoch 104, Loss: 2.2371, Accuracy: 27.2608, Test Loss: 1.5764, Test Accuracy: 19.4444\n",
      "Epoch 105, Loss: 2.2306, Accuracy: 27.2619, Test Loss: 1.5762, Test Accuracy: 19.4444\n",
      "Epoch 106, Loss: 2.2241, Accuracy: 27.2630, Test Loss: 1.5760, Test Accuracy: 19.4444\n",
      "Epoch 107, Loss: 2.2180, Accuracy: 27.2641, Test Loss: 1.5757, Test Accuracy: 19.4444\n",
      "Epoch 108, Loss: 2.2119, Accuracy: 27.2652, Test Loss: 1.5755, Test Accuracy: 19.4444\n",
      "Epoch 109, Loss: 2.2062, Accuracy: 27.2663, Test Loss: 1.5753, Test Accuracy: 19.4444\n",
      "Epoch 110, Loss: 2.2004, Accuracy: 27.2673, Test Loss: 1.5751, Test Accuracy: 19.4444\n",
      "Epoch 111, Loss: 2.1945, Accuracy: 27.2683, Test Loss: 1.5749, Test Accuracy: 19.4444\n",
      "Epoch 112, Loss: 2.1889, Accuracy: 27.2693, Test Loss: 1.5747, Test Accuracy: 19.4444\n",
      "Epoch 113, Loss: 2.1833, Accuracy: 27.2703, Test Loss: 1.5744, Test Accuracy: 19.4444\n",
      "Epoch 114, Loss: 2.1778, Accuracy: 27.2713, Test Loss: 1.5742, Test Accuracy: 19.4444\n",
      "Epoch 115, Loss: 2.1724, Accuracy: 27.2723, Test Loss: 1.5740, Test Accuracy: 19.4444\n",
      "Epoch 116, Loss: 2.1672, Accuracy: 27.2732, Test Loss: 1.5738, Test Accuracy: 19.4444\n",
      "Epoch 117, Loss: 2.1619, Accuracy: 27.2741, Test Loss: 1.5736, Test Accuracy: 19.4444\n",
      "Epoch 118, Loss: 2.1568, Accuracy: 27.2750, Test Loss: 1.5734, Test Accuracy: 19.4444\n",
      "Epoch 119, Loss: 2.1518, Accuracy: 27.2759, Test Loss: 1.5732, Test Accuracy: 19.4444\n",
      "Epoch 120, Loss: 2.1470, Accuracy: 27.2768, Test Loss: 1.5730, Test Accuracy: 19.4444\n",
      "Epoch 121, Loss: 2.1422, Accuracy: 27.2776, Test Loss: 1.5728, Test Accuracy: 19.4444\n",
      "Epoch 122, Loss: 2.1374, Accuracy: 27.2785, Test Loss: 1.5726, Test Accuracy: 19.4444\n",
      "Epoch 123, Loss: 2.1327, Accuracy: 27.2793, Test Loss: 1.5724, Test Accuracy: 19.4444\n",
      "Epoch 124, Loss: 2.1281, Accuracy: 27.2801, Test Loss: 1.5722, Test Accuracy: 19.4444\n",
      "Epoch 125, Loss: 2.1236, Accuracy: 27.2810, Test Loss: 1.5720, Test Accuracy: 19.4444\n",
      "Epoch 126, Loss: 2.1192, Accuracy: 27.2817, Test Loss: 1.5718, Test Accuracy: 19.4444\n",
      "Epoch 127, Loss: 2.1149, Accuracy: 27.2825, Test Loss: 1.5716, Test Accuracy: 19.4444\n",
      "Epoch 128, Loss: 2.1105, Accuracy: 27.2833, Test Loss: 1.5714, Test Accuracy: 19.4444\n",
      "Epoch 129, Loss: 2.1063, Accuracy: 27.2841, Test Loss: 1.5712, Test Accuracy: 19.4444\n",
      "Epoch 130, Loss: 2.1022, Accuracy: 27.2848, Test Loss: 1.5710, Test Accuracy: 19.4444\n",
      "Epoch 131, Loss: 2.0981, Accuracy: 27.2855, Test Loss: 1.5708, Test Accuracy: 19.4444\n",
      "Epoch 132, Loss: 2.0940, Accuracy: 27.2863, Test Loss: 1.5706, Test Accuracy: 19.4444\n",
      "Epoch 133, Loss: 2.0900, Accuracy: 27.2870, Test Loss: 1.5705, Test Accuracy: 19.4444\n",
      "Epoch 134, Loss: 2.0861, Accuracy: 27.2877, Test Loss: 1.5703, Test Accuracy: 19.4444\n",
      "Epoch 135, Loss: 2.0821, Accuracy: 27.2884, Test Loss: 1.5701, Test Accuracy: 19.4444\n",
      "Epoch 136, Loss: 2.0783, Accuracy: 27.2890, Test Loss: 1.5699, Test Accuracy: 19.4444\n",
      "Epoch 137, Loss: 2.0745, Accuracy: 27.2897, Test Loss: 1.5698, Test Accuracy: 19.4444\n",
      "Epoch 138, Loss: 2.0710, Accuracy: 27.2904, Test Loss: 1.5696, Test Accuracy: 19.4444\n",
      "Epoch 139, Loss: 2.0674, Accuracy: 27.2910, Test Loss: 1.5694, Test Accuracy: 19.4444\n",
      "Epoch 140, Loss: 2.0638, Accuracy: 27.2917, Test Loss: 1.5692, Test Accuracy: 19.4444\n",
      "Epoch 141, Loss: 2.0602, Accuracy: 27.2923, Test Loss: 1.5691, Test Accuracy: 19.4444\n",
      "Epoch 142, Loss: 2.0567, Accuracy: 27.2929, Test Loss: 1.5689, Test Accuracy: 19.4444\n",
      "Epoch 143, Loss: 2.0532, Accuracy: 27.2935, Test Loss: 1.5687, Test Accuracy: 19.4444\n",
      "Epoch 144, Loss: 2.0498, Accuracy: 27.2941, Test Loss: 1.5686, Test Accuracy: 19.4444\n",
      "Epoch 145, Loss: 2.0462, Accuracy: 27.2947, Test Loss: 1.5684, Test Accuracy: 19.4444\n",
      "Epoch 146, Loss: 2.0428, Accuracy: 27.2953, Test Loss: 1.5682, Test Accuracy: 19.4444\n",
      "Epoch 147, Loss: 2.0395, Accuracy: 27.2959, Test Loss: 1.5681, Test Accuracy: 19.4444\n",
      "Epoch 148, Loss: 2.0362, Accuracy: 27.3005, Test Loss: 1.5679, Test Accuracy: 19.4444\n",
      "Epoch 149, Loss: 2.0330, Accuracy: 27.3011, Test Loss: 1.5677, Test Accuracy: 19.4444\n",
      "Epoch 150, Loss: 2.0299, Accuracy: 27.3016, Test Loss: 1.5676, Test Accuracy: 19.4444\n",
      "Epoch 151, Loss: 2.0269, Accuracy: 27.3021, Test Loss: 1.5674, Test Accuracy: 19.4444\n",
      "Epoch 152, Loss: 2.0239, Accuracy: 27.3026, Test Loss: 1.5673, Test Accuracy: 19.4444\n",
      "Epoch 153, Loss: 2.0208, Accuracy: 27.3070, Test Loss: 1.5671, Test Accuracy: 19.4444\n",
      "Epoch 154, Loss: 2.0178, Accuracy: 27.3152, Test Loss: 1.5670, Test Accuracy: 19.4444\n",
      "Epoch 155, Loss: 2.0152, Accuracy: 27.3118, Test Loss: 1.5668, Test Accuracy: 19.4444\n",
      "Epoch 156, Loss: 2.0122, Accuracy: 27.3123, Test Loss: 1.5666, Test Accuracy: 19.4444\n",
      "Epoch 157, Loss: 2.0093, Accuracy: 27.3127, Test Loss: 1.5665, Test Accuracy: 19.4444\n",
      "Epoch 158, Loss: 2.0065, Accuracy: 27.3131, Test Loss: 1.5663, Test Accuracy: 19.4444\n",
      "Epoch 159, Loss: 2.0036, Accuracy: 27.3136, Test Loss: 1.5662, Test Accuracy: 19.4444\n",
      "Epoch 160, Loss: 2.0008, Accuracy: 27.3140, Test Loss: 1.5660, Test Accuracy: 19.4444\n",
      "Epoch 161, Loss: 1.9981, Accuracy: 27.3144, Test Loss: 1.5659, Test Accuracy: 19.4444\n",
      "Epoch 162, Loss: 1.9953, Accuracy: 27.3148, Test Loss: 1.5657, Test Accuracy: 19.4444\n",
      "Epoch 163, Loss: 1.9926, Accuracy: 27.3152, Test Loss: 1.5656, Test Accuracy: 19.4444\n",
      "Epoch 164, Loss: 1.9901, Accuracy: 27.3156, Test Loss: 1.5654, Test Accuracy: 19.4444\n",
      "Epoch 165, Loss: 1.9880, Accuracy: 27.3124, Test Loss: 1.5653, Test Accuracy: 19.4444\n",
      "Epoch 166, Loss: 1.9854, Accuracy: 27.3128, Test Loss: 1.5652, Test Accuracy: 19.4444\n",
      "Epoch 167, Loss: 1.9828, Accuracy: 27.3132, Test Loss: 1.5650, Test Accuracy: 19.4444\n",
      "Epoch 168, Loss: 1.9803, Accuracy: 27.3136, Test Loss: 1.5649, Test Accuracy: 19.4444\n",
      "Epoch 169, Loss: 1.9776, Accuracy: 27.3140, Test Loss: 1.5647, Test Accuracy: 19.4444\n",
      "Epoch 170, Loss: 1.9751, Accuracy: 27.3144, Test Loss: 1.5646, Test Accuracy: 19.4444\n",
      "Epoch 171, Loss: 1.9727, Accuracy: 27.3148, Test Loss: 1.5645, Test Accuracy: 19.4444\n",
      "Epoch 172, Loss: 1.9702, Accuracy: 27.3152, Test Loss: 1.5643, Test Accuracy: 19.4444\n",
      "Epoch 173, Loss: 1.9679, Accuracy: 27.3156, Test Loss: 1.5642, Test Accuracy: 19.4444\n",
      "Epoch 174, Loss: 1.9655, Accuracy: 27.3160, Test Loss: 1.5641, Test Accuracy: 19.4444\n",
      "Epoch 175, Loss: 1.9631, Accuracy: 27.3163, Test Loss: 1.5639, Test Accuracy: 19.4444\n",
      "Epoch 176, Loss: 1.9609, Accuracy: 27.3167, Test Loss: 1.5638, Test Accuracy: 19.4444\n",
      "Epoch 177, Loss: 1.9586, Accuracy: 27.3171, Test Loss: 1.5637, Test Accuracy: 19.4444\n",
      "Epoch 178, Loss: 1.9564, Accuracy: 27.3174, Test Loss: 1.5635, Test Accuracy: 19.4444\n",
      "Epoch 179, Loss: 1.9541, Accuracy: 27.3178, Test Loss: 1.5634, Test Accuracy: 19.4444\n",
      "Epoch 180, Loss: 1.9520, Accuracy: 27.3181, Test Loss: 1.5633, Test Accuracy: 19.4444\n",
      "Epoch 181, Loss: 1.9498, Accuracy: 27.3185, Test Loss: 1.5632, Test Accuracy: 19.4444\n",
      "Epoch 182, Loss: 1.9477, Accuracy: 27.3188, Test Loss: 1.5630, Test Accuracy: 19.4444\n",
      "Epoch 183, Loss: 1.9456, Accuracy: 27.3192, Test Loss: 1.5629, Test Accuracy: 19.4444\n",
      "Epoch 184, Loss: 1.9434, Accuracy: 27.3195, Test Loss: 1.5628, Test Accuracy: 19.4444\n",
      "Epoch 185, Loss: 1.9413, Accuracy: 27.3198, Test Loss: 1.5627, Test Accuracy: 19.4444\n",
      "Epoch 186, Loss: 1.9392, Accuracy: 27.3202, Test Loss: 1.5625, Test Accuracy: 19.4444\n",
      "Epoch 187, Loss: 1.9372, Accuracy: 27.3205, Test Loss: 1.5624, Test Accuracy: 19.4444\n",
      "Epoch 188, Loss: 1.9351, Accuracy: 27.3208, Test Loss: 1.5623, Test Accuracy: 19.4444\n",
      "Epoch 189, Loss: 1.9331, Accuracy: 27.3211, Test Loss: 1.5622, Test Accuracy: 19.4444\n",
      "Epoch 190, Loss: 1.9310, Accuracy: 27.3214, Test Loss: 1.5620, Test Accuracy: 19.4444\n",
      "Epoch 191, Loss: 1.9290, Accuracy: 27.3217, Test Loss: 1.5619, Test Accuracy: 19.4444\n",
      "Epoch 192, Loss: 1.9272, Accuracy: 27.3220, Test Loss: 1.5618, Test Accuracy: 19.4444\n",
      "Epoch 193, Loss: 1.9253, Accuracy: 27.3224, Test Loss: 1.5617, Test Accuracy: 19.4444\n",
      "Epoch 194, Loss: 1.9233, Accuracy: 27.3227, Test Loss: 1.5616, Test Accuracy: 19.4444\n",
      "Epoch 195, Loss: 1.9214, Accuracy: 27.3230, Test Loss: 1.5614, Test Accuracy: 19.4444\n",
      "Epoch 196, Loss: 1.9195, Accuracy: 27.3233, Test Loss: 1.5613, Test Accuracy: 19.4444\n",
      "Epoch 197, Loss: 1.9177, Accuracy: 27.3235, Test Loss: 1.5612, Test Accuracy: 19.4444\n",
      "Epoch 198, Loss: 1.9158, Accuracy: 27.3238, Test Loss: 1.5611, Test Accuracy: 19.4444\n",
      "Epoch 199, Loss: 1.9141, Accuracy: 27.3241, Test Loss: 1.5610, Test Accuracy: 19.4444\n",
      "Epoch 200, Loss: 1.9123, Accuracy: 27.3244, Test Loss: 1.5609, Test Accuracy: 19.4444\n",
      "average of 11 each\n",
      "Epoch 1, Loss: 21.6266, Accuracy: 22.7273, Test Loss: 1.6355, Test Accuracy: 13.4328\n",
      "Epoch 2, Loss: 19.2965, Accuracy: 22.7273, Test Loss: 1.6329, Test Accuracy: 18.6567\n",
      "Epoch 3, Loss: 16.0438, Accuracy: 22.0779, Test Loss: 1.6223, Test Accuracy: 24.8756\n",
      "Epoch 4, Loss: 14.3294, Accuracy: 22.5649, Test Loss: 1.6185, Test Accuracy: 26.1194\n",
      "Epoch 5, Loss: 12.8704, Accuracy: 22.7273, Test Loss: 1.6170, Test Accuracy: 26.8657\n",
      "Epoch 6, Loss: 11.5301, Accuracy: 23.4848, Test Loss: 1.6157, Test Accuracy: 26.6169\n",
      "Epoch 7, Loss: 10.3284, Accuracy: 24.4898, Test Loss: 1.6140, Test Accuracy: 26.4392\n",
      "Epoch 8, Loss: 9.3599, Accuracy: 24.1071, Test Loss: 1.6130, Test Accuracy: 26.3060\n",
      "Epoch 9, Loss: 8.5821, Accuracy: 24.1703, Test Loss: 1.6123, Test Accuracy: 26.2023\n",
      "Epoch 10, Loss: 7.9412, Accuracy: 24.5455, Test Loss: 1.6116, Test Accuracy: 26.1194\n",
      "Epoch 11, Loss: 7.3722, Accuracy: 24.6753, Test Loss: 1.6110, Test Accuracy: 26.0516\n",
      "Epoch 12, Loss: 6.8958, Accuracy: 24.6753, Test Loss: 1.6105, Test Accuracy: 25.9950\n",
      "Epoch 13, Loss: 6.4907, Accuracy: 25.0250, Test Loss: 1.6100, Test Accuracy: 25.9472\n",
      "Epoch 14, Loss: 6.1548, Accuracy: 24.9536, Test Loss: 1.6096, Test Accuracy: 25.9062\n",
      "Epoch 15, Loss: 5.8512, Accuracy: 24.9784, Test Loss: 1.6092, Test Accuracy: 25.8706\n",
      "Epoch 16, Loss: 5.5868, Accuracy: 24.9594, Test Loss: 1.6088, Test Accuracy: 25.8396\n",
      "Epoch 17, Loss: 5.3555, Accuracy: 24.9809, Test Loss: 1.6084, Test Accuracy: 25.8121\n",
      "Epoch 18, Loss: 5.1454, Accuracy: 25.1443, Test Loss: 1.6080, Test Accuracy: 25.7877\n",
      "Epoch 19, Loss: 4.9626, Accuracy: 25.1538, Test Loss: 1.6077, Test Accuracy: 25.7659\n",
      "Epoch 20, Loss: 4.7949, Accuracy: 25.1299, Test Loss: 1.6073, Test Accuracy: 25.7463\n",
      "Epoch 21, Loss: 4.6417, Accuracy: 25.2319, Test Loss: 1.6070, Test Accuracy: 25.3731\n",
      "Epoch 22, Loss: 4.5032, Accuracy: 25.2952, Test Loss: 1.6067, Test Accuracy: 25.0339\n",
      "Epoch 23, Loss: 4.3764, Accuracy: 25.4094, Test Loss: 1.6064, Test Accuracy: 24.7242\n",
      "Epoch 24, Loss: 4.2614, Accuracy: 25.4870, Test Loss: 1.6061, Test Accuracy: 24.4403\n",
      "Epoch 25, Loss: 4.1540, Accuracy: 25.5584, Test Loss: 1.6058, Test Accuracy: 24.1791\n",
      "Epoch 26, Loss: 4.0556, Accuracy: 25.6494, Test Loss: 1.6055, Test Accuracy: 23.9380\n",
      "Epoch 27, Loss: 3.9636, Accuracy: 25.7576, Test Loss: 1.6053, Test Accuracy: 23.7148\n",
      "Epoch 28, Loss: 3.8801, Accuracy: 25.8349, Test Loss: 1.6050, Test Accuracy: 23.5075\n",
      "Epoch 29, Loss: 3.8004, Accuracy: 25.9516, Test Loss: 1.6047, Test Accuracy: 23.3145\n",
      "Epoch 30, Loss: 3.7291, Accuracy: 26.0390, Test Loss: 1.6045, Test Accuracy: 23.1343\n",
      "Epoch 31, Loss: 3.6608, Accuracy: 26.1207, Test Loss: 1.6042, Test Accuracy: 22.9658\n",
      "Epoch 32, Loss: 3.5969, Accuracy: 26.1364, Test Loss: 1.6040, Test Accuracy: 22.8078\n",
      "Epoch 33, Loss: 3.5370, Accuracy: 26.2102, Test Loss: 1.6038, Test Accuracy: 22.6594\n",
      "Epoch 34, Loss: 3.4806, Accuracy: 26.2414, Test Loss: 1.6036, Test Accuracy: 22.5198\n",
      "Epoch 35, Loss: 3.4261, Accuracy: 26.2709, Test Loss: 1.6034, Test Accuracy: 22.3881\n",
      "Epoch 36, Loss: 3.3745, Accuracy: 26.2987, Test Loss: 1.6031, Test Accuracy: 22.2637\n",
      "Epoch 37, Loss: 3.3271, Accuracy: 26.3250, Test Loss: 1.6029, Test Accuracy: 22.1460\n",
      "Epoch 38, Loss: 3.2811, Accuracy: 26.3671, Test Loss: 1.6027, Test Accuracy: 22.0346\n",
      "Epoch 39, Loss: 3.2371, Accuracy: 26.3903, Test Loss: 1.6025, Test Accuracy: 21.9288\n",
      "Epoch 40, Loss: 3.1957, Accuracy: 26.4286, Test Loss: 1.6024, Test Accuracy: 21.8284\n",
      "Epoch 41, Loss: 3.1568, Accuracy: 26.4650, Test Loss: 1.6022, Test Accuracy: 21.7328\n",
      "Epoch 42, Loss: 3.1198, Accuracy: 26.4997, Test Loss: 1.6020, Test Accuracy: 21.6418\n",
      "Epoch 43, Loss: 3.0837, Accuracy: 26.5630, Test Loss: 1.6018, Test Accuracy: 21.5550\n",
      "Epoch 44, Loss: 3.0505, Accuracy: 26.5643, Test Loss: 1.6016, Test Accuracy: 21.4722\n",
      "Epoch 45, Loss: 3.0176, Accuracy: 26.6089, Test Loss: 1.6014, Test Accuracy: 21.3930\n",
      "Epoch 46, Loss: 2.9864, Accuracy: 26.6375, Test Loss: 1.6013, Test Accuracy: 21.3173\n",
      "Epoch 47, Loss: 2.9569, Accuracy: 26.6786, Test Loss: 1.6011, Test Accuracy: 21.2448\n",
      "Epoch 48, Loss: 2.9281, Accuracy: 26.7045, Test Loss: 1.6009, Test Accuracy: 21.1754\n",
      "Epoch 49, Loss: 2.9003, Accuracy: 26.7426, Test Loss: 1.6008, Test Accuracy: 21.1087\n",
      "Epoch 50, Loss: 2.8737, Accuracy: 26.7662, Test Loss: 1.6006, Test Accuracy: 21.0448\n",
      "Epoch 51, Loss: 2.8489, Accuracy: 26.7889, Test Loss: 1.6005, Test Accuracy: 20.9833\n",
      "Epoch 52, Loss: 2.8243, Accuracy: 26.8107, Test Loss: 1.6003, Test Accuracy: 20.9242\n",
      "Epoch 53, Loss: 2.8010, Accuracy: 26.8194, Test Loss: 1.6002, Test Accuracy: 20.8674\n",
      "Epoch 54, Loss: 2.7782, Accuracy: 26.8398, Test Loss: 1.6000, Test Accuracy: 20.8126\n",
      "Epoch 55, Loss: 2.7562, Accuracy: 26.8595, Test Loss: 1.5999, Test Accuracy: 20.7598\n",
      "Epoch 56, Loss: 2.7350, Accuracy: 26.8785, Test Loss: 1.5998, Test Accuracy: 20.7090\n",
      "Epoch 57, Loss: 2.7144, Accuracy: 26.9082, Test Loss: 1.5996, Test Accuracy: 20.6599\n",
      "Epoch 58, Loss: 2.6945, Accuracy: 26.9369, Test Loss: 1.5995, Test Accuracy: 20.6125\n",
      "Epoch 59, Loss: 2.6752, Accuracy: 26.9646, Test Loss: 1.5994, Test Accuracy: 20.5667\n",
      "Epoch 60, Loss: 2.6567, Accuracy: 26.9913, Test Loss: 1.5993, Test Accuracy: 20.5224\n",
      "Epoch 61, Loss: 2.6389, Accuracy: 27.0066, Test Loss: 1.5992, Test Accuracy: 20.4796\n",
      "Epoch 62, Loss: 2.6216, Accuracy: 27.0214, Test Loss: 1.5990, Test Accuracy: 20.4381\n",
      "Epoch 63, Loss: 2.6059, Accuracy: 27.0357, Test Loss: 1.5989, Test Accuracy: 20.3980\n",
      "Epoch 64, Loss: 2.5895, Accuracy: 27.0597, Test Loss: 1.5988, Test Accuracy: 20.3591\n",
      "Epoch 65, Loss: 2.5748, Accuracy: 27.0829, Test Loss: 1.5987, Test Accuracy: 20.3215\n",
      "Epoch 66, Loss: 2.5595, Accuracy: 27.0858, Test Loss: 1.5986, Test Accuracy: 20.2849\n",
      "Epoch 67, Loss: 2.5449, Accuracy: 27.0789, Test Loss: 1.5985, Test Accuracy: 20.2495\n",
      "Epoch 68, Loss: 2.5304, Accuracy: 27.0913, Test Loss: 1.5984, Test Accuracy: 20.2151\n",
      "Epoch 69, Loss: 2.5164, Accuracy: 27.1033, Test Loss: 1.5983, Test Accuracy: 20.1817\n",
      "Epoch 70, Loss: 2.5028, Accuracy: 27.1150, Test Loss: 1.5982, Test Accuracy: 20.1493\n",
      "Epoch 71, Loss: 2.4895, Accuracy: 27.1264, Test Loss: 1.5981, Test Accuracy: 20.1177\n",
      "Epoch 72, Loss: 2.4765, Accuracy: 27.1374, Test Loss: 1.5980, Test Accuracy: 20.0871\n",
      "Epoch 73, Loss: 2.4640, Accuracy: 27.1482, Test Loss: 1.5979, Test Accuracy: 20.0572\n",
      "Epoch 74, Loss: 2.4519, Accuracy: 27.1587, Test Loss: 1.5979, Test Accuracy: 20.0282\n",
      "Epoch 75, Loss: 2.4400, Accuracy: 27.1688, Test Loss: 1.5978, Test Accuracy: 20.0000\n",
      "Epoch 76, Loss: 2.4284, Accuracy: 27.1787, Test Loss: 1.5977, Test Accuracy: 19.9725\n",
      "Epoch 77, Loss: 2.4172, Accuracy: 27.1884, Test Loss: 1.5976, Test Accuracy: 19.9457\n",
      "Epoch 78, Loss: 2.4062, Accuracy: 27.1978, Test Loss: 1.5975, Test Accuracy: 19.9196\n",
      "Epoch 79, Loss: 2.3955, Accuracy: 27.2070, Test Loss: 1.5975, Test Accuracy: 19.8942\n",
      "Epoch 80, Loss: 2.3859, Accuracy: 27.2159, Test Loss: 1.5974, Test Accuracy: 19.8694\n",
      "Epoch 81, Loss: 2.3757, Accuracy: 27.2246, Test Loss: 1.5973, Test Accuracy: 19.8452\n",
      "Epoch 82, Loss: 2.3660, Accuracy: 27.2331, Test Loss: 1.5973, Test Accuracy: 19.8216\n",
      "Epoch 83, Loss: 2.3563, Accuracy: 27.2414, Test Loss: 1.5972, Test Accuracy: 19.7986\n",
      "Epoch 84, Loss: 2.3468, Accuracy: 27.2495, Test Loss: 1.5971, Test Accuracy: 19.7761\n",
      "Epoch 85, Loss: 2.3376, Accuracy: 27.2574, Test Loss: 1.5971, Test Accuracy: 19.7542\n",
      "Epoch 86, Loss: 2.3285, Accuracy: 27.2652, Test Loss: 1.5970, Test Accuracy: 19.7327\n",
      "Epoch 87, Loss: 2.3197, Accuracy: 27.2727, Test Loss: 1.5970, Test Accuracy: 19.7118\n",
      "Epoch 88, Loss: 2.3110, Accuracy: 27.2801, Test Loss: 1.5969, Test Accuracy: 19.6913\n",
      "Epoch 89, Loss: 2.3024, Accuracy: 27.2873, Test Loss: 1.5969, Test Accuracy: 19.6713\n",
      "Epoch 90, Loss: 2.2942, Accuracy: 27.2944, Test Loss: 1.5968, Test Accuracy: 19.6517\n",
      "Epoch 91, Loss: 2.2860, Accuracy: 27.3013, Test Loss: 1.5968, Test Accuracy: 19.6326\n",
      "Epoch 92, Loss: 2.2784, Accuracy: 27.3080, Test Loss: 1.5967, Test Accuracy: 19.6139\n",
      "Epoch 93, Loss: 2.2706, Accuracy: 27.3216, Test Loss: 1.5967, Test Accuracy: 19.5956\n",
      "Epoch 94, Loss: 2.2630, Accuracy: 27.3280, Test Loss: 1.5966, Test Accuracy: 19.5776\n",
      "Epoch 95, Loss: 2.2556, Accuracy: 27.3342, Test Loss: 1.5966, Test Accuracy: 19.5601\n",
      "Epoch 96, Loss: 2.2482, Accuracy: 27.3404, Test Loss: 1.5965, Test Accuracy: 19.5429\n",
      "Epoch 97, Loss: 2.2410, Accuracy: 27.3464, Test Loss: 1.5965, Test Accuracy: 19.5261\n",
      "Epoch 98, Loss: 2.2341, Accuracy: 27.3522, Test Loss: 1.5965, Test Accuracy: 19.5096\n",
      "Epoch 99, Loss: 2.2272, Accuracy: 27.3580, Test Loss: 1.5964, Test Accuracy: 19.4934\n",
      "Epoch 100, Loss: 2.2205, Accuracy: 27.3636, Test Loss: 1.5964, Test Accuracy: 19.4776\n",
      "Epoch 101, Loss: 2.2139, Accuracy: 27.3692, Test Loss: 1.5963, Test Accuracy: 19.4621\n",
      "Epoch 102, Loss: 2.2076, Accuracy: 27.3746, Test Loss: 1.5963, Test Accuracy: 19.4469\n",
      "Epoch 103, Loss: 2.2012, Accuracy: 27.3799, Test Loss: 1.5963, Test Accuracy: 19.4320\n",
      "Epoch 104, Loss: 2.1949, Accuracy: 27.3851, Test Loss: 1.5963, Test Accuracy: 19.4173\n",
      "Epoch 105, Loss: 2.1888, Accuracy: 27.3902, Test Loss: 1.5962, Test Accuracy: 19.4030\n",
      "Epoch 106, Loss: 2.1828, Accuracy: 27.3952, Test Loss: 1.5962, Test Accuracy: 19.3889\n",
      "Epoch 107, Loss: 2.1769, Accuracy: 27.4002, Test Loss: 1.5962, Test Accuracy: 19.3751\n",
      "Epoch 108, Loss: 2.1711, Accuracy: 27.4050, Test Loss: 1.5961, Test Accuracy: 19.3615\n",
      "Epoch 109, Loss: 2.1655, Accuracy: 27.4157, Test Loss: 1.5961, Test Accuracy: 19.3482\n",
      "Epoch 110, Loss: 2.1599, Accuracy: 27.4203, Test Loss: 1.5961, Test Accuracy: 19.3351\n",
      "Epoch 111, Loss: 2.1545, Accuracy: 27.4248, Test Loss: 1.5961, Test Accuracy: 19.3223\n",
      "Epoch 112, Loss: 2.1491, Accuracy: 27.4235, Test Loss: 1.5961, Test Accuracy: 19.3097\n",
      "Epoch 113, Loss: 2.1437, Accuracy: 27.4336, Test Loss: 1.5960, Test Accuracy: 19.2973\n",
      "Epoch 114, Loss: 2.1385, Accuracy: 27.4379, Test Loss: 1.5960, Test Accuracy: 19.2852\n",
      "Epoch 115, Loss: 2.1335, Accuracy: 27.4421, Test Loss: 1.5960, Test Accuracy: 19.2732\n",
      "Epoch 116, Loss: 2.1284, Accuracy: 27.4519, Test Loss: 1.5960, Test Accuracy: 19.2615\n",
      "Epoch 117, Loss: 2.1236, Accuracy: 27.4448, Test Loss: 1.5960, Test Accuracy: 19.2499\n",
      "Epoch 118, Loss: 2.1187, Accuracy: 27.4488, Test Loss: 1.5959, Test Accuracy: 19.2386\n",
      "Epoch 119, Loss: 2.1139, Accuracy: 27.4528, Test Loss: 1.5959, Test Accuracy: 19.2274\n",
      "Epoch 120, Loss: 2.1091, Accuracy: 27.4567, Test Loss: 1.5959, Test Accuracy: 19.2164\n",
      "Epoch 121, Loss: 2.1045, Accuracy: 27.4606, Test Loss: 1.5959, Test Accuracy: 19.2056\n",
      "Epoch 122, Loss: 2.1003, Accuracy: 27.4643, Test Loss: 1.5959, Test Accuracy: 19.1950\n",
      "Epoch 123, Loss: 2.0957, Accuracy: 27.4681, Test Loss: 1.5959, Test Accuracy: 19.1846\n",
      "Epoch 124, Loss: 2.0913, Accuracy: 27.4717, Test Loss: 1.5959, Test Accuracy: 19.1743\n",
      "Epoch 125, Loss: 2.0870, Accuracy: 27.4753, Test Loss: 1.5959, Test Accuracy: 19.1642\n",
      "Epoch 126, Loss: 2.0828, Accuracy: 27.4789, Test Loss: 1.5959, Test Accuracy: 19.1542\n",
      "Epoch 127, Loss: 2.0786, Accuracy: 27.4824, Test Loss: 1.5958, Test Accuracy: 19.1444\n",
      "Epoch 128, Loss: 2.0744, Accuracy: 27.4858, Test Loss: 1.5958, Test Accuracy: 19.1348\n",
      "Epoch 129, Loss: 2.0707, Accuracy: 27.4892, Test Loss: 1.5958, Test Accuracy: 19.1253\n",
      "Epoch 130, Loss: 2.0676, Accuracy: 27.4925, Test Loss: 1.5958, Test Accuracy: 19.1160\n",
      "Epoch 131, Loss: 2.0637, Accuracy: 27.4958, Test Loss: 1.5958, Test Accuracy: 19.1068\n",
      "Epoch 132, Loss: 2.0598, Accuracy: 27.4990, Test Loss: 1.5958, Test Accuracy: 19.0977\n",
      "Epoch 133, Loss: 2.0560, Accuracy: 27.5022, Test Loss: 1.5958, Test Accuracy: 19.0888\n",
      "Epoch 134, Loss: 2.0522, Accuracy: 27.5053, Test Loss: 1.5958, Test Accuracy: 19.0800\n",
      "Epoch 135, Loss: 2.0485, Accuracy: 27.5084, Test Loss: 1.5958, Test Accuracy: 19.0713\n",
      "Epoch 136, Loss: 2.0448, Accuracy: 27.5115, Test Loss: 1.5958, Test Accuracy: 19.0628\n",
      "Epoch 137, Loss: 2.0412, Accuracy: 27.5145, Test Loss: 1.5958, Test Accuracy: 19.0544\n",
      "Epoch 138, Loss: 2.0377, Accuracy: 27.5127, Test Loss: 1.5958, Test Accuracy: 19.0461\n",
      "Epoch 139, Loss: 2.0342, Accuracy: 27.5156, Test Loss: 1.5958, Test Accuracy: 19.0379\n",
      "Epoch 140, Loss: 2.0307, Accuracy: 27.5186, Test Loss: 1.5958, Test Accuracy: 19.0299\n",
      "Epoch 141, Loss: 2.0273, Accuracy: 27.5214, Test Loss: 1.5958, Test Accuracy: 19.0219\n",
      "Epoch 142, Loss: 2.0240, Accuracy: 27.5242, Test Loss: 1.5958, Test Accuracy: 19.0141\n",
      "Epoch 143, Loss: 2.0206, Accuracy: 27.5270, Test Loss: 1.5958, Test Accuracy: 19.0064\n",
      "Epoch 144, Loss: 2.0174, Accuracy: 27.5298, Test Loss: 1.5958, Test Accuracy: 18.9988\n",
      "Epoch 145, Loss: 2.0141, Accuracy: 27.5325, Test Loss: 1.5958, Test Accuracy: 18.9913\n",
      "Epoch 146, Loss: 2.0109, Accuracy: 27.5351, Test Loss: 1.5958, Test Accuracy: 18.9838\n",
      "Epoch 147, Loss: 2.0078, Accuracy: 27.5378, Test Loss: 1.5958, Test Accuracy: 18.9765\n",
      "Epoch 148, Loss: 2.0047, Accuracy: 27.5404, Test Loss: 1.5959, Test Accuracy: 18.9693\n",
      "Epoch 149, Loss: 2.0016, Accuracy: 27.5429, Test Loss: 1.5959, Test Accuracy: 18.9622\n",
      "Epoch 150, Loss: 1.9986, Accuracy: 27.5455, Test Loss: 1.5959, Test Accuracy: 18.9552\n",
      "Epoch 151, Loss: 1.9957, Accuracy: 27.5479, Test Loss: 1.5959, Test Accuracy: 18.9483\n",
      "Epoch 152, Loss: 1.9927, Accuracy: 27.5504, Test Loss: 1.5959, Test Accuracy: 18.9415\n",
      "Epoch 153, Loss: 1.9898, Accuracy: 27.5528, Test Loss: 1.5959, Test Accuracy: 18.9347\n",
      "Epoch 154, Loss: 1.9870, Accuracy: 27.5552, Test Loss: 1.5959, Test Accuracy: 18.9281\n",
      "Epoch 155, Loss: 1.9842, Accuracy: 27.5576, Test Loss: 1.5959, Test Accuracy: 18.9215\n",
      "Epoch 156, Loss: 1.9814, Accuracy: 27.5599, Test Loss: 1.5959, Test Accuracy: 18.9150\n",
      "Epoch 157, Loss: 1.9786, Accuracy: 27.5622, Test Loss: 1.5959, Test Accuracy: 18.9086\n",
      "Epoch 158, Loss: 1.9759, Accuracy: 27.5645, Test Loss: 1.5959, Test Accuracy: 18.9023\n",
      "Epoch 159, Loss: 1.9732, Accuracy: 27.5668, Test Loss: 1.5960, Test Accuracy: 18.8961\n",
      "Epoch 160, Loss: 1.9705, Accuracy: 27.5690, Test Loss: 1.5960, Test Accuracy: 18.8899\n",
      "Epoch 161, Loss: 1.9679, Accuracy: 27.5712, Test Loss: 1.5960, Test Accuracy: 18.8838\n",
      "Epoch 162, Loss: 1.9653, Accuracy: 27.5734, Test Loss: 1.5960, Test Accuracy: 18.8778\n",
      "Epoch 163, Loss: 1.9628, Accuracy: 27.5715, Test Loss: 1.5960, Test Accuracy: 18.8719\n",
      "Epoch 164, Loss: 1.9602, Accuracy: 27.5736, Test Loss: 1.5960, Test Accuracy: 18.8660\n",
      "Epoch 165, Loss: 1.9577, Accuracy: 27.5758, Test Loss: 1.5960, Test Accuracy: 18.8602\n",
      "Epoch 166, Loss: 1.9553, Accuracy: 27.5778, Test Loss: 1.5960, Test Accuracy: 18.8545\n",
      "Epoch 167, Loss: 1.9528, Accuracy: 27.5799, Test Loss: 1.5961, Test Accuracy: 18.8489\n",
      "Epoch 168, Loss: 1.9504, Accuracy: 27.5819, Test Loss: 1.5961, Test Accuracy: 18.8433\n",
      "Epoch 169, Loss: 1.9480, Accuracy: 27.5840, Test Loss: 1.5961, Test Accuracy: 18.8378\n",
      "Epoch 170, Loss: 1.9456, Accuracy: 27.5859, Test Loss: 1.5961, Test Accuracy: 18.8323\n",
      "Epoch 171, Loss: 1.9433, Accuracy: 27.5879, Test Loss: 1.5961, Test Accuracy: 18.8269\n",
      "Epoch 172, Loss: 1.9410, Accuracy: 27.5899, Test Loss: 1.5961, Test Accuracy: 18.8216\n",
      "Epoch 173, Loss: 1.9388, Accuracy: 27.5918, Test Loss: 1.5962, Test Accuracy: 18.8163\n",
      "Epoch 174, Loss: 1.9365, Accuracy: 27.5937, Test Loss: 1.5962, Test Accuracy: 18.8111\n",
      "Epoch 175, Loss: 1.9343, Accuracy: 27.5955, Test Loss: 1.5962, Test Accuracy: 18.8060\n",
      "Epoch 176, Loss: 1.9321, Accuracy: 27.5974, Test Loss: 1.5962, Test Accuracy: 18.8009\n",
      "Epoch 177, Loss: 1.9299, Accuracy: 27.5992, Test Loss: 1.5962, Test Accuracy: 18.7959\n",
      "Epoch 178, Loss: 1.9278, Accuracy: 27.6011, Test Loss: 1.5962, Test Accuracy: 18.7909\n",
      "Epoch 179, Loss: 1.9257, Accuracy: 27.6028, Test Loss: 1.5963, Test Accuracy: 18.7860\n",
      "Epoch 180, Loss: 1.9236, Accuracy: 27.6046, Test Loss: 1.5963, Test Accuracy: 18.7811\n",
      "Epoch 181, Loss: 1.9215, Accuracy: 27.6064, Test Loss: 1.5963, Test Accuracy: 18.7763\n",
      "Epoch 182, Loss: 1.9194, Accuracy: 27.6081, Test Loss: 1.5963, Test Accuracy: 18.7715\n",
      "Epoch 183, Loss: 1.9174, Accuracy: 27.6098, Test Loss: 1.5963, Test Accuracy: 18.7668\n",
      "Epoch 184, Loss: 1.9154, Accuracy: 27.6115, Test Loss: 1.5964, Test Accuracy: 18.7622\n",
      "Epoch 185, Loss: 1.9134, Accuracy: 27.6132, Test Loss: 1.5964, Test Accuracy: 18.7576\n",
      "Epoch 186, Loss: 1.9114, Accuracy: 27.6149, Test Loss: 1.5964, Test Accuracy: 18.7530\n",
      "Epoch 187, Loss: 1.9095, Accuracy: 27.6165, Test Loss: 1.5964, Test Accuracy: 18.7485\n",
      "Epoch 188, Loss: 1.9076, Accuracy: 27.6181, Test Loss: 1.5964, Test Accuracy: 18.7440\n",
      "Epoch 189, Loss: 1.9056, Accuracy: 27.6197, Test Loss: 1.5965, Test Accuracy: 18.7396\n",
      "Epoch 190, Loss: 1.9037, Accuracy: 27.6213, Test Loss: 1.5965, Test Accuracy: 18.7353\n",
      "Epoch 191, Loss: 1.9019, Accuracy: 27.6229, Test Loss: 1.5965, Test Accuracy: 18.7310\n",
      "Epoch 192, Loss: 1.9002, Accuracy: 27.6211, Test Loss: 1.5965, Test Accuracy: 18.7267\n",
      "Epoch 193, Loss: 1.8985, Accuracy: 27.6226, Test Loss: 1.5965, Test Accuracy: 18.7224\n",
      "Epoch 194, Loss: 1.8967, Accuracy: 27.6242, Test Loss: 1.5966, Test Accuracy: 18.7183\n",
      "Epoch 195, Loss: 1.8949, Accuracy: 27.6257, Test Loss: 1.5966, Test Accuracy: 18.7141\n",
      "Epoch 196, Loss: 1.8931, Accuracy: 27.6272, Test Loss: 1.5966, Test Accuracy: 18.7100\n",
      "Epoch 197, Loss: 1.8914, Accuracy: 27.6287, Test Loss: 1.5966, Test Accuracy: 18.7060\n",
      "Epoch 198, Loss: 1.8896, Accuracy: 27.6302, Test Loss: 1.5966, Test Accuracy: 18.7019\n",
      "Epoch 199, Loss: 1.8879, Accuracy: 27.6317, Test Loss: 1.5967, Test Accuracy: 18.6980\n",
      "Epoch 200, Loss: 1.8862, Accuracy: 27.6331, Test Loss: 1.5967, Test Accuracy: 18.6940\n",
      "average of 12 each\n",
      "Epoch 1, Loss: 25.5190, Accuracy: 17.1429, Test Loss: 1.6497, Test Accuracy: 11.6667\n",
      "Epoch 2, Loss: 20.8396, Accuracy: 20.0000, Test Loss: 1.6951, Test Accuracy: 10.8333\n",
      "Epoch 3, Loss: 17.4322, Accuracy: 20.7143, Test Loss: 1.7329, Test Accuracy: 9.4444\n",
      "Epoch 4, Loss: 14.8960, Accuracy: 21.7857, Test Loss: 1.7093, Test Accuracy: 13.7500\n",
      "Epoch 5, Loss: 12.9648, Accuracy: 21.2857, Test Loss: 1.6852, Test Accuracy: 17.6667\n",
      "Epoch 6, Loss: 11.5378, Accuracy: 21.5476, Test Loss: 1.6682, Test Accuracy: 19.1667\n",
      "Epoch 7, Loss: 10.4141, Accuracy: 21.7347, Test Loss: 1.6576, Test Accuracy: 20.2381\n",
      "Epoch 8, Loss: 9.3909, Accuracy: 22.0536, Test Loss: 1.6508, Test Accuracy: 21.0417\n",
      "Epoch 9, Loss: 8.5730, Accuracy: 22.3810, Test Loss: 1.6457, Test Accuracy: 21.6667\n",
      "Epoch 10, Loss: 7.8820, Accuracy: 22.7143, Test Loss: 1.6415, Test Accuracy: 22.1667\n",
      "Epoch 11, Loss: 7.3170, Accuracy: 23.1169, Test Loss: 1.6380, Test Accuracy: 22.5758\n",
      "Epoch 12, Loss: 6.8440, Accuracy: 23.2143, Test Loss: 1.6350, Test Accuracy: 22.9167\n",
      "Epoch 13, Loss: 6.4620, Accuracy: 23.4066, Test Loss: 1.6325, Test Accuracy: 23.2051\n",
      "Epoch 14, Loss: 6.1165, Accuracy: 23.4184, Test Loss: 1.6302, Test Accuracy: 23.4524\n",
      "Epoch 15, Loss: 5.8154, Accuracy: 23.5238, Test Loss: 1.6282, Test Accuracy: 23.6667\n",
      "Epoch 16, Loss: 5.5537, Accuracy: 23.4821, Test Loss: 1.6264, Test Accuracy: 23.8542\n",
      "Epoch 17, Loss: 5.3229, Accuracy: 23.4454, Test Loss: 1.6248, Test Accuracy: 24.0196\n",
      "Epoch 18, Loss: 5.1167, Accuracy: 23.5317, Test Loss: 1.6233, Test Accuracy: 24.1667\n",
      "Epoch 19, Loss: 4.9369, Accuracy: 23.4962, Test Loss: 1.6218, Test Accuracy: 24.2982\n",
      "Epoch 20, Loss: 4.7726, Accuracy: 23.6071, Test Loss: 1.6205, Test Accuracy: 24.4167\n",
      "Epoch 21, Loss: 4.6199, Accuracy: 23.7075, Test Loss: 1.6193, Test Accuracy: 24.5238\n",
      "Epoch 22, Loss: 4.4828, Accuracy: 23.7338, Test Loss: 1.6181, Test Accuracy: 24.6212\n",
      "Epoch 23, Loss: 4.3577, Accuracy: 23.7267, Test Loss: 1.6170, Test Accuracy: 24.7101\n",
      "Epoch 24, Loss: 4.2503, Accuracy: 23.7500, Test Loss: 1.6159, Test Accuracy: 24.7917\n",
      "Epoch 25, Loss: 4.1433, Accuracy: 23.8571, Test Loss: 1.6149, Test Accuracy: 24.8667\n",
      "Epoch 26, Loss: 4.0453, Accuracy: 23.8187, Test Loss: 1.6139, Test Accuracy: 24.9359\n",
      "Epoch 27, Loss: 3.9546, Accuracy: 23.8624, Test Loss: 1.6130, Test Accuracy: 25.0000\n",
      "Epoch 28, Loss: 3.8705, Accuracy: 23.9031, Test Loss: 1.6121, Test Accuracy: 25.0595\n",
      "Epoch 29, Loss: 3.7918, Accuracy: 24.0148, Test Loss: 1.6112, Test Accuracy: 25.1149\n",
      "Epoch 30, Loss: 3.7197, Accuracy: 24.0476, Test Loss: 1.6104, Test Accuracy: 25.1667\n",
      "Epoch 31, Loss: 3.6505, Accuracy: 24.1014, Test Loss: 1.6096, Test Accuracy: 25.2151\n",
      "Epoch 32, Loss: 3.5863, Accuracy: 24.1295, Test Loss: 1.6088, Test Accuracy: 25.2604\n",
      "Epoch 33, Loss: 3.5260, Accuracy: 24.1558, Test Loss: 1.6080, Test Accuracy: 25.3030\n",
      "Epoch 34, Loss: 3.4712, Accuracy: 24.1807, Test Loss: 1.6073, Test Accuracy: 25.3431\n",
      "Epoch 35, Loss: 3.4177, Accuracy: 24.1837, Test Loss: 1.6066, Test Accuracy: 25.3810\n",
      "Epoch 36, Loss: 3.3671, Accuracy: 24.1667, Test Loss: 1.6059, Test Accuracy: 25.4167\n",
      "Epoch 37, Loss: 3.3203, Accuracy: 24.1506, Test Loss: 1.6052, Test Accuracy: 25.4505\n",
      "Epoch 38, Loss: 3.2747, Accuracy: 24.1729, Test Loss: 1.6046, Test Accuracy: 25.4825\n",
      "Epoch 39, Loss: 3.2314, Accuracy: 24.1941, Test Loss: 1.6039, Test Accuracy: 25.5128\n",
      "Epoch 40, Loss: 3.1914, Accuracy: 24.1964, Test Loss: 1.6033, Test Accuracy: 25.5417\n",
      "Epoch 41, Loss: 3.1526, Accuracy: 24.1986, Test Loss: 1.6026, Test Accuracy: 25.5691\n",
      "Epoch 42, Loss: 3.1162, Accuracy: 24.2007, Test Loss: 1.6020, Test Accuracy: 25.5952\n",
      "Epoch 43, Loss: 3.0807, Accuracy: 24.2359, Test Loss: 1.6014, Test Accuracy: 25.6202\n",
      "Epoch 44, Loss: 3.0468, Accuracy: 24.2370, Test Loss: 1.6008, Test Accuracy: 25.6439\n",
      "Epoch 45, Loss: 3.0139, Accuracy: 24.2698, Test Loss: 1.6003, Test Accuracy: 25.6667\n",
      "Epoch 46, Loss: 2.9874, Accuracy: 24.2857, Test Loss: 1.5997, Test Accuracy: 25.6884\n",
      "Epoch 47, Loss: 2.9572, Accuracy: 24.3009, Test Loss: 1.5992, Test Accuracy: 25.7092\n",
      "Epoch 48, Loss: 2.9288, Accuracy: 24.3155, Test Loss: 1.5986, Test Accuracy: 25.7292\n",
      "Epoch 49, Loss: 2.9015, Accuracy: 24.3149, Test Loss: 1.5981, Test Accuracy: 25.7483\n",
      "Epoch 50, Loss: 2.8750, Accuracy: 24.3143, Test Loss: 1.5976, Test Accuracy: 25.7667\n",
      "Epoch 51, Loss: 2.8505, Accuracy: 24.3137, Test Loss: 1.5971, Test Accuracy: 25.7843\n",
      "Epoch 52, Loss: 2.8260, Accuracy: 24.3269, Test Loss: 1.5966, Test Accuracy: 25.8013\n",
      "Epoch 53, Loss: 2.8025, Accuracy: 24.3261, Test Loss: 1.5961, Test Accuracy: 25.8176\n",
      "Epoch 54, Loss: 2.7800, Accuracy: 24.3386, Test Loss: 1.5956, Test Accuracy: 25.8333\n",
      "Epoch 55, Loss: 2.7590, Accuracy: 24.3377, Test Loss: 1.5951, Test Accuracy: 25.8485\n",
      "Epoch 56, Loss: 2.7381, Accuracy: 24.3367, Test Loss: 1.5946, Test Accuracy: 25.8631\n",
      "Epoch 57, Loss: 2.7183, Accuracy: 24.3233, Test Loss: 1.5941, Test Accuracy: 25.8772\n",
      "Epoch 58, Loss: 2.6988, Accuracy: 24.3350, Test Loss: 1.5936, Test Accuracy: 25.8908\n",
      "Epoch 59, Loss: 2.6797, Accuracy: 24.3341, Test Loss: 1.5932, Test Accuracy: 25.9040\n",
      "Epoch 60, Loss: 2.6615, Accuracy: 24.3333, Test Loss: 1.5927, Test Accuracy: 25.9167\n",
      "Epoch 61, Loss: 2.6436, Accuracy: 24.3326, Test Loss: 1.5923, Test Accuracy: 25.9290\n",
      "Epoch 62, Loss: 2.6272, Accuracy: 24.3433, Test Loss: 1.5918, Test Accuracy: 25.9409\n",
      "Epoch 63, Loss: 2.6105, Accuracy: 24.3424, Test Loss: 1.5913, Test Accuracy: 25.9524\n",
      "Epoch 64, Loss: 2.5955, Accuracy: 24.3527, Test Loss: 1.5909, Test Accuracy: 25.9635\n",
      "Epoch 65, Loss: 2.5803, Accuracy: 24.3516, Test Loss: 1.5905, Test Accuracy: 25.9744\n",
      "Epoch 66, Loss: 2.5649, Accuracy: 24.3723, Test Loss: 1.5900, Test Accuracy: 25.9848\n",
      "Epoch 67, Loss: 2.5513, Accuracy: 24.3817, Test Loss: 1.5896, Test Accuracy: 25.9950\n",
      "Epoch 68, Loss: 2.5371, Accuracy: 24.3803, Test Loss: 1.5892, Test Accuracy: 26.0049\n",
      "Epoch 69, Loss: 2.5236, Accuracy: 24.3789, Test Loss: 1.5888, Test Accuracy: 26.0145\n",
      "Epoch 70, Loss: 2.5103, Accuracy: 24.3776, Test Loss: 1.5883, Test Accuracy: 26.0238\n",
      "Epoch 71, Loss: 2.4972, Accuracy: 24.3763, Test Loss: 1.5879, Test Accuracy: 26.0329\n",
      "Epoch 72, Loss: 2.4846, Accuracy: 24.3750, Test Loss: 1.5875, Test Accuracy: 26.0417\n",
      "Epoch 73, Loss: 2.4723, Accuracy: 24.3738, Test Loss: 1.5871, Test Accuracy: 26.0502\n",
      "Epoch 74, Loss: 2.4604, Accuracy: 24.3822, Test Loss: 1.5867, Test Accuracy: 26.0586\n",
      "Epoch 75, Loss: 2.4488, Accuracy: 24.3810, Test Loss: 1.5863, Test Accuracy: 26.0667\n",
      "Epoch 76, Loss: 2.4375, Accuracy: 24.3891, Test Loss: 1.5859, Test Accuracy: 26.0746\n",
      "Epoch 77, Loss: 2.4263, Accuracy: 24.3878, Test Loss: 1.5856, Test Accuracy: 26.0823\n",
      "Epoch 78, Loss: 2.4157, Accuracy: 24.3864, Test Loss: 1.5852, Test Accuracy: 26.0897\n",
      "Epoch 79, Loss: 2.4050, Accuracy: 24.3942, Test Loss: 1.5848, Test Accuracy: 26.0970\n",
      "Epoch 80, Loss: 2.3948, Accuracy: 24.3929, Test Loss: 1.5844, Test Accuracy: 26.1042\n",
      "Epoch 81, Loss: 2.3849, Accuracy: 24.3915, Test Loss: 1.5841, Test Accuracy: 26.1111\n",
      "Epoch 82, Loss: 2.3759, Accuracy: 24.3902, Test Loss: 1.5837, Test Accuracy: 26.1179\n",
      "Epoch 83, Loss: 2.3666, Accuracy: 24.3976, Test Loss: 1.5833, Test Accuracy: 26.1245\n",
      "Epoch 84, Loss: 2.3579, Accuracy: 24.4048, Test Loss: 1.5830, Test Accuracy: 26.1310\n",
      "Epoch 85, Loss: 2.3488, Accuracy: 24.4034, Test Loss: 1.5826, Test Accuracy: 26.1373\n",
      "Epoch 86, Loss: 2.3400, Accuracy: 24.4020, Test Loss: 1.5823, Test Accuracy: 26.1434\n",
      "Epoch 87, Loss: 2.3312, Accuracy: 24.4007, Test Loss: 1.5819, Test Accuracy: 26.1494\n",
      "Epoch 88, Loss: 2.3232, Accuracy: 24.4075, Test Loss: 1.5816, Test Accuracy: 26.1553\n",
      "Epoch 89, Loss: 2.3150, Accuracy: 24.4061, Test Loss: 1.5813, Test Accuracy: 26.1610\n",
      "Epoch 90, Loss: 2.3071, Accuracy: 24.3968, Test Loss: 1.5809, Test Accuracy: 26.1667\n",
      "Epoch 91, Loss: 2.2992, Accuracy: 24.3956, Test Loss: 1.5806, Test Accuracy: 26.1722\n",
      "Epoch 92, Loss: 2.2914, Accuracy: 24.3866, Test Loss: 1.5803, Test Accuracy: 26.1775\n",
      "Epoch 93, Loss: 2.2839, Accuracy: 24.3856, Test Loss: 1.5799, Test Accuracy: 26.1828\n",
      "Epoch 94, Loss: 2.2765, Accuracy: 24.3921, Test Loss: 1.5796, Test Accuracy: 26.1879\n",
      "Epoch 95, Loss: 2.2693, Accuracy: 24.3985, Test Loss: 1.5793, Test Accuracy: 26.1930\n",
      "Epoch 96, Loss: 2.2621, Accuracy: 24.3973, Test Loss: 1.5790, Test Accuracy: 26.1979\n",
      "Epoch 97, Loss: 2.2552, Accuracy: 24.3962, Test Loss: 1.5787, Test Accuracy: 26.2028\n",
      "Epoch 98, Loss: 2.2483, Accuracy: 24.3950, Test Loss: 1.5784, Test Accuracy: 26.2075\n",
      "Epoch 99, Loss: 2.2416, Accuracy: 24.3939, Test Loss: 1.5781, Test Accuracy: 26.2121\n",
      "Epoch 100, Loss: 2.2350, Accuracy: 24.4000, Test Loss: 1.5778, Test Accuracy: 26.2167\n",
      "Epoch 101, Loss: 2.2286, Accuracy: 24.3989, Test Loss: 1.5775, Test Accuracy: 26.2211\n",
      "Epoch 102, Loss: 2.2223, Accuracy: 24.3978, Test Loss: 1.5772, Test Accuracy: 26.2255\n",
      "Epoch 103, Loss: 2.2158, Accuracy: 24.4175, Test Loss: 1.5769, Test Accuracy: 26.2298\n",
      "Epoch 104, Loss: 2.2098, Accuracy: 24.4162, Test Loss: 1.5766, Test Accuracy: 26.2340\n",
      "Epoch 105, Loss: 2.2050, Accuracy: 24.4354, Test Loss: 1.5763, Test Accuracy: 26.2381\n",
      "Epoch 106, Loss: 2.1988, Accuracy: 24.4744, Test Loss: 1.5761, Test Accuracy: 26.2421\n",
      "Epoch 107, Loss: 2.1930, Accuracy: 24.4860, Test Loss: 1.5758, Test Accuracy: 26.2461\n",
      "Epoch 108, Loss: 2.1870, Accuracy: 24.4974, Test Loss: 1.5755, Test Accuracy: 26.2500\n",
      "Epoch 109, Loss: 2.1817, Accuracy: 24.5085, Test Loss: 1.5752, Test Accuracy: 26.2538\n",
      "Epoch 110, Loss: 2.1762, Accuracy: 24.5130, Test Loss: 1.5750, Test Accuracy: 26.2576\n",
      "Epoch 111, Loss: 2.1710, Accuracy: 24.5109, Test Loss: 1.5747, Test Accuracy: 26.2613\n",
      "Epoch 112, Loss: 2.1659, Accuracy: 24.5089, Test Loss: 1.5745, Test Accuracy: 26.2649\n",
      "Epoch 113, Loss: 2.1609, Accuracy: 24.5006, Test Loss: 1.5742, Test Accuracy: 26.2684\n",
      "Epoch 114, Loss: 2.1558, Accuracy: 24.5050, Test Loss: 1.5739, Test Accuracy: 26.2719\n",
      "Epoch 115, Loss: 2.1508, Accuracy: 24.5031, Test Loss: 1.5737, Test Accuracy: 26.2754\n",
      "Epoch 116, Loss: 2.1460, Accuracy: 24.5012, Test Loss: 1.5734, Test Accuracy: 26.2787\n",
      "Epoch 117, Loss: 2.1412, Accuracy: 24.4994, Test Loss: 1.5732, Test Accuracy: 26.2821\n",
      "Epoch 118, Loss: 2.1366, Accuracy: 24.4976, Test Loss: 1.5729, Test Accuracy: 26.2853\n",
      "Epoch 119, Loss: 2.1321, Accuracy: 24.4958, Test Loss: 1.5727, Test Accuracy: 26.2885\n",
      "Epoch 120, Loss: 2.1275, Accuracy: 24.4940, Test Loss: 1.5725, Test Accuracy: 26.2917\n",
      "Epoch 121, Loss: 2.1231, Accuracy: 24.4923, Test Loss: 1.5722, Test Accuracy: 26.2948\n",
      "Epoch 122, Loss: 2.1186, Accuracy: 24.4906, Test Loss: 1.5720, Test Accuracy: 26.2978\n",
      "Epoch 123, Loss: 2.1143, Accuracy: 24.4948, Test Loss: 1.5718, Test Accuracy: 26.3008\n",
      "Epoch 124, Loss: 2.1099, Accuracy: 24.4988, Test Loss: 1.5715, Test Accuracy: 26.3038\n",
      "Epoch 125, Loss: 2.1056, Accuracy: 24.4971, Test Loss: 1.5713, Test Accuracy: 26.3067\n",
      "Epoch 126, Loss: 2.1015, Accuracy: 24.4955, Test Loss: 1.5711, Test Accuracy: 26.3095\n",
      "Epoch 127, Loss: 2.0975, Accuracy: 24.4938, Test Loss: 1.5708, Test Accuracy: 26.3123\n",
      "Epoch 128, Loss: 2.0935, Accuracy: 24.4922, Test Loss: 1.5706, Test Accuracy: 26.3151\n",
      "Epoch 129, Loss: 2.0895, Accuracy: 24.4906, Test Loss: 1.5704, Test Accuracy: 26.3178\n",
      "Epoch 130, Loss: 2.0857, Accuracy: 24.4890, Test Loss: 1.5701, Test Accuracy: 26.3205\n",
      "Epoch 131, Loss: 2.0819, Accuracy: 24.4875, Test Loss: 1.5699, Test Accuracy: 26.3232\n",
      "Epoch 132, Loss: 2.0781, Accuracy: 24.4859, Test Loss: 1.5697, Test Accuracy: 26.3258\n",
      "Epoch 133, Loss: 2.0744, Accuracy: 24.4844, Test Loss: 1.5695, Test Accuracy: 26.3283\n",
      "Epoch 134, Loss: 2.0707, Accuracy: 24.4829, Test Loss: 1.5693, Test Accuracy: 26.3308\n",
      "Epoch 135, Loss: 2.0671, Accuracy: 24.4868, Test Loss: 1.5690, Test Accuracy: 26.3333\n",
      "Epoch 136, Loss: 2.0636, Accuracy: 24.4853, Test Loss: 1.5688, Test Accuracy: 26.3358\n",
      "Epoch 137, Loss: 2.0600, Accuracy: 24.4838, Test Loss: 1.5686, Test Accuracy: 26.3382\n",
      "Epoch 138, Loss: 2.0566, Accuracy: 24.4824, Test Loss: 1.5684, Test Accuracy: 26.3406\n",
      "Epoch 139, Loss: 2.0532, Accuracy: 24.4810, Test Loss: 1.5682, Test Accuracy: 26.3429\n",
      "Epoch 140, Loss: 2.0499, Accuracy: 24.4796, Test Loss: 1.5680, Test Accuracy: 26.3452\n",
      "Epoch 141, Loss: 2.0466, Accuracy: 24.4782, Test Loss: 1.5678, Test Accuracy: 26.3475\n",
      "Epoch 142, Loss: 2.0433, Accuracy: 24.4769, Test Loss: 1.5676, Test Accuracy: 26.3498\n",
      "Epoch 143, Loss: 2.0401, Accuracy: 24.4755, Test Loss: 1.5673, Test Accuracy: 26.3520\n",
      "Epoch 144, Loss: 2.0370, Accuracy: 24.4742, Test Loss: 1.5671, Test Accuracy: 26.3542\n",
      "Epoch 145, Loss: 2.0339, Accuracy: 24.4729, Test Loss: 1.5669, Test Accuracy: 26.3563\n",
      "Epoch 146, Loss: 2.0307, Accuracy: 24.4765, Test Loss: 1.5667, Test Accuracy: 26.3584\n",
      "Epoch 147, Loss: 2.0277, Accuracy: 24.4752, Test Loss: 1.5665, Test Accuracy: 26.3605\n",
      "Epoch 148, Loss: 2.0247, Accuracy: 24.4788, Test Loss: 1.5663, Test Accuracy: 26.3626\n",
      "Epoch 149, Loss: 2.0217, Accuracy: 24.4775, Test Loss: 1.5661, Test Accuracy: 26.3647\n",
      "Epoch 150, Loss: 2.0188, Accuracy: 24.4762, Test Loss: 1.5659, Test Accuracy: 26.3667\n",
      "Epoch 151, Loss: 2.0159, Accuracy: 24.4749, Test Loss: 1.5657, Test Accuracy: 26.3687\n",
      "Epoch 152, Loss: 2.0130, Accuracy: 24.4737, Test Loss: 1.5656, Test Accuracy: 26.3706\n",
      "Epoch 153, Loss: 2.0102, Accuracy: 24.4725, Test Loss: 1.5654, Test Accuracy: 26.3725\n",
      "Epoch 154, Loss: 2.0074, Accuracy: 24.4712, Test Loss: 1.5652, Test Accuracy: 26.3745\n",
      "Epoch 155, Loss: 2.0047, Accuracy: 24.4700, Test Loss: 1.5650, Test Accuracy: 26.3763\n",
      "Epoch 156, Loss: 2.0020, Accuracy: 24.4689, Test Loss: 1.5648, Test Accuracy: 26.3782\n",
      "Epoch 157, Loss: 1.9993, Accuracy: 24.4677, Test Loss: 1.5646, Test Accuracy: 26.3800\n",
      "Epoch 158, Loss: 1.9967, Accuracy: 24.4665, Test Loss: 1.5644, Test Accuracy: 26.3819\n",
      "Epoch 159, Loss: 1.9941, Accuracy: 24.4654, Test Loss: 1.5642, Test Accuracy: 26.3836\n",
      "Epoch 160, Loss: 1.9916, Accuracy: 24.4643, Test Loss: 1.5640, Test Accuracy: 26.3854\n",
      "Epoch 161, Loss: 1.9891, Accuracy: 24.4632, Test Loss: 1.5639, Test Accuracy: 26.3872\n",
      "Epoch 162, Loss: 1.9866, Accuracy: 24.4621, Test Loss: 1.5637, Test Accuracy: 26.3889\n",
      "Epoch 163, Loss: 1.9841, Accuracy: 24.4610, Test Loss: 1.5635, Test Accuracy: 26.3906\n",
      "Epoch 164, Loss: 1.9816, Accuracy: 24.4599, Test Loss: 1.5633, Test Accuracy: 26.3923\n",
      "Epoch 165, Loss: 1.9792, Accuracy: 24.4589, Test Loss: 1.5631, Test Accuracy: 26.3939\n",
      "Epoch 166, Loss: 1.9768, Accuracy: 24.4578, Test Loss: 1.5630, Test Accuracy: 26.3956\n",
      "Epoch 167, Loss: 1.9744, Accuracy: 24.4568, Test Loss: 1.5628, Test Accuracy: 26.3972\n",
      "Epoch 168, Loss: 1.9720, Accuracy: 24.4558, Test Loss: 1.5626, Test Accuracy: 26.3988\n",
      "Epoch 169, Loss: 1.9697, Accuracy: 24.4548, Test Loss: 1.5624, Test Accuracy: 26.4004\n",
      "Epoch 170, Loss: 1.9675, Accuracy: 24.4538, Test Loss: 1.5623, Test Accuracy: 26.4020\n",
      "Epoch 171, Loss: 1.9652, Accuracy: 24.4528, Test Loss: 1.5621, Test Accuracy: 26.4035\n",
      "Epoch 172, Loss: 1.9630, Accuracy: 24.4560, Test Loss: 1.5619, Test Accuracy: 26.4050\n",
      "Epoch 173, Loss: 1.9608, Accuracy: 24.4550, Test Loss: 1.5617, Test Accuracy: 26.4066\n",
      "Epoch 174, Loss: 1.9587, Accuracy: 24.4540, Test Loss: 1.5616, Test Accuracy: 26.4080\n",
      "Epoch 175, Loss: 1.9565, Accuracy: 24.4531, Test Loss: 1.5614, Test Accuracy: 26.4095\n",
      "Epoch 176, Loss: 1.9544, Accuracy: 24.4521, Test Loss: 1.5612, Test Accuracy: 26.4110\n",
      "Epoch 177, Loss: 1.9523, Accuracy: 24.4512, Test Loss: 1.5611, Test Accuracy: 26.4124\n",
      "Epoch 178, Loss: 1.9502, Accuracy: 24.4502, Test Loss: 1.5609, Test Accuracy: 26.4139\n",
      "Epoch 179, Loss: 1.9481, Accuracy: 24.4493, Test Loss: 1.5608, Test Accuracy: 26.4153\n",
      "Epoch 180, Loss: 1.9460, Accuracy: 24.4524, Test Loss: 1.5606, Test Accuracy: 26.4167\n",
      "Epoch 181, Loss: 1.9441, Accuracy: 24.4515, Test Loss: 1.5604, Test Accuracy: 26.4180\n",
      "Epoch 182, Loss: 1.9420, Accuracy: 24.4506, Test Loss: 1.5603, Test Accuracy: 26.4194\n",
      "Epoch 183, Loss: 1.9401, Accuracy: 24.4496, Test Loss: 1.5601, Test Accuracy: 26.4208\n",
      "Epoch 184, Loss: 1.9381, Accuracy: 24.4488, Test Loss: 1.5599, Test Accuracy: 26.4221\n",
      "Epoch 185, Loss: 1.9361, Accuracy: 24.4479, Test Loss: 1.5598, Test Accuracy: 26.4234\n",
      "Epoch 186, Loss: 1.9341, Accuracy: 24.4508, Test Loss: 1.5596, Test Accuracy: 26.4247\n",
      "Epoch 187, Loss: 1.9323, Accuracy: 24.4538, Test Loss: 1.5595, Test Accuracy: 26.4260\n",
      "Epoch 188, Loss: 1.9315, Accuracy: 24.4491, Test Loss: 1.5593, Test Accuracy: 26.4273\n",
      "Epoch 189, Loss: 1.9295, Accuracy: 24.4520, Test Loss: 1.5592, Test Accuracy: 26.4286\n",
      "Epoch 190, Loss: 1.9278, Accuracy: 24.4511, Test Loss: 1.5590, Test Accuracy: 26.4298\n",
      "Epoch 191, Loss: 1.9260, Accuracy: 24.4503, Test Loss: 1.5589, Test Accuracy: 26.4311\n",
      "Epoch 192, Loss: 1.9243, Accuracy: 24.4494, Test Loss: 1.5587, Test Accuracy: 26.4323\n",
      "Epoch 193, Loss: 1.9225, Accuracy: 24.4486, Test Loss: 1.5585, Test Accuracy: 26.4335\n",
      "Epoch 194, Loss: 1.9206, Accuracy: 24.4514, Test Loss: 1.5584, Test Accuracy: 26.4347\n",
      "Epoch 195, Loss: 1.9189, Accuracy: 24.4506, Test Loss: 1.5583, Test Accuracy: 26.4359\n",
      "Epoch 196, Loss: 1.9172, Accuracy: 24.4497, Test Loss: 1.5581, Test Accuracy: 26.4371\n",
      "Epoch 197, Loss: 1.9155, Accuracy: 24.4489, Test Loss: 1.5580, Test Accuracy: 26.4382\n",
      "Epoch 198, Loss: 1.9138, Accuracy: 24.4481, Test Loss: 1.5578, Test Accuracy: 26.4394\n",
      "Epoch 199, Loss: 1.9121, Accuracy: 24.4508, Test Loss: 1.5577, Test Accuracy: 26.4405\n",
      "Epoch 200, Loss: 1.9105, Accuracy: 24.4500, Test Loss: 1.5575, Test Accuracy: 26.4417\n",
      "average of 13 each\n",
      "Epoch 1, Loss: 36.1614, Accuracy: 21.2121, Test Loss: 1.6098, Test Accuracy: 22.8070\n",
      "Epoch 2, Loss: 28.8430, Accuracy: 19.3182, Test Loss: 1.5964, Test Accuracy: 24.5614\n",
      "Epoch 3, Loss: 25.6637, Accuracy: 18.4343, Test Loss: 1.5802, Test Accuracy: 27.4854\n",
      "Epoch 4, Loss: 22.6844, Accuracy: 20.0758, Test Loss: 1.5733, Test Accuracy: 28.9474\n",
      "Epoch 5, Loss: 20.4810, Accuracy: 20.1515, Test Loss: 1.5740, Test Accuracy: 29.8246\n",
      "Epoch 6, Loss: 17.8638, Accuracy: 20.3283, Test Loss: 1.5764, Test Accuracy: 28.6550\n",
      "Epoch 7, Loss: 16.0787, Accuracy: 20.4545, Test Loss: 1.5804, Test Accuracy: 27.0677\n",
      "Epoch 8, Loss: 14.4893, Accuracy: 19.4129, Test Loss: 1.5836, Test Accuracy: 26.7544\n",
      "Epoch 9, Loss: 13.1958, Accuracy: 20.6229, Test Loss: 1.5860, Test Accuracy: 26.5107\n",
      "Epoch 10, Loss: 12.0732, Accuracy: 21.1364, Test Loss: 1.5879, Test Accuracy: 26.3158\n",
      "Epoch 11, Loss: 11.1488, Accuracy: 21.7631, Test Loss: 1.5894, Test Accuracy: 26.1563\n",
      "Epoch 12, Loss: 10.3948, Accuracy: 21.7803, Test Loss: 1.5906, Test Accuracy: 26.0234\n",
      "Epoch 13, Loss: 9.7218, Accuracy: 21.9697, Test Loss: 1.5916, Test Accuracy: 25.9109\n",
      "Epoch 14, Loss: 9.1509, Accuracy: 22.1861, Test Loss: 1.5925, Test Accuracy: 25.8145\n",
      "Epoch 15, Loss: 8.6578, Accuracy: 22.4242, Test Loss: 1.5932, Test Accuracy: 25.7310\n",
      "Epoch 16, Loss: 8.2172, Accuracy: 22.5379, Test Loss: 1.5937, Test Accuracy: 25.6579\n",
      "Epoch 17, Loss: 7.8296, Accuracy: 22.6381, Test Loss: 1.5942, Test Accuracy: 25.5934\n",
      "Epoch 18, Loss: 7.4870, Accuracy: 22.7273, Test Loss: 1.5946, Test Accuracy: 25.5361\n",
      "Epoch 19, Loss: 7.1800, Accuracy: 22.8469, Test Loss: 1.5949, Test Accuracy: 25.4848\n",
      "Epoch 20, Loss: 6.9010, Accuracy: 22.9167, Test Loss: 1.5952, Test Accuracy: 25.4386\n",
      "Epoch 21, Loss: 6.6487, Accuracy: 23.0159, Test Loss: 1.5954, Test Accuracy: 25.3968\n",
      "Epoch 22, Loss: 6.4203, Accuracy: 23.1061, Test Loss: 1.5956, Test Accuracy: 25.3589\n",
      "Epoch 23, Loss: 6.2112, Accuracy: 23.1884, Test Loss: 1.5957, Test Accuracy: 25.3242\n",
      "Epoch 24, Loss: 6.0191, Accuracy: 23.2639, Test Loss: 1.5958, Test Accuracy: 25.2924\n",
      "Epoch 25, Loss: 5.8423, Accuracy: 23.3030, Test Loss: 1.5959, Test Accuracy: 25.2632\n",
      "Epoch 26, Loss: 5.6802, Accuracy: 23.3392, Test Loss: 1.5959, Test Accuracy: 25.2362\n",
      "Epoch 27, Loss: 5.5302, Accuracy: 23.4007, Test Loss: 1.5959, Test Accuracy: 25.2112\n",
      "Epoch 28, Loss: 5.3911, Accuracy: 23.4037, Test Loss: 1.5959, Test Accuracy: 25.1880\n",
      "Epoch 29, Loss: 5.2621, Accuracy: 23.4587, Test Loss: 1.5959, Test Accuracy: 25.1664\n",
      "Epoch 30, Loss: 5.1401, Accuracy: 23.5101, Test Loss: 1.5958, Test Accuracy: 25.1462\n",
      "Epoch 31, Loss: 5.0271, Accuracy: 23.5582, Test Loss: 1.5957, Test Accuracy: 25.1273\n",
      "Epoch 32, Loss: 4.9198, Accuracy: 23.6269, Test Loss: 1.5956, Test Accuracy: 25.1096\n",
      "Epoch 33, Loss: 4.8195, Accuracy: 23.6685, Test Loss: 1.5955, Test Accuracy: 25.0930\n",
      "Epoch 34, Loss: 4.7248, Accuracy: 23.7077, Test Loss: 1.5954, Test Accuracy: 25.0774\n",
      "Epoch 35, Loss: 4.6353, Accuracy: 23.7446, Test Loss: 1.5953, Test Accuracy: 25.0627\n",
      "Epoch 36, Loss: 4.5531, Accuracy: 23.7795, Test Loss: 1.5952, Test Accuracy: 25.0487\n",
      "Epoch 37, Loss: 4.4743, Accuracy: 23.8329, Test Loss: 1.5951, Test Accuracy: 25.0356\n",
      "Epoch 38, Loss: 4.3993, Accuracy: 23.8636, Test Loss: 1.5949, Test Accuracy: 25.0231\n",
      "Epoch 39, Loss: 4.3278, Accuracy: 23.8928, Test Loss: 1.5948, Test Accuracy: 25.0112\n",
      "Epoch 40, Loss: 4.2596, Accuracy: 23.9205, Test Loss: 1.5946, Test Accuracy: 25.0000\n",
      "Epoch 41, Loss: 4.1946, Accuracy: 23.9468, Test Loss: 1.5945, Test Accuracy: 24.9893\n",
      "Epoch 42, Loss: 4.1328, Accuracy: 23.9719, Test Loss: 1.5943, Test Accuracy: 24.9791\n",
      "Epoch 43, Loss: 4.0736, Accuracy: 23.9958, Test Loss: 1.5942, Test Accuracy: 24.9694\n",
      "Epoch 44, Loss: 4.0173, Accuracy: 24.0186, Test Loss: 1.5940, Test Accuracy: 24.9601\n",
      "Epoch 45, Loss: 3.9654, Accuracy: 24.0404, Test Loss: 1.5938, Test Accuracy: 24.9513\n",
      "Epoch 46, Loss: 3.9138, Accuracy: 24.0613, Test Loss: 1.5937, Test Accuracy: 24.9428\n",
      "Epoch 47, Loss: 3.8644, Accuracy: 24.0812, Test Loss: 1.5935, Test Accuracy: 24.9347\n",
      "Epoch 48, Loss: 3.8170, Accuracy: 24.1004, Test Loss: 1.5933, Test Accuracy: 24.9269\n",
      "Epoch 49, Loss: 3.7716, Accuracy: 24.1187, Test Loss: 1.5931, Test Accuracy: 24.9194\n",
      "Epoch 50, Loss: 3.7278, Accuracy: 24.1212, Test Loss: 1.5930, Test Accuracy: 24.9123\n",
      "Epoch 51, Loss: 3.6858, Accuracy: 24.1533, Test Loss: 1.5928, Test Accuracy: 24.9054\n",
      "Epoch 52, Loss: 3.6454, Accuracy: 24.1696, Test Loss: 1.5926, Test Accuracy: 24.8988\n",
      "Epoch 53, Loss: 3.6070, Accuracy: 24.1852, Test Loss: 1.5924, Test Accuracy: 24.8924\n",
      "Epoch 54, Loss: 3.5702, Accuracy: 24.1863, Test Loss: 1.5922, Test Accuracy: 24.8863\n",
      "Epoch 55, Loss: 3.5341, Accuracy: 24.2011, Test Loss: 1.5920, Test Accuracy: 24.8804\n",
      "Epoch 56, Loss: 3.4998, Accuracy: 24.2154, Test Loss: 1.5918, Test Accuracy: 24.8747\n",
      "Epoch 57, Loss: 3.4665, Accuracy: 24.2291, Test Loss: 1.5916, Test Accuracy: 24.8692\n",
      "Epoch 58, Loss: 3.4359, Accuracy: 24.2424, Test Loss: 1.5914, Test Accuracy: 24.8639\n",
      "Epoch 59, Loss: 3.4050, Accuracy: 24.2553, Test Loss: 1.5912, Test Accuracy: 24.8588\n",
      "Epoch 60, Loss: 3.3748, Accuracy: 24.2677, Test Loss: 1.5911, Test Accuracy: 24.8538\n",
      "Epoch 61, Loss: 3.3456, Accuracy: 24.2797, Test Loss: 1.5909, Test Accuracy: 24.8490\n",
      "Epoch 62, Loss: 3.3172, Accuracy: 24.2913, Test Loss: 1.5907, Test Accuracy: 24.8444\n",
      "Epoch 63, Loss: 3.2896, Accuracy: 24.3025, Test Loss: 1.5905, Test Accuracy: 24.8399\n",
      "Epoch 64, Loss: 3.2628, Accuracy: 24.3134, Test Loss: 1.5904, Test Accuracy: 24.8355\n",
      "Epoch 65, Loss: 3.2370, Accuracy: 24.3124, Test Loss: 1.5902, Test Accuracy: 24.8313\n",
      "Epoch 66, Loss: 3.2121, Accuracy: 24.3343, Test Loss: 1.5900, Test Accuracy: 24.8272\n",
      "Epoch 67, Loss: 3.1886, Accuracy: 24.2537, Test Loss: 1.5898, Test Accuracy: 24.7971\n",
      "Epoch 68, Loss: 3.1650, Accuracy: 24.2758, Test Loss: 1.5896, Test Accuracy: 24.7678\n",
      "Epoch 69, Loss: 3.1423, Accuracy: 24.2973, Test Loss: 1.5894, Test Accuracy: 24.7394\n",
      "Epoch 70, Loss: 3.1199, Accuracy: 24.3182, Test Loss: 1.5893, Test Accuracy: 24.7118\n",
      "Epoch 71, Loss: 3.0985, Accuracy: 24.3385, Test Loss: 1.5891, Test Accuracy: 24.6850\n",
      "Epoch 72, Loss: 3.0774, Accuracy: 24.3582, Test Loss: 1.5889, Test Accuracy: 24.6589\n",
      "Epoch 73, Loss: 3.0572, Accuracy: 24.3773, Test Loss: 1.5887, Test Accuracy: 24.6335\n",
      "Epoch 74, Loss: 3.0381, Accuracy: 24.4062, Test Loss: 1.5885, Test Accuracy: 24.6088\n",
      "Epoch 75, Loss: 3.0188, Accuracy: 24.4343, Test Loss: 1.5883, Test Accuracy: 24.5848\n",
      "Epoch 76, Loss: 3.0000, Accuracy: 24.4617, Test Loss: 1.5881, Test Accuracy: 24.5614\n",
      "Epoch 77, Loss: 2.9820, Accuracy: 24.5179, Test Loss: 1.5880, Test Accuracy: 24.5386\n",
      "Epoch 78, Loss: 2.9638, Accuracy: 24.5435, Test Loss: 1.5878, Test Accuracy: 24.5164\n",
      "Epoch 79, Loss: 2.9464, Accuracy: 24.5493, Test Loss: 1.5876, Test Accuracy: 24.4948\n",
      "Epoch 80, Loss: 2.9291, Accuracy: 24.5739, Test Loss: 1.5874, Test Accuracy: 24.4737\n",
      "Epoch 81, Loss: 2.9122, Accuracy: 24.5978, Test Loss: 1.5872, Test Accuracy: 24.4531\n",
      "Epoch 82, Loss: 2.8968, Accuracy: 24.6305, Test Loss: 1.5870, Test Accuracy: 24.4330\n",
      "Epoch 83, Loss: 2.8810, Accuracy: 24.6623, Test Loss: 1.5869, Test Accuracy: 24.4134\n",
      "Epoch 84, Loss: 2.8657, Accuracy: 24.6663, Test Loss: 1.5867, Test Accuracy: 24.3943\n",
      "Epoch 85, Loss: 2.8507, Accuracy: 24.6791, Test Loss: 1.5865, Test Accuracy: 24.3756\n",
      "Epoch 86, Loss: 2.8358, Accuracy: 24.6917, Test Loss: 1.5863, Test Accuracy: 24.3574\n",
      "Epoch 87, Loss: 2.8217, Accuracy: 24.7039, Test Loss: 1.5862, Test Accuracy: 24.3396\n",
      "Epoch 88, Loss: 2.8077, Accuracy: 24.7159, Test Loss: 1.5860, Test Accuracy: 24.3222\n",
      "Epoch 89, Loss: 2.7938, Accuracy: 24.7276, Test Loss: 1.5858, Test Accuracy: 24.3051\n",
      "Epoch 90, Loss: 2.7802, Accuracy: 24.7391, Test Loss: 1.5857, Test Accuracy: 24.2885\n",
      "Epoch 91, Loss: 2.7673, Accuracy: 24.7502, Test Loss: 1.5855, Test Accuracy: 24.2722\n",
      "Epoch 92, Loss: 2.7544, Accuracy: 24.7612, Test Loss: 1.5853, Test Accuracy: 24.2563\n",
      "Epoch 93, Loss: 2.7416, Accuracy: 24.7719, Test Loss: 1.5852, Test Accuracy: 24.2407\n",
      "Epoch 94, Loss: 2.7294, Accuracy: 24.7824, Test Loss: 1.5850, Test Accuracy: 24.2255\n",
      "Epoch 95, Loss: 2.7172, Accuracy: 24.7927, Test Loss: 1.5848, Test Accuracy: 24.2105\n",
      "Epoch 96, Loss: 2.7053, Accuracy: 24.8027, Test Loss: 1.5846, Test Accuracy: 24.1959\n",
      "Epoch 97, Loss: 2.6937, Accuracy: 24.8126, Test Loss: 1.5845, Test Accuracy: 24.1816\n",
      "Epoch 98, Loss: 2.6829, Accuracy: 24.8222, Test Loss: 1.5843, Test Accuracy: 24.1676\n",
      "Epoch 99, Loss: 2.6718, Accuracy: 24.8316, Test Loss: 1.5841, Test Accuracy: 24.1538\n",
      "Epoch 100, Loss: 2.6610, Accuracy: 24.8409, Test Loss: 1.5840, Test Accuracy: 24.1404\n",
      "Epoch 101, Loss: 2.6503, Accuracy: 24.8500, Test Loss: 1.5838, Test Accuracy: 24.1271\n",
      "Epoch 102, Loss: 2.6398, Accuracy: 24.8589, Test Loss: 1.5836, Test Accuracy: 24.1142\n",
      "Epoch 103, Loss: 2.6296, Accuracy: 24.8676, Test Loss: 1.5834, Test Accuracy: 24.1015\n",
      "Epoch 104, Loss: 2.6196, Accuracy: 24.8762, Test Loss: 1.5833, Test Accuracy: 24.0891\n",
      "Epoch 105, Loss: 2.6098, Accuracy: 24.8846, Test Loss: 1.5831, Test Accuracy: 24.0769\n",
      "Epoch 106, Loss: 2.6000, Accuracy: 24.8856, Test Loss: 1.5830, Test Accuracy: 24.0649\n",
      "Epoch 107, Loss: 2.5905, Accuracy: 24.8938, Test Loss: 1.5828, Test Accuracy: 24.0531\n",
      "Epoch 108, Loss: 2.5813, Accuracy: 24.9018, Test Loss: 1.5826, Test Accuracy: 24.0416\n",
      "Epoch 109, Loss: 2.5721, Accuracy: 24.9096, Test Loss: 1.5825, Test Accuracy: 24.0303\n",
      "Epoch 110, Loss: 2.5631, Accuracy: 24.9174, Test Loss: 1.5823, Test Accuracy: 24.0191\n",
      "Epoch 111, Loss: 2.5543, Accuracy: 24.9249, Test Loss: 1.5822, Test Accuracy: 24.0082\n",
      "Epoch 112, Loss: 2.5456, Accuracy: 24.9324, Test Loss: 1.5820, Test Accuracy: 23.9975\n",
      "Epoch 113, Loss: 2.5370, Accuracy: 24.9397, Test Loss: 1.5819, Test Accuracy: 23.9870\n",
      "Epoch 114, Loss: 2.5287, Accuracy: 24.9468, Test Loss: 1.5817, Test Accuracy: 23.9766\n",
      "Epoch 115, Loss: 2.5205, Accuracy: 24.9539, Test Loss: 1.5816, Test Accuracy: 23.9664\n",
      "Epoch 116, Loss: 2.5124, Accuracy: 24.9608, Test Loss: 1.5814, Test Accuracy: 23.9564\n",
      "Epoch 117, Loss: 2.5045, Accuracy: 24.9676, Test Loss: 1.5813, Test Accuracy: 23.9466\n",
      "Epoch 118, Loss: 2.4968, Accuracy: 24.9743, Test Loss: 1.5812, Test Accuracy: 23.9370\n",
      "Epoch 119, Loss: 2.4890, Accuracy: 24.9809, Test Loss: 1.5810, Test Accuracy: 23.9275\n",
      "Epoch 120, Loss: 2.4814, Accuracy: 24.9874, Test Loss: 1.5809, Test Accuracy: 23.9181\n",
      "Epoch 121, Loss: 2.4740, Accuracy: 24.9937, Test Loss: 1.5808, Test Accuracy: 23.9089\n",
      "Epoch 122, Loss: 2.4666, Accuracy: 25.0000, Test Loss: 1.5806, Test Accuracy: 23.8999\n",
      "Epoch 123, Loss: 2.4594, Accuracy: 25.0062, Test Loss: 1.5805, Test Accuracy: 23.8910\n",
      "Epoch 124, Loss: 2.4522, Accuracy: 25.0122, Test Loss: 1.5804, Test Accuracy: 23.8823\n",
      "Epoch 125, Loss: 2.4452, Accuracy: 25.0182, Test Loss: 1.5802, Test Accuracy: 23.8737\n",
      "Epoch 126, Loss: 2.4383, Accuracy: 25.0240, Test Loss: 1.5801, Test Accuracy: 23.8652\n",
      "Epoch 127, Loss: 2.4315, Accuracy: 25.0298, Test Loss: 1.5800, Test Accuracy: 23.8569\n",
      "Epoch 128, Loss: 2.4248, Accuracy: 25.0355, Test Loss: 1.5799, Test Accuracy: 23.8487\n",
      "Epoch 129, Loss: 2.4182, Accuracy: 25.0411, Test Loss: 1.5797, Test Accuracy: 23.8406\n",
      "Epoch 130, Loss: 2.4117, Accuracy: 25.0466, Test Loss: 1.5796, Test Accuracy: 23.8327\n",
      "Epoch 131, Loss: 2.4053, Accuracy: 25.0520, Test Loss: 1.5795, Test Accuracy: 23.8248\n",
      "Epoch 132, Loss: 2.3994, Accuracy: 25.0574, Test Loss: 1.5793, Test Accuracy: 23.8171\n",
      "Epoch 133, Loss: 2.3932, Accuracy: 25.0627, Test Loss: 1.5792, Test Accuracy: 23.8095\n",
      "Epoch 134, Loss: 2.3871, Accuracy: 25.0678, Test Loss: 1.5791, Test Accuracy: 23.8020\n",
      "Epoch 135, Loss: 2.3811, Accuracy: 25.0730, Test Loss: 1.5790, Test Accuracy: 23.7947\n",
      "Epoch 136, Loss: 2.3752, Accuracy: 25.0780, Test Loss: 1.5789, Test Accuracy: 23.7874\n",
      "Epoch 137, Loss: 2.3695, Accuracy: 25.0829, Test Loss: 1.5787, Test Accuracy: 23.7803\n",
      "Epoch 138, Loss: 2.3639, Accuracy: 25.0878, Test Loss: 1.5786, Test Accuracy: 23.7732\n",
      "Epoch 139, Loss: 2.3582, Accuracy: 25.0927, Test Loss: 1.5785, Test Accuracy: 23.7662\n",
      "Epoch 140, Loss: 2.3526, Accuracy: 25.0974, Test Loss: 1.5784, Test Accuracy: 23.7594\n",
      "Epoch 141, Loss: 2.3471, Accuracy: 25.1021, Test Loss: 1.5783, Test Accuracy: 23.7526\n",
      "Epoch 142, Loss: 2.3417, Accuracy: 25.1067, Test Loss: 1.5782, Test Accuracy: 23.7460\n",
      "Epoch 143, Loss: 2.3363, Accuracy: 25.1113, Test Loss: 1.5781, Test Accuracy: 23.7394\n",
      "Epoch 144, Loss: 2.3311, Accuracy: 25.1157, Test Loss: 1.5779, Test Accuracy: 23.7329\n",
      "Epoch 145, Loss: 2.3259, Accuracy: 25.1202, Test Loss: 1.5778, Test Accuracy: 23.7266\n",
      "Epoch 146, Loss: 2.3206, Accuracy: 25.1245, Test Loss: 1.5777, Test Accuracy: 23.7203\n",
      "Epoch 147, Loss: 2.3154, Accuracy: 25.1288, Test Loss: 1.5776, Test Accuracy: 23.7140\n",
      "Epoch 148, Loss: 2.3105, Accuracy: 25.1331, Test Loss: 1.5775, Test Accuracy: 23.7079\n",
      "Epoch 149, Loss: 2.3055, Accuracy: 25.1373, Test Loss: 1.5774, Test Accuracy: 23.7019\n",
      "Epoch 150, Loss: 2.3007, Accuracy: 25.1414, Test Loss: 1.5773, Test Accuracy: 23.6959\n",
      "Epoch 151, Loss: 2.2960, Accuracy: 25.1455, Test Loss: 1.5772, Test Accuracy: 23.6900\n",
      "Epoch 152, Loss: 2.2912, Accuracy: 25.1495, Test Loss: 1.5771, Test Accuracy: 23.6842\n",
      "Epoch 153, Loss: 2.2865, Accuracy: 25.1535, Test Loss: 1.5770, Test Accuracy: 23.6785\n",
      "Epoch 154, Loss: 2.2818, Accuracy: 25.1574, Test Loss: 1.5769, Test Accuracy: 23.6728\n",
      "Epoch 155, Loss: 2.2774, Accuracy: 25.1613, Test Loss: 1.5767, Test Accuracy: 23.6672\n",
      "Epoch 156, Loss: 2.2729, Accuracy: 25.1651, Test Loss: 1.5766, Test Accuracy: 23.6617\n",
      "Epoch 157, Loss: 2.2685, Accuracy: 25.1689, Test Loss: 1.5765, Test Accuracy: 23.6563\n",
      "Epoch 158, Loss: 2.2640, Accuracy: 25.1726, Test Loss: 1.5764, Test Accuracy: 23.6509\n",
      "Epoch 159, Loss: 2.2597, Accuracy: 25.1763, Test Loss: 1.5763, Test Accuracy: 23.6456\n",
      "Epoch 160, Loss: 2.2554, Accuracy: 25.1799, Test Loss: 1.5762, Test Accuracy: 23.6404\n",
      "Epoch 161, Loss: 2.2512, Accuracy: 25.1835, Test Loss: 1.5761, Test Accuracy: 23.6352\n",
      "Epoch 162, Loss: 2.2470, Accuracy: 25.1871, Test Loss: 1.5760, Test Accuracy: 23.6301\n",
      "Epoch 163, Loss: 2.2429, Accuracy: 25.1906, Test Loss: 1.5759, Test Accuracy: 23.6250\n",
      "Epoch 164, Loss: 2.2390, Accuracy: 25.1940, Test Loss: 1.5758, Test Accuracy: 23.6200\n",
      "Epoch 165, Loss: 2.2349, Accuracy: 25.1974, Test Loss: 1.5757, Test Accuracy: 23.6151\n",
      "Epoch 166, Loss: 2.2310, Accuracy: 25.2008, Test Loss: 1.5756, Test Accuracy: 23.6102\n",
      "Epoch 167, Loss: 2.2270, Accuracy: 25.2041, Test Loss: 1.5755, Test Accuracy: 23.6054\n",
      "Epoch 168, Loss: 2.2231, Accuracy: 25.2074, Test Loss: 1.5755, Test Accuracy: 23.6007\n",
      "Epoch 169, Loss: 2.2193, Accuracy: 25.2107, Test Loss: 1.5754, Test Accuracy: 23.5960\n",
      "Epoch 170, Loss: 2.2155, Accuracy: 25.2139, Test Loss: 1.5753, Test Accuracy: 23.5913\n",
      "Epoch 171, Loss: 2.2119, Accuracy: 25.2171, Test Loss: 1.5752, Test Accuracy: 23.5867\n",
      "Epoch 172, Loss: 2.2082, Accuracy: 25.2202, Test Loss: 1.5751, Test Accuracy: 23.5822\n",
      "Epoch 173, Loss: 2.2045, Accuracy: 25.2233, Test Loss: 1.5750, Test Accuracy: 23.5777\n",
      "Epoch 174, Loss: 2.2009, Accuracy: 25.2264, Test Loss: 1.5750, Test Accuracy: 23.5733\n",
      "Epoch 175, Loss: 2.1975, Accuracy: 25.2294, Test Loss: 1.5749, Test Accuracy: 23.5689\n",
      "Epoch 176, Loss: 2.1941, Accuracy: 25.2324, Test Loss: 1.5748, Test Accuracy: 23.5646\n",
      "Epoch 177, Loss: 2.1907, Accuracy: 25.2354, Test Loss: 1.5747, Test Accuracy: 23.5603\n",
      "Epoch 178, Loss: 2.1873, Accuracy: 25.2383, Test Loss: 1.5746, Test Accuracy: 23.5561\n",
      "Epoch 179, Loss: 2.1838, Accuracy: 25.2412, Test Loss: 1.5746, Test Accuracy: 23.5519\n",
      "Epoch 180, Loss: 2.1804, Accuracy: 25.2441, Test Loss: 1.5745, Test Accuracy: 23.5478\n",
      "Epoch 181, Loss: 2.1771, Accuracy: 25.2469, Test Loss: 1.5744, Test Accuracy: 23.5437\n",
      "Epoch 182, Loss: 2.1737, Accuracy: 25.2498, Test Loss: 1.5743, Test Accuracy: 23.5396\n",
      "Epoch 183, Loss: 2.1707, Accuracy: 25.2525, Test Loss: 1.5742, Test Accuracy: 23.5356\n",
      "Epoch 184, Loss: 2.1676, Accuracy: 25.2553, Test Loss: 1.5742, Test Accuracy: 23.5317\n",
      "Epoch 185, Loss: 2.1643, Accuracy: 25.2580, Test Loss: 1.5741, Test Accuracy: 23.5277\n",
      "Epoch 186, Loss: 2.1613, Accuracy: 25.2607, Test Loss: 1.5740, Test Accuracy: 23.5239\n",
      "Epoch 187, Loss: 2.1581, Accuracy: 25.2633, Test Loss: 1.5739, Test Accuracy: 23.5200\n",
      "Epoch 188, Loss: 2.1549, Accuracy: 25.2660, Test Loss: 1.5739, Test Accuracy: 23.5162\n",
      "Epoch 189, Loss: 2.1519, Accuracy: 25.2686, Test Loss: 1.5738, Test Accuracy: 23.5125\n",
      "Epoch 190, Loss: 2.1491, Accuracy: 25.2711, Test Loss: 1.5737, Test Accuracy: 23.5088\n",
      "Epoch 191, Loss: 2.1461, Accuracy: 25.2737, Test Loss: 1.5737, Test Accuracy: 23.5051\n",
      "Epoch 192, Loss: 2.1430, Accuracy: 25.2762, Test Loss: 1.5736, Test Accuracy: 23.5015\n",
      "Epoch 193, Loss: 2.1401, Accuracy: 25.2787, Test Loss: 1.5735, Test Accuracy: 23.4979\n",
      "Epoch 194, Loss: 2.1374, Accuracy: 25.2812, Test Loss: 1.5734, Test Accuracy: 23.4943\n",
      "Epoch 195, Loss: 2.1346, Accuracy: 25.2836, Test Loss: 1.5734, Test Accuracy: 23.4908\n",
      "Epoch 196, Loss: 2.1318, Accuracy: 25.2860, Test Loss: 1.5733, Test Accuracy: 23.4873\n",
      "Epoch 197, Loss: 2.1290, Accuracy: 25.2884, Test Loss: 1.5732, Test Accuracy: 23.4838\n",
      "Epoch 198, Loss: 2.1261, Accuracy: 25.2908, Test Loss: 1.5732, Test Accuracy: 23.4804\n",
      "Epoch 199, Loss: 2.1235, Accuracy: 25.2931, Test Loss: 1.5731, Test Accuracy: 23.4770\n",
      "Epoch 200, Loss: 2.1208, Accuracy: 25.2955, Test Loss: 1.5730, Test Accuracy: 23.4737\n",
      "average of 14 each\n",
      "Epoch 1, Loss: 21.3492, Accuracy: 23.1405, Test Loss: 1.5982, Test Accuracy: 21.1538\n",
      "Epoch 2, Loss: 19.0284, Accuracy: 23.5537, Test Loss: 1.5980, Test Accuracy: 21.1538\n",
      "Epoch 3, Loss: 17.5486, Accuracy: 22.0386, Test Loss: 1.6016, Test Accuracy: 18.5897\n",
      "Epoch 4, Loss: 15.6141, Accuracy: 23.5537, Test Loss: 1.6056, Test Accuracy: 18.2692\n",
      "Epoch 5, Loss: 13.9659, Accuracy: 24.1322, Test Loss: 1.6038, Test Accuracy: 19.2308\n",
      "Epoch 6, Loss: 12.5784, Accuracy: 24.6556, Test Loss: 1.6046, Test Accuracy: 19.2308\n",
      "Epoch 7, Loss: 11.3323, Accuracy: 25.2656, Test Loss: 1.6050, Test Accuracy: 20.3297\n",
      "Epoch 8, Loss: 10.3651, Accuracy: 25.2066, Test Loss: 1.6053, Test Accuracy: 20.6731\n",
      "Epoch 9, Loss: 9.4768, Accuracy: 25.5280, Test Loss: 1.6056, Test Accuracy: 20.9402\n",
      "Epoch 10, Loss: 8.7420, Accuracy: 25.2066, Test Loss: 1.6058, Test Accuracy: 21.1538\n",
      "Epoch 11, Loss: 8.1291, Accuracy: 25.2442, Test Loss: 1.6059, Test Accuracy: 21.3287\n",
      "Epoch 12, Loss: 7.5932, Accuracy: 25.4821, Test Loss: 1.6060, Test Accuracy: 21.4744\n",
      "Epoch 13, Loss: 7.1333, Accuracy: 25.3020, Test Loss: 1.6060, Test Accuracy: 21.5976\n",
      "Epoch 14, Loss: 6.7435, Accuracy: 25.3247, Test Loss: 1.6059, Test Accuracy: 21.7033\n",
      "Epoch 15, Loss: 6.4127, Accuracy: 25.1791, Test Loss: 1.6058, Test Accuracy: 21.6667\n",
      "Epoch 16, Loss: 6.1121, Accuracy: 25.1033, Test Loss: 1.6057, Test Accuracy: 21.7548\n",
      "Epoch 17, Loss: 5.8465, Accuracy: 24.9878, Test Loss: 1.6056, Test Accuracy: 21.7195\n",
      "Epoch 18, Loss: 5.6131, Accuracy: 25.1148, Test Loss: 1.6054, Test Accuracy: 21.6880\n",
      "Epoch 19, Loss: 5.4020, Accuracy: 25.2284, Test Loss: 1.6052, Test Accuracy: 21.6599\n",
      "Epoch 20, Loss: 5.2147, Accuracy: 25.2479, Test Loss: 1.6051, Test Accuracy: 21.7308\n",
      "Epoch 21, Loss: 5.0438, Accuracy: 25.0295, Test Loss: 1.6049, Test Accuracy: 21.7949\n",
      "Epoch 22, Loss: 4.8865, Accuracy: 25.2066, Test Loss: 1.6047, Test Accuracy: 21.8531\n",
      "Epoch 23, Loss: 4.7429, Accuracy: 25.1886, Test Loss: 1.6044, Test Accuracy: 21.9064\n",
      "Epoch 24, Loss: 4.6114, Accuracy: 25.1033, Test Loss: 1.6042, Test Accuracy: 21.9551\n",
      "Epoch 25, Loss: 4.4911, Accuracy: 25.0909, Test Loss: 1.6040, Test Accuracy: 22.0000\n",
      "Epoch 26, Loss: 4.3824, Accuracy: 25.1748, Test Loss: 1.6038, Test Accuracy: 22.0414\n",
      "Epoch 27, Loss: 4.2793, Accuracy: 25.2219, Test Loss: 1.6036, Test Accuracy: 22.0798\n",
      "Epoch 28, Loss: 4.1845, Accuracy: 25.0000, Test Loss: 1.6033, Test Accuracy: 22.0467\n",
      "Epoch 29, Loss: 4.0979, Accuracy: 25.0784, Test Loss: 1.6031, Test Accuracy: 22.0159\n",
      "Epoch 30, Loss: 4.0167, Accuracy: 25.0964, Test Loss: 1.6029, Test Accuracy: 21.9872\n",
      "Epoch 31, Loss: 3.9388, Accuracy: 25.1400, Test Loss: 1.6026, Test Accuracy: 21.9603\n",
      "Epoch 32, Loss: 3.8654, Accuracy: 25.1808, Test Loss: 1.6024, Test Accuracy: 21.9351\n",
      "Epoch 33, Loss: 3.7960, Accuracy: 25.2442, Test Loss: 1.6021, Test Accuracy: 21.9114\n",
      "Epoch 34, Loss: 3.7312, Accuracy: 25.2795, Test Loss: 1.6019, Test Accuracy: 21.8891\n",
      "Epoch 35, Loss: 3.6704, Accuracy: 25.2893, Test Loss: 1.6016, Test Accuracy: 21.8681\n",
      "Epoch 36, Loss: 3.6130, Accuracy: 25.3214, Test Loss: 1.6014, Test Accuracy: 21.8483\n",
      "Epoch 37, Loss: 3.5596, Accuracy: 25.3518, Test Loss: 1.6011, Test Accuracy: 21.8295\n",
      "Epoch 38, Loss: 3.5078, Accuracy: 25.3806, Test Loss: 1.6009, Test Accuracy: 21.8117\n",
      "Epoch 39, Loss: 3.4586, Accuracy: 25.4079, Test Loss: 1.6007, Test Accuracy: 21.7949\n",
      "Epoch 40, Loss: 3.4122, Accuracy: 25.4132, Test Loss: 1.6004, Test Accuracy: 21.7788\n",
      "Epoch 41, Loss: 3.3677, Accuracy: 25.4384, Test Loss: 1.6002, Test Accuracy: 21.7636\n",
      "Epoch 42, Loss: 3.3252, Accuracy: 25.4624, Test Loss: 1.5999, Test Accuracy: 21.7491\n",
      "Epoch 43, Loss: 3.2847, Accuracy: 25.4853, Test Loss: 1.5997, Test Accuracy: 21.7352\n",
      "Epoch 44, Loss: 3.2462, Accuracy: 25.4884, Test Loss: 1.5994, Test Accuracy: 21.7220\n",
      "Epoch 45, Loss: 3.2093, Accuracy: 25.4913, Test Loss: 1.5992, Test Accuracy: 21.7094\n",
      "Epoch 46, Loss: 3.1749, Accuracy: 25.5120, Test Loss: 1.5989, Test Accuracy: 21.6973\n",
      "Epoch 47, Loss: 3.1411, Accuracy: 25.5319, Test Loss: 1.5987, Test Accuracy: 21.6858\n",
      "Epoch 48, Loss: 3.1092, Accuracy: 25.5510, Test Loss: 1.5985, Test Accuracy: 21.6747\n",
      "Epoch 49, Loss: 3.0781, Accuracy: 25.5692, Test Loss: 1.5982, Test Accuracy: 21.6641\n",
      "Epoch 50, Loss: 3.0482, Accuracy: 25.5868, Test Loss: 1.5980, Test Accuracy: 21.6538\n",
      "Epoch 51, Loss: 3.0195, Accuracy: 25.6036, Test Loss: 1.5978, Test Accuracy: 21.6440\n",
      "Epoch 52, Loss: 2.9919, Accuracy: 25.6198, Test Loss: 1.5975, Test Accuracy: 21.6346\n",
      "Epoch 53, Loss: 2.9653, Accuracy: 25.6354, Test Loss: 1.5973, Test Accuracy: 21.6255\n",
      "Epoch 54, Loss: 2.9397, Accuracy: 25.6504, Test Loss: 1.5971, Test Accuracy: 21.6168\n",
      "Epoch 55, Loss: 2.9149, Accuracy: 25.6499, Test Loss: 1.5968, Test Accuracy: 21.6084\n",
      "Epoch 56, Loss: 2.8911, Accuracy: 25.6789, Test Loss: 1.5966, Test Accuracy: 21.6003\n",
      "Epoch 57, Loss: 2.8686, Accuracy: 25.6923, Test Loss: 1.5964, Test Accuracy: 21.5924\n",
      "Epoch 58, Loss: 2.8462, Accuracy: 25.7196, Test Loss: 1.5962, Test Accuracy: 21.5849\n",
      "Epoch 59, Loss: 2.8247, Accuracy: 25.7319, Test Loss: 1.5959, Test Accuracy: 21.5776\n",
      "Epoch 60, Loss: 2.8039, Accuracy: 25.7438, Test Loss: 1.5957, Test Accuracy: 21.5705\n",
      "Epoch 61, Loss: 2.7838, Accuracy: 25.7553, Test Loss: 1.5955, Test Accuracy: 21.5637\n",
      "Epoch 62, Loss: 2.7644, Accuracy: 25.7665, Test Loss: 1.5953, Test Accuracy: 21.5571\n",
      "Epoch 63, Loss: 2.7455, Accuracy: 25.7773, Test Loss: 1.5951, Test Accuracy: 21.5507\n",
      "Epoch 64, Loss: 2.7273, Accuracy: 25.8006, Test Loss: 1.5948, Test Accuracy: 21.5445\n",
      "Epoch 65, Loss: 2.7101, Accuracy: 25.7978, Test Loss: 1.5946, Test Accuracy: 21.5385\n",
      "Epoch 66, Loss: 2.6932, Accuracy: 25.8077, Test Loss: 1.5944, Test Accuracy: 21.5326\n",
      "Epoch 67, Loss: 2.6765, Accuracy: 25.8172, Test Loss: 1.5942, Test Accuracy: 21.5270\n",
      "Epoch 68, Loss: 2.6603, Accuracy: 25.8264, Test Loss: 1.5940, Test Accuracy: 21.5215\n",
      "Epoch 69, Loss: 2.6454, Accuracy: 25.8235, Test Loss: 1.5938, Test Accuracy: 21.5162\n",
      "Epoch 70, Loss: 2.6301, Accuracy: 25.8323, Test Loss: 1.5936, Test Accuracy: 21.5110\n",
      "Epoch 71, Loss: 2.6152, Accuracy: 25.8410, Test Loss: 1.5934, Test Accuracy: 21.5060\n",
      "Epoch 72, Loss: 2.6008, Accuracy: 25.8494, Test Loss: 1.5932, Test Accuracy: 21.5011\n",
      "Epoch 73, Loss: 2.5867, Accuracy: 25.8576, Test Loss: 1.5930, Test Accuracy: 21.4963\n",
      "Epoch 74, Loss: 2.5730, Accuracy: 25.8655, Test Loss: 1.5928, Test Accuracy: 21.4917\n",
      "Epoch 75, Loss: 2.5597, Accuracy: 25.8733, Test Loss: 1.5927, Test Accuracy: 21.4872\n",
      "Epoch 76, Loss: 2.5471, Accuracy: 25.8699, Test Loss: 1.5925, Test Accuracy: 21.4828\n",
      "Epoch 77, Loss: 2.5344, Accuracy: 25.8774, Test Loss: 1.5923, Test Accuracy: 21.4785\n",
      "Epoch 78, Loss: 2.5221, Accuracy: 25.8847, Test Loss: 1.5921, Test Accuracy: 21.4744\n",
      "Epoch 79, Loss: 2.5101, Accuracy: 25.8918, Test Loss: 1.5919, Test Accuracy: 21.4703\n",
      "Epoch 80, Loss: 2.4983, Accuracy: 25.8988, Test Loss: 1.5917, Test Accuracy: 21.4663\n",
      "Epoch 81, Loss: 2.4870, Accuracy: 25.9055, Test Loss: 1.5916, Test Accuracy: 21.4625\n",
      "Epoch 82, Loss: 2.4758, Accuracy: 25.9222, Test Loss: 1.5914, Test Accuracy: 21.4587\n",
      "Epoch 83, Loss: 2.4648, Accuracy: 25.9385, Test Loss: 1.5912, Test Accuracy: 21.4551\n",
      "Epoch 84, Loss: 2.4546, Accuracy: 25.9445, Test Loss: 1.5910, Test Accuracy: 21.4515\n",
      "Epoch 85, Loss: 2.4442, Accuracy: 25.9504, Test Loss: 1.5909, Test Accuracy: 21.4480\n",
      "Epoch 86, Loss: 2.4340, Accuracy: 25.9658, Test Loss: 1.5907, Test Accuracy: 21.4445\n",
      "Epoch 87, Loss: 2.4244, Accuracy: 25.9713, Test Loss: 1.5905, Test Accuracy: 21.4412\n",
      "Epoch 88, Loss: 2.4147, Accuracy: 25.9767, Test Loss: 1.5903, Test Accuracy: 21.4379\n",
      "Epoch 89, Loss: 2.4053, Accuracy: 25.9820, Test Loss: 1.5902, Test Accuracy: 21.4347\n",
      "Epoch 90, Loss: 2.3960, Accuracy: 25.9871, Test Loss: 1.5900, Test Accuracy: 21.4316\n",
      "Epoch 91, Loss: 2.3876, Accuracy: 25.9922, Test Loss: 1.5899, Test Accuracy: 21.4286\n",
      "Epoch 92, Loss: 2.3787, Accuracy: 25.9971, Test Loss: 1.5897, Test Accuracy: 21.4256\n",
      "Epoch 93, Loss: 2.3699, Accuracy: 26.0020, Test Loss: 1.5895, Test Accuracy: 21.4227\n",
      "Epoch 94, Loss: 2.3615, Accuracy: 25.9979, Test Loss: 1.5894, Test Accuracy: 21.4198\n",
      "Epoch 95, Loss: 2.3531, Accuracy: 26.0026, Test Loss: 1.5892, Test Accuracy: 21.4170\n",
      "Epoch 96, Loss: 2.3450, Accuracy: 26.0158, Test Loss: 1.5891, Test Accuracy: 21.4143\n",
      "Epoch 97, Loss: 2.3374, Accuracy: 26.0203, Test Loss: 1.5889, Test Accuracy: 21.4116\n",
      "Epoch 98, Loss: 2.3297, Accuracy: 26.0246, Test Loss: 1.5888, Test Accuracy: 21.4089\n",
      "Epoch 99, Loss: 2.3230, Accuracy: 26.0289, Test Loss: 1.5886, Test Accuracy: 21.4064\n",
      "Epoch 100, Loss: 2.3155, Accuracy: 26.0331, Test Loss: 1.5885, Test Accuracy: 21.4038\n",
      "Epoch 101, Loss: 2.3082, Accuracy: 26.0372, Test Loss: 1.5883, Test Accuracy: 21.4014\n",
      "Epoch 102, Loss: 2.3009, Accuracy: 26.0412, Test Loss: 1.5882, Test Accuracy: 21.3989\n",
      "Epoch 103, Loss: 2.2938, Accuracy: 26.0451, Test Loss: 1.5880, Test Accuracy: 21.3966\n",
      "Epoch 104, Loss: 2.2868, Accuracy: 26.0490, Test Loss: 1.5879, Test Accuracy: 21.3942\n",
      "Epoch 105, Loss: 2.2800, Accuracy: 26.0527, Test Loss: 1.5877, Test Accuracy: 21.3919\n",
      "Epoch 106, Loss: 2.2731, Accuracy: 26.0642, Test Loss: 1.5876, Test Accuracy: 21.3897\n",
      "Epoch 107, Loss: 2.2665, Accuracy: 26.0678, Test Loss: 1.5875, Test Accuracy: 21.3875\n",
      "Epoch 108, Loss: 2.2602, Accuracy: 26.0713, Test Loss: 1.5873, Test Accuracy: 21.3853\n",
      "Epoch 109, Loss: 2.2539, Accuracy: 26.0748, Test Loss: 1.5872, Test Accuracy: 21.3832\n",
      "Epoch 110, Loss: 2.2477, Accuracy: 26.0781, Test Loss: 1.5871, Test Accuracy: 21.3811\n",
      "Epoch 111, Loss: 2.2416, Accuracy: 26.0815, Test Loss: 1.5869, Test Accuracy: 21.3791\n",
      "Epoch 112, Loss: 2.2356, Accuracy: 26.0847, Test Loss: 1.5868, Test Accuracy: 21.3771\n",
      "Epoch 113, Loss: 2.2297, Accuracy: 26.0879, Test Loss: 1.5867, Test Accuracy: 21.3751\n",
      "Epoch 114, Loss: 2.2238, Accuracy: 26.0911, Test Loss: 1.5865, Test Accuracy: 21.3731\n",
      "Epoch 115, Loss: 2.2181, Accuracy: 26.0941, Test Loss: 1.5864, Test Accuracy: 21.3712\n",
      "Epoch 116, Loss: 2.2125, Accuracy: 26.0972, Test Loss: 1.5863, Test Accuracy: 21.3694\n",
      "Epoch 117, Loss: 2.2070, Accuracy: 26.1002, Test Loss: 1.5862, Test Accuracy: 21.3675\n",
      "Epoch 118, Loss: 2.2016, Accuracy: 26.1031, Test Loss: 1.5861, Test Accuracy: 21.3657\n",
      "Epoch 119, Loss: 2.1963, Accuracy: 26.1060, Test Loss: 1.5859, Test Accuracy: 21.3639\n",
      "Epoch 120, Loss: 2.1910, Accuracy: 26.1088, Test Loss: 1.5858, Test Accuracy: 21.3622\n",
      "Epoch 121, Loss: 2.1858, Accuracy: 26.1116, Test Loss: 1.5857, Test Accuracy: 21.3605\n",
      "Epoch 122, Loss: 2.1808, Accuracy: 26.1143, Test Loss: 1.5856, Test Accuracy: 21.3588\n",
      "Epoch 123, Loss: 2.1758, Accuracy: 26.1170, Test Loss: 1.5855, Test Accuracy: 21.3571\n",
      "Epoch 124, Loss: 2.1709, Accuracy: 26.1197, Test Loss: 1.5853, Test Accuracy: 21.3555\n",
      "Epoch 125, Loss: 2.1660, Accuracy: 26.1223, Test Loss: 1.5852, Test Accuracy: 21.3538\n",
      "Epoch 126, Loss: 2.1612, Accuracy: 26.1249, Test Loss: 1.5851, Test Accuracy: 21.3523\n",
      "Epoch 127, Loss: 2.1565, Accuracy: 26.1274, Test Loss: 1.5850, Test Accuracy: 21.3507\n",
      "Epoch 128, Loss: 2.1519, Accuracy: 26.1299, Test Loss: 1.5849, Test Accuracy: 21.3492\n",
      "Epoch 129, Loss: 2.1473, Accuracy: 26.1324, Test Loss: 1.5848, Test Accuracy: 21.3476\n",
      "Epoch 130, Loss: 2.1428, Accuracy: 26.1348, Test Loss: 1.5847, Test Accuracy: 21.3462\n",
      "Epoch 131, Loss: 2.1384, Accuracy: 26.1372, Test Loss: 1.5846, Test Accuracy: 21.3447\n",
      "Epoch 132, Loss: 2.1341, Accuracy: 26.1395, Test Loss: 1.5845, Test Accuracy: 21.3432\n",
      "Epoch 133, Loss: 2.1298, Accuracy: 26.1418, Test Loss: 1.5844, Test Accuracy: 21.3418\n",
      "Epoch 134, Loss: 2.1256, Accuracy: 26.1441, Test Loss: 1.5843, Test Accuracy: 21.3404\n",
      "Epoch 135, Loss: 2.1226, Accuracy: 26.1463, Test Loss: 1.5842, Test Accuracy: 21.3390\n",
      "Epoch 136, Loss: 2.1185, Accuracy: 26.1485, Test Loss: 1.5841, Test Accuracy: 21.3377\n",
      "Epoch 137, Loss: 2.1144, Accuracy: 26.1507, Test Loss: 1.5840, Test Accuracy: 21.3363\n",
      "Epoch 138, Loss: 2.1105, Accuracy: 26.1528, Test Loss: 1.5839, Test Accuracy: 21.3350\n",
      "Epoch 139, Loss: 2.1066, Accuracy: 26.1549, Test Loss: 1.5838, Test Accuracy: 21.3337\n",
      "Epoch 140, Loss: 2.1028, Accuracy: 26.1570, Test Loss: 1.5837, Test Accuracy: 21.3324\n",
      "Epoch 141, Loss: 2.0989, Accuracy: 26.1591, Test Loss: 1.5836, Test Accuracy: 21.3312\n",
      "Epoch 142, Loss: 2.0951, Accuracy: 26.1611, Test Loss: 1.5835, Test Accuracy: 21.3299\n",
      "Epoch 143, Loss: 2.0914, Accuracy: 26.1631, Test Loss: 1.5834, Test Accuracy: 21.3287\n",
      "Epoch 144, Loss: 2.0877, Accuracy: 26.1651, Test Loss: 1.5833, Test Accuracy: 21.3275\n",
      "Epoch 145, Loss: 2.0841, Accuracy: 26.1670, Test Loss: 1.5832, Test Accuracy: 21.3263\n",
      "Epoch 146, Loss: 2.0805, Accuracy: 26.1689, Test Loss: 1.5831, Test Accuracy: 21.3251\n",
      "Epoch 147, Loss: 2.0770, Accuracy: 26.1708, Test Loss: 1.5831, Test Accuracy: 21.3239\n",
      "Epoch 148, Loss: 2.0736, Accuracy: 26.1727, Test Loss: 1.5830, Test Accuracy: 21.3228\n",
      "Epoch 149, Loss: 2.0701, Accuracy: 26.1745, Test Loss: 1.5829, Test Accuracy: 21.3216\n",
      "Epoch 150, Loss: 2.0667, Accuracy: 26.1818, Test Loss: 1.5828, Test Accuracy: 21.3205\n",
      "Epoch 151, Loss: 2.0634, Accuracy: 26.1836, Test Loss: 1.5827, Test Accuracy: 21.3194\n",
      "Epoch 152, Loss: 2.0600, Accuracy: 26.1907, Test Loss: 1.5826, Test Accuracy: 21.3183\n",
      "Epoch 153, Loss: 2.0567, Accuracy: 26.1870, Test Loss: 1.5825, Test Accuracy: 21.3172\n",
      "Epoch 154, Loss: 2.0538, Accuracy: 26.1833, Test Loss: 1.5825, Test Accuracy: 21.3162\n",
      "Epoch 155, Loss: 2.0508, Accuracy: 26.1850, Test Loss: 1.5824, Test Accuracy: 21.3151\n",
      "Epoch 156, Loss: 2.0477, Accuracy: 26.1867, Test Loss: 1.5823, Test Accuracy: 21.3141\n",
      "Epoch 157, Loss: 2.0446, Accuracy: 26.1883, Test Loss: 1.5822, Test Accuracy: 21.3131\n",
      "Epoch 158, Loss: 2.0416, Accuracy: 26.1900, Test Loss: 1.5821, Test Accuracy: 21.3121\n",
      "Epoch 159, Loss: 2.0386, Accuracy: 26.1916, Test Loss: 1.5821, Test Accuracy: 21.3111\n",
      "Epoch 160, Loss: 2.0356, Accuracy: 26.1932, Test Loss: 1.5820, Test Accuracy: 21.3101\n",
      "Epoch 161, Loss: 2.0326, Accuracy: 26.1948, Test Loss: 1.5819, Test Accuracy: 21.3091\n",
      "Epoch 162, Loss: 2.0297, Accuracy: 26.1963, Test Loss: 1.5818, Test Accuracy: 21.3082\n",
      "Epoch 163, Loss: 2.0268, Accuracy: 26.1978, Test Loss: 1.5818, Test Accuracy: 21.3072\n",
      "Epoch 164, Loss: 2.0240, Accuracy: 26.1994, Test Loss: 1.5817, Test Accuracy: 21.3063\n",
      "Epoch 165, Loss: 2.0212, Accuracy: 26.2009, Test Loss: 1.5816, Test Accuracy: 21.3054\n",
      "Epoch 166, Loss: 2.0184, Accuracy: 26.2073, Test Loss: 1.5815, Test Accuracy: 21.3044\n",
      "Epoch 167, Loss: 2.0156, Accuracy: 26.2087, Test Loss: 1.5815, Test Accuracy: 21.3035\n",
      "Epoch 168, Loss: 2.0129, Accuracy: 26.2102, Test Loss: 1.5814, Test Accuracy: 21.3027\n",
      "Epoch 169, Loss: 2.0103, Accuracy: 26.2116, Test Loss: 1.5813, Test Accuracy: 21.3018\n",
      "Epoch 170, Loss: 2.0076, Accuracy: 26.2129, Test Loss: 1.5813, Test Accuracy: 21.3009\n",
      "Epoch 171, Loss: 2.0050, Accuracy: 26.2143, Test Loss: 1.5812, Test Accuracy: 21.3000\n",
      "Epoch 172, Loss: 2.0024, Accuracy: 26.2156, Test Loss: 1.5811, Test Accuracy: 21.2992\n",
      "Epoch 173, Loss: 1.9999, Accuracy: 26.2170, Test Loss: 1.5811, Test Accuracy: 21.2984\n",
      "Epoch 174, Loss: 1.9974, Accuracy: 26.2183, Test Loss: 1.5810, Test Accuracy: 21.2975\n",
      "Epoch 175, Loss: 1.9949, Accuracy: 26.2196, Test Loss: 1.5809, Test Accuracy: 21.2967\n",
      "Epoch 176, Loss: 1.9924, Accuracy: 26.2209, Test Loss: 1.5809, Test Accuracy: 21.2959\n",
      "Epoch 177, Loss: 1.9900, Accuracy: 26.2222, Test Loss: 1.5808, Test Accuracy: 21.2951\n",
      "Epoch 178, Loss: 1.9876, Accuracy: 26.2234, Test Loss: 1.5807, Test Accuracy: 21.2943\n",
      "Epoch 179, Loss: 1.9852, Accuracy: 26.2247, Test Loss: 1.5807, Test Accuracy: 21.2935\n",
      "Epoch 180, Loss: 1.9829, Accuracy: 26.2213, Test Loss: 1.5806, Test Accuracy: 21.2927\n",
      "Epoch 181, Loss: 1.9806, Accuracy: 26.2225, Test Loss: 1.5805, Test Accuracy: 21.2920\n",
      "Epoch 182, Loss: 1.9783, Accuracy: 26.2238, Test Loss: 1.5805, Test Accuracy: 21.2912\n",
      "Epoch 183, Loss: 1.9760, Accuracy: 26.2250, Test Loss: 1.5804, Test Accuracy: 21.2905\n",
      "Epoch 184, Loss: 1.9738, Accuracy: 26.2262, Test Loss: 1.5804, Test Accuracy: 21.2897\n",
      "Epoch 185, Loss: 1.9715, Accuracy: 26.2274, Test Loss: 1.5803, Test Accuracy: 21.2890\n",
      "Epoch 186, Loss: 1.9692, Accuracy: 26.2286, Test Loss: 1.5802, Test Accuracy: 21.2883\n",
      "Epoch 187, Loss: 1.9676, Accuracy: 26.2297, Test Loss: 1.5802, Test Accuracy: 21.2875\n",
      "Epoch 188, Loss: 1.9654, Accuracy: 26.2309, Test Loss: 1.5801, Test Accuracy: 21.2868\n",
      "Epoch 189, Loss: 1.9632, Accuracy: 26.2320, Test Loss: 1.5801, Test Accuracy: 21.2861\n",
      "Epoch 190, Loss: 1.9611, Accuracy: 26.2331, Test Loss: 1.5800, Test Accuracy: 21.2854\n",
      "Epoch 191, Loss: 1.9590, Accuracy: 26.2343, Test Loss: 1.5800, Test Accuracy: 21.2847\n",
      "Epoch 192, Loss: 1.9569, Accuracy: 26.2354, Test Loss: 1.5799, Test Accuracy: 21.2841\n",
      "Epoch 193, Loss: 1.9548, Accuracy: 26.2365, Test Loss: 1.5798, Test Accuracy: 21.2834\n",
      "Epoch 194, Loss: 1.9528, Accuracy: 26.2375, Test Loss: 1.5798, Test Accuracy: 21.2827\n",
      "Epoch 195, Loss: 1.9507, Accuracy: 26.2428, Test Loss: 1.5797, Test Accuracy: 21.2821\n",
      "Epoch 196, Loss: 1.9488, Accuracy: 26.2439, Test Loss: 1.5797, Test Accuracy: 21.2814\n",
      "Epoch 197, Loss: 1.9468, Accuracy: 26.2449, Test Loss: 1.5796, Test Accuracy: 21.2807\n",
      "Epoch 198, Loss: 1.9449, Accuracy: 26.2459, Test Loss: 1.5796, Test Accuracy: 21.2801\n",
      "Epoch 199, Loss: 1.9429, Accuracy: 26.2469, Test Loss: 1.5795, Test Accuracy: 21.2795\n",
      "Epoch 200, Loss: 1.9410, Accuracy: 26.2479, Test Loss: 1.5795, Test Accuracy: 21.2788\n",
      "average of 15 each\n",
      "Epoch 1, Loss: 26.5419, Accuracy: 24.1071, Test Loss: 1.5824, Test Accuracy: 27.0833\n",
      "Epoch 2, Loss: 23.7964, Accuracy: 23.6607, Test Loss: 1.5956, Test Accuracy: 26.0417\n",
      "Epoch 3, Loss: 21.3372, Accuracy: 21.7262, Test Loss: 1.6020, Test Accuracy: 25.6944\n",
      "Epoch 4, Loss: 18.9488, Accuracy: 22.9911, Test Loss: 1.6041, Test Accuracy: 24.4792\n",
      "Epoch 5, Loss: 17.1432, Accuracy: 23.5714, Test Loss: 1.6047, Test Accuracy: 23.3333\n",
      "Epoch 6, Loss: 15.4454, Accuracy: 23.3631, Test Loss: 1.6058, Test Accuracy: 22.9167\n",
      "Epoch 7, Loss: 13.9385, Accuracy: 22.7041, Test Loss: 1.6062, Test Accuracy: 22.6190\n",
      "Epoch 8, Loss: 12.5818, Accuracy: 22.6562, Test Loss: 1.6064, Test Accuracy: 22.3958\n",
      "Epoch 9, Loss: 11.4553, Accuracy: 22.5198, Test Loss: 1.6065, Test Accuracy: 22.2222\n",
      "Epoch 10, Loss: 10.5451, Accuracy: 22.4107, Test Loss: 1.6066, Test Accuracy: 22.0833\n",
      "Epoch 11, Loss: 9.7385, Accuracy: 22.8084, Test Loss: 1.6066, Test Accuracy: 21.9697\n",
      "Epoch 12, Loss: 9.0592, Accuracy: 23.4375, Test Loss: 1.6066, Test Accuracy: 21.8750\n",
      "Epoch 13, Loss: 8.4923, Accuracy: 23.6264, Test Loss: 1.6065, Test Accuracy: 21.7949\n",
      "Epoch 14, Loss: 8.0026, Accuracy: 23.7883, Test Loss: 1.6064, Test Accuracy: 21.7262\n",
      "Epoch 15, Loss: 7.5753, Accuracy: 23.9881, Test Loss: 1.6063, Test Accuracy: 21.6667\n",
      "Epoch 16, Loss: 7.2082, Accuracy: 24.2746, Test Loss: 1.6062, Test Accuracy: 21.6146\n",
      "Epoch 17, Loss: 6.8802, Accuracy: 24.3172, Test Loss: 1.6061, Test Accuracy: 21.5686\n",
      "Epoch 18, Loss: 6.5866, Accuracy: 24.4544, Test Loss: 1.6059, Test Accuracy: 21.5278\n",
      "Epoch 19, Loss: 6.3244, Accuracy: 24.5771, Test Loss: 1.6058, Test Accuracy: 21.4912\n",
      "Epoch 20, Loss: 6.0901, Accuracy: 24.5982, Test Loss: 1.6056, Test Accuracy: 21.4583\n",
      "Epoch 21, Loss: 5.8762, Accuracy: 24.7449, Test Loss: 1.6055, Test Accuracy: 21.4286\n",
      "Epoch 22, Loss: 5.6806, Accuracy: 24.8377, Test Loss: 1.6053, Test Accuracy: 21.4015\n",
      "Epoch 23, Loss: 5.5028, Accuracy: 24.8835, Test Loss: 1.6051, Test Accuracy: 21.3768\n",
      "Epoch 24, Loss: 5.3404, Accuracy: 24.9628, Test Loss: 1.6050, Test Accuracy: 21.3542\n",
      "Epoch 25, Loss: 5.1902, Accuracy: 25.0357, Test Loss: 1.6048, Test Accuracy: 21.3333\n",
      "Epoch 26, Loss: 5.0518, Accuracy: 25.1030, Test Loss: 1.6046, Test Accuracy: 21.3141\n",
      "Epoch 27, Loss: 4.9240, Accuracy: 25.1653, Test Loss: 1.6045, Test Accuracy: 21.2963\n",
      "Epoch 28, Loss: 4.8047, Accuracy: 25.2232, Test Loss: 1.6043, Test Accuracy: 21.2798\n",
      "Epoch 29, Loss: 4.6950, Accuracy: 25.2463, Test Loss: 1.6041, Test Accuracy: 21.2644\n",
      "Epoch 30, Loss: 4.5919, Accuracy: 25.2976, Test Loss: 1.6040, Test Accuracy: 21.2500\n",
      "Epoch 31, Loss: 4.4951, Accuracy: 25.3456, Test Loss: 1.6038, Test Accuracy: 21.2366\n",
      "Epoch 32, Loss: 4.4041, Accuracy: 25.3627, Test Loss: 1.6036, Test Accuracy: 21.2240\n",
      "Epoch 33, Loss: 4.3186, Accuracy: 25.4058, Test Loss: 1.6035, Test Accuracy: 21.2121\n",
      "Epoch 34, Loss: 4.2381, Accuracy: 25.4464, Test Loss: 1.6033, Test Accuracy: 21.2010\n",
      "Epoch 35, Loss: 4.1622, Accuracy: 25.4847, Test Loss: 1.6031, Test Accuracy: 21.1905\n",
      "Epoch 36, Loss: 4.0918, Accuracy: 25.5456, Test Loss: 1.6030, Test Accuracy: 21.1806\n",
      "Epoch 37, Loss: 4.0240, Accuracy: 25.5792, Test Loss: 1.6028, Test Accuracy: 21.1712\n",
      "Epoch 38, Loss: 3.9598, Accuracy: 25.6109, Test Loss: 1.6026, Test Accuracy: 21.1623\n",
      "Epoch 39, Loss: 3.8990, Accuracy: 25.6410, Test Loss: 1.6025, Test Accuracy: 21.1538\n",
      "Epoch 40, Loss: 3.8418, Accuracy: 25.6696, Test Loss: 1.6023, Test Accuracy: 21.1458\n",
      "Epoch 41, Loss: 3.7865, Accuracy: 25.6751, Test Loss: 1.6022, Test Accuracy: 21.1382\n",
      "Epoch 42, Loss: 3.7337, Accuracy: 25.7015, Test Loss: 1.6020, Test Accuracy: 21.1310\n",
      "Epoch 43, Loss: 3.6835, Accuracy: 25.7267, Test Loss: 1.6018, Test Accuracy: 21.1240\n",
      "Epoch 44, Loss: 3.6357, Accuracy: 25.7508, Test Loss: 1.6017, Test Accuracy: 21.1174\n",
      "Epoch 45, Loss: 3.5899, Accuracy: 25.7738, Test Loss: 1.6015, Test Accuracy: 21.1111\n",
      "Epoch 46, Loss: 3.5461, Accuracy: 25.7958, Test Loss: 1.6014, Test Accuracy: 21.1051\n",
      "Epoch 47, Loss: 3.5041, Accuracy: 25.8359, Test Loss: 1.6012, Test Accuracy: 21.0993\n",
      "Epoch 48, Loss: 3.4640, Accuracy: 25.8557, Test Loss: 1.6011, Test Accuracy: 21.0938\n",
      "Epoch 49, Loss: 3.4254, Accuracy: 25.8746, Test Loss: 1.6010, Test Accuracy: 21.0884\n",
      "Epoch 50, Loss: 3.3883, Accuracy: 25.8929, Test Loss: 1.6008, Test Accuracy: 21.0833\n",
      "Epoch 51, Loss: 3.3527, Accuracy: 25.9104, Test Loss: 1.6007, Test Accuracy: 21.0784\n",
      "Epoch 52, Loss: 3.3185, Accuracy: 25.9272, Test Loss: 1.6005, Test Accuracy: 21.0737\n",
      "Epoch 53, Loss: 3.2856, Accuracy: 25.9434, Test Loss: 1.6004, Test Accuracy: 21.0692\n",
      "Epoch 54, Loss: 3.2539, Accuracy: 25.9425, Test Loss: 1.6003, Test Accuracy: 21.0648\n",
      "Epoch 55, Loss: 3.2234, Accuracy: 25.9578, Test Loss: 1.6002, Test Accuracy: 21.0606\n",
      "Epoch 56, Loss: 3.1939, Accuracy: 25.9566, Test Loss: 1.6000, Test Accuracy: 21.0565\n",
      "Epoch 57, Loss: 3.1655, Accuracy: 25.9555, Test Loss: 1.5999, Test Accuracy: 21.0526\n",
      "Epoch 58, Loss: 3.1381, Accuracy: 25.9698, Test Loss: 1.5998, Test Accuracy: 21.0489\n",
      "Epoch 59, Loss: 3.1115, Accuracy: 25.9837, Test Loss: 1.5997, Test Accuracy: 21.0452\n",
      "Epoch 60, Loss: 3.0860, Accuracy: 25.9673, Test Loss: 1.5995, Test Accuracy: 21.0417\n",
      "Epoch 61, Loss: 3.0611, Accuracy: 25.9807, Test Loss: 1.5994, Test Accuracy: 21.0382\n",
      "Epoch 62, Loss: 3.0370, Accuracy: 25.9937, Test Loss: 1.5993, Test Accuracy: 21.0349\n",
      "Epoch 63, Loss: 3.0136, Accuracy: 26.0062, Test Loss: 1.5992, Test Accuracy: 21.0317\n",
      "Epoch 64, Loss: 2.9921, Accuracy: 26.0184, Test Loss: 1.5991, Test Accuracy: 21.0286\n",
      "Epoch 65, Loss: 2.9716, Accuracy: 26.0302, Test Loss: 1.5990, Test Accuracy: 21.0256\n",
      "Epoch 66, Loss: 2.9503, Accuracy: 26.0417, Test Loss: 1.5989, Test Accuracy: 21.0227\n",
      "Epoch 67, Loss: 2.9296, Accuracy: 26.0528, Test Loss: 1.5988, Test Accuracy: 21.0199\n",
      "Epoch 68, Loss: 2.9095, Accuracy: 26.0767, Test Loss: 1.5987, Test Accuracy: 21.0172\n",
      "Epoch 69, Loss: 2.8899, Accuracy: 26.0870, Test Loss: 1.5985, Test Accuracy: 21.0145\n",
      "Epoch 70, Loss: 2.8711, Accuracy: 26.0969, Test Loss: 1.5984, Test Accuracy: 21.0119\n",
      "Epoch 71, Loss: 2.8527, Accuracy: 26.1066, Test Loss: 1.5983, Test Accuracy: 21.0094\n",
      "Epoch 72, Loss: 2.8347, Accuracy: 26.1161, Test Loss: 1.5982, Test Accuracy: 21.0069\n",
      "Epoch 73, Loss: 2.8174, Accuracy: 26.1252, Test Loss: 1.5981, Test Accuracy: 21.0046\n",
      "Epoch 74, Loss: 2.8004, Accuracy: 26.1342, Test Loss: 1.5981, Test Accuracy: 21.0023\n",
      "Epoch 75, Loss: 2.7841, Accuracy: 26.1429, Test Loss: 1.5980, Test Accuracy: 21.0000\n",
      "Epoch 76, Loss: 2.7681, Accuracy: 26.1513, Test Loss: 1.5979, Test Accuracy: 20.9978\n",
      "Epoch 77, Loss: 2.7524, Accuracy: 26.1596, Test Loss: 1.5978, Test Accuracy: 20.9957\n",
      "Epoch 78, Loss: 2.7371, Accuracy: 26.1676, Test Loss: 1.5977, Test Accuracy: 20.9936\n",
      "Epoch 79, Loss: 2.7223, Accuracy: 26.1754, Test Loss: 1.5976, Test Accuracy: 20.9916\n",
      "Epoch 80, Loss: 2.7078, Accuracy: 26.1830, Test Loss: 1.5975, Test Accuracy: 20.9896\n",
      "Epoch 81, Loss: 2.6937, Accuracy: 26.1905, Test Loss: 1.5974, Test Accuracy: 20.9877\n",
      "Epoch 82, Loss: 2.6801, Accuracy: 26.1977, Test Loss: 1.5974, Test Accuracy: 20.9858\n",
      "Epoch 83, Loss: 2.6668, Accuracy: 26.2048, Test Loss: 1.5973, Test Accuracy: 20.9839\n",
      "Epoch 84, Loss: 2.6540, Accuracy: 26.2117, Test Loss: 1.5972, Test Accuracy: 20.9821\n",
      "Epoch 85, Loss: 2.6410, Accuracy: 26.2185, Test Loss: 1.5971, Test Accuracy: 20.9804\n",
      "Epoch 86, Loss: 2.6287, Accuracy: 26.2355, Test Loss: 1.5971, Test Accuracy: 20.9787\n",
      "Epoch 87, Loss: 2.6187, Accuracy: 26.2418, Test Loss: 1.5970, Test Accuracy: 20.9770\n",
      "Epoch 88, Loss: 2.6066, Accuracy: 26.2480, Test Loss: 1.5969, Test Accuracy: 20.9754\n",
      "Epoch 89, Loss: 2.5949, Accuracy: 26.2540, Test Loss: 1.5968, Test Accuracy: 20.9738\n",
      "Epoch 90, Loss: 2.5835, Accuracy: 26.2599, Test Loss: 1.5968, Test Accuracy: 20.9722\n",
      "Epoch 91, Loss: 2.5723, Accuracy: 26.2657, Test Loss: 1.5967, Test Accuracy: 20.9707\n",
      "Epoch 92, Loss: 2.5613, Accuracy: 26.2714, Test Loss: 1.5966, Test Accuracy: 20.9692\n",
      "Epoch 93, Loss: 2.5503, Accuracy: 26.2769, Test Loss: 1.5966, Test Accuracy: 20.9677\n",
      "Epoch 94, Loss: 2.5398, Accuracy: 26.2823, Test Loss: 1.5965, Test Accuracy: 20.9663\n",
      "Epoch 95, Loss: 2.5294, Accuracy: 26.2876, Test Loss: 1.5964, Test Accuracy: 20.9649\n",
      "Epoch 96, Loss: 2.5193, Accuracy: 26.2928, Test Loss: 1.5964, Test Accuracy: 20.9635\n",
      "Epoch 97, Loss: 2.5093, Accuracy: 26.2979, Test Loss: 1.5963, Test Accuracy: 20.9622\n",
      "Epoch 98, Loss: 2.4996, Accuracy: 26.3028, Test Loss: 1.5962, Test Accuracy: 20.9609\n",
      "Epoch 99, Loss: 2.4901, Accuracy: 26.3077, Test Loss: 1.5962, Test Accuracy: 20.9596\n",
      "Epoch 100, Loss: 2.4807, Accuracy: 26.3125, Test Loss: 1.5961, Test Accuracy: 20.9583\n",
      "Epoch 101, Loss: 2.4716, Accuracy: 26.3172, Test Loss: 1.5961, Test Accuracy: 20.9571\n",
      "Epoch 102, Loss: 2.4626, Accuracy: 26.3218, Test Loss: 1.5960, Test Accuracy: 20.9559\n",
      "Epoch 103, Loss: 2.4538, Accuracy: 26.3263, Test Loss: 1.5960, Test Accuracy: 20.9547\n",
      "Epoch 104, Loss: 2.4451, Accuracy: 26.3307, Test Loss: 1.5959, Test Accuracy: 20.9535\n",
      "Epoch 105, Loss: 2.4367, Accuracy: 26.3350, Test Loss: 1.5959, Test Accuracy: 20.9524\n",
      "Epoch 106, Loss: 2.4283, Accuracy: 26.3393, Test Loss: 1.5958, Test Accuracy: 20.9513\n",
      "Epoch 107, Loss: 2.4201, Accuracy: 26.3435, Test Loss: 1.5958, Test Accuracy: 20.9502\n",
      "Epoch 108, Loss: 2.4120, Accuracy: 26.3476, Test Loss: 1.5957, Test Accuracy: 20.9491\n",
      "Epoch 109, Loss: 2.4042, Accuracy: 26.3516, Test Loss: 1.5957, Test Accuracy: 20.9480\n",
      "Epoch 110, Loss: 2.3965, Accuracy: 26.3555, Test Loss: 1.5956, Test Accuracy: 20.9470\n",
      "Epoch 111, Loss: 2.3889, Accuracy: 26.3594, Test Loss: 1.5956, Test Accuracy: 20.9459\n",
      "Epoch 112, Loss: 2.3814, Accuracy: 26.3632, Test Loss: 1.5956, Test Accuracy: 20.9449\n",
      "Epoch 113, Loss: 2.3741, Accuracy: 26.3669, Test Loss: 1.5955, Test Accuracy: 20.9440\n",
      "Epoch 114, Loss: 2.3669, Accuracy: 26.3706, Test Loss: 1.5955, Test Accuracy: 20.9430\n",
      "Epoch 115, Loss: 2.3598, Accuracy: 26.3742, Test Loss: 1.5954, Test Accuracy: 20.9420\n",
      "Epoch 116, Loss: 2.3527, Accuracy: 26.3855, Test Loss: 1.5954, Test Accuracy: 20.9411\n",
      "Epoch 117, Loss: 2.3459, Accuracy: 26.3813, Test Loss: 1.5953, Test Accuracy: 20.9402\n",
      "Epoch 118, Loss: 2.3391, Accuracy: 26.3847, Test Loss: 1.5953, Test Accuracy: 20.9393\n",
      "Epoch 119, Loss: 2.3325, Accuracy: 26.3881, Test Loss: 1.5953, Test Accuracy: 20.9384\n",
      "Epoch 120, Loss: 2.3258, Accuracy: 26.4062, Test Loss: 1.5952, Test Accuracy: 20.9375\n",
      "Epoch 121, Loss: 2.3199, Accuracy: 26.4020, Test Loss: 1.5952, Test Accuracy: 20.9366\n",
      "Epoch 122, Loss: 2.3135, Accuracy: 26.4052, Test Loss: 1.5952, Test Accuracy: 20.9358\n",
      "Epoch 123, Loss: 2.3073, Accuracy: 26.4082, Test Loss: 1.5951, Test Accuracy: 20.9350\n",
      "Epoch 124, Loss: 2.3012, Accuracy: 26.4113, Test Loss: 1.5951, Test Accuracy: 20.9341\n",
      "Epoch 125, Loss: 2.2956, Accuracy: 26.4000, Test Loss: 1.5950, Test Accuracy: 20.9333\n",
      "Epoch 126, Loss: 2.2897, Accuracy: 26.4031, Test Loss: 1.5950, Test Accuracy: 20.9325\n",
      "Epoch 127, Loss: 2.2840, Accuracy: 26.3920, Test Loss: 1.5950, Test Accuracy: 20.9318\n",
      "Epoch 128, Loss: 2.2783, Accuracy: 26.3951, Test Loss: 1.5950, Test Accuracy: 20.9310\n",
      "Epoch 129, Loss: 2.2726, Accuracy: 26.3843, Test Loss: 1.5949, Test Accuracy: 20.9302\n",
      "Epoch 130, Loss: 2.2671, Accuracy: 26.3805, Test Loss: 1.5949, Test Accuracy: 20.9295\n",
      "Epoch 131, Loss: 2.2616, Accuracy: 26.3836, Test Loss: 1.5949, Test Accuracy: 20.9288\n",
      "Epoch 132, Loss: 2.2561, Accuracy: 26.3934, Test Loss: 1.5948, Test Accuracy: 20.9280\n",
      "Epoch 133, Loss: 2.2515, Accuracy: 26.3896, Test Loss: 1.5948, Test Accuracy: 20.9273\n",
      "Epoch 134, Loss: 2.2462, Accuracy: 26.3926, Test Loss: 1.5948, Test Accuracy: 20.9266\n",
      "Epoch 135, Loss: 2.2411, Accuracy: 26.3955, Test Loss: 1.5948, Test Accuracy: 20.9259\n",
      "Epoch 136, Loss: 2.2361, Accuracy: 26.3984, Test Loss: 1.5947, Test Accuracy: 20.9252\n",
      "Epoch 137, Loss: 2.2310, Accuracy: 26.4012, Test Loss: 1.5947, Test Accuracy: 20.9246\n",
      "Epoch 138, Loss: 2.2260, Accuracy: 26.4040, Test Loss: 1.5947, Test Accuracy: 20.9239\n",
      "Epoch 139, Loss: 2.2211, Accuracy: 26.4067, Test Loss: 1.5947, Test Accuracy: 20.9233\n",
      "Epoch 140, Loss: 2.2163, Accuracy: 26.4031, Test Loss: 1.5946, Test Accuracy: 20.9226\n",
      "Epoch 141, Loss: 2.2116, Accuracy: 26.4058, Test Loss: 1.5946, Test Accuracy: 20.9220\n",
      "Epoch 142, Loss: 2.2069, Accuracy: 26.4085, Test Loss: 1.5946, Test Accuracy: 20.9214\n",
      "Epoch 143, Loss: 2.2023, Accuracy: 26.4111, Test Loss: 1.5946, Test Accuracy: 20.9207\n",
      "Epoch 144, Loss: 2.1976, Accuracy: 26.4137, Test Loss: 1.5946, Test Accuracy: 20.9201\n",
      "Epoch 145, Loss: 2.1939, Accuracy: 26.4163, Test Loss: 1.5945, Test Accuracy: 20.9195\n",
      "Epoch 146, Loss: 2.1894, Accuracy: 26.4188, Test Loss: 1.5945, Test Accuracy: 20.9190\n",
      "Epoch 147, Loss: 2.1851, Accuracy: 26.4213, Test Loss: 1.5945, Test Accuracy: 20.9184\n",
      "Epoch 148, Loss: 2.1808, Accuracy: 26.4237, Test Loss: 1.5945, Test Accuracy: 20.9178\n",
      "Epoch 149, Loss: 2.1765, Accuracy: 26.4202, Test Loss: 1.5945, Test Accuracy: 20.9172\n",
      "Epoch 150, Loss: 2.1723, Accuracy: 26.4464, Test Loss: 1.5945, Test Accuracy: 20.9167\n",
      "Epoch 151, Loss: 2.1682, Accuracy: 26.4487, Test Loss: 1.5945, Test Accuracy: 20.9161\n",
      "Epoch 152, Loss: 2.1641, Accuracy: 26.4509, Test Loss: 1.5945, Test Accuracy: 20.9156\n",
      "Epoch 153, Loss: 2.1601, Accuracy: 26.4531, Test Loss: 1.5944, Test Accuracy: 20.9150\n",
      "Epoch 154, Loss: 2.1561, Accuracy: 26.4552, Test Loss: 1.5944, Test Accuracy: 20.9145\n",
      "Epoch 155, Loss: 2.1522, Accuracy: 26.4574, Test Loss: 1.5944, Test Accuracy: 20.9140\n",
      "Epoch 156, Loss: 2.1483, Accuracy: 26.4595, Test Loss: 1.5944, Test Accuracy: 20.9135\n",
      "Epoch 157, Loss: 2.1445, Accuracy: 26.4616, Test Loss: 1.5944, Test Accuracy: 20.9130\n",
      "Epoch 158, Loss: 2.1407, Accuracy: 26.4636, Test Loss: 1.5944, Test Accuracy: 20.9124\n",
      "Epoch 159, Loss: 2.1370, Accuracy: 26.4656, Test Loss: 1.5944, Test Accuracy: 20.9119\n",
      "Epoch 160, Loss: 2.1333, Accuracy: 26.4676, Test Loss: 1.5944, Test Accuracy: 20.9115\n",
      "Epoch 161, Loss: 2.1297, Accuracy: 26.4696, Test Loss: 1.5944, Test Accuracy: 20.9110\n",
      "Epoch 162, Loss: 2.1261, Accuracy: 26.4716, Test Loss: 1.5944, Test Accuracy: 20.9105\n",
      "Epoch 163, Loss: 2.1225, Accuracy: 26.4735, Test Loss: 1.5944, Test Accuracy: 20.9100\n",
      "Epoch 164, Loss: 2.1189, Accuracy: 26.4754, Test Loss: 1.5944, Test Accuracy: 20.9096\n",
      "Epoch 165, Loss: 2.1155, Accuracy: 26.4773, Test Loss: 1.5944, Test Accuracy: 20.9091\n",
      "Epoch 166, Loss: 2.1120, Accuracy: 26.4791, Test Loss: 1.5944, Test Accuracy: 20.9086\n",
      "Epoch 167, Loss: 2.1086, Accuracy: 26.4810, Test Loss: 1.5943, Test Accuracy: 20.9082\n",
      "Epoch 168, Loss: 2.1052, Accuracy: 26.4828, Test Loss: 1.5943, Test Accuracy: 20.9077\n",
      "Epoch 169, Loss: 2.1019, Accuracy: 26.4846, Test Loss: 1.5943, Test Accuracy: 20.9073\n",
      "Epoch 170, Loss: 2.0986, Accuracy: 26.4863, Test Loss: 1.5943, Test Accuracy: 20.9069\n",
      "Epoch 171, Loss: 2.0955, Accuracy: 26.4881, Test Loss: 1.5943, Test Accuracy: 20.9064\n",
      "Epoch 172, Loss: 2.0927, Accuracy: 26.4898, Test Loss: 1.5943, Test Accuracy: 20.9060\n",
      "Epoch 173, Loss: 2.0896, Accuracy: 26.4915, Test Loss: 1.5943, Test Accuracy: 20.9056\n",
      "Epoch 174, Loss: 2.0865, Accuracy: 26.4932, Test Loss: 1.5943, Test Accuracy: 20.9052\n",
      "Epoch 175, Loss: 2.0835, Accuracy: 26.4949, Test Loss: 1.5943, Test Accuracy: 20.9048\n",
      "Epoch 176, Loss: 2.0803, Accuracy: 26.4965, Test Loss: 1.5943, Test Accuracy: 20.9044\n",
      "Epoch 177, Loss: 2.0772, Accuracy: 26.4982, Test Loss: 1.5943, Test Accuracy: 20.9040\n",
      "Epoch 178, Loss: 2.0742, Accuracy: 26.4998, Test Loss: 1.5943, Test Accuracy: 20.9036\n",
      "Epoch 179, Loss: 2.0712, Accuracy: 26.5014, Test Loss: 1.5943, Test Accuracy: 20.9032\n",
      "Epoch 180, Loss: 2.0682, Accuracy: 26.5030, Test Loss: 1.5943, Test Accuracy: 20.9028\n",
      "Epoch 181, Loss: 2.0655, Accuracy: 26.5045, Test Loss: 1.5943, Test Accuracy: 20.9024\n",
      "Epoch 182, Loss: 2.0627, Accuracy: 26.5061, Test Loss: 1.5943, Test Accuracy: 20.9020\n",
      "Epoch 183, Loss: 2.0599, Accuracy: 26.5076, Test Loss: 1.5943, Test Accuracy: 20.9016\n",
      "Epoch 184, Loss: 2.0569, Accuracy: 26.5140, Test Loss: 1.5943, Test Accuracy: 20.9013\n",
      "Epoch 185, Loss: 2.0541, Accuracy: 26.5203, Test Loss: 1.5944, Test Accuracy: 20.9009\n",
      "Epoch 186, Loss: 2.0513, Accuracy: 26.5217, Test Loss: 1.5944, Test Accuracy: 20.9005\n",
      "Epoch 187, Loss: 2.0486, Accuracy: 26.5231, Test Loss: 1.5944, Test Accuracy: 20.9002\n",
      "Epoch 188, Loss: 2.0459, Accuracy: 26.5293, Test Loss: 1.5944, Test Accuracy: 20.8998\n",
      "Epoch 189, Loss: 2.0433, Accuracy: 26.5306, Test Loss: 1.5944, Test Accuracy: 20.8995\n",
      "Epoch 190, Loss: 2.0406, Accuracy: 26.5320, Test Loss: 1.5944, Test Accuracy: 20.8991\n",
      "Epoch 191, Loss: 2.0380, Accuracy: 26.5380, Test Loss: 1.5944, Test Accuracy: 20.8988\n",
      "Epoch 192, Loss: 2.0354, Accuracy: 26.5392, Test Loss: 1.5944, Test Accuracy: 20.8984\n",
      "Epoch 193, Loss: 2.0330, Accuracy: 26.5405, Test Loss: 1.5944, Test Accuracy: 20.8981\n",
      "Epoch 194, Loss: 2.0305, Accuracy: 26.5418, Test Loss: 1.5944, Test Accuracy: 20.8978\n",
      "Epoch 195, Loss: 2.0281, Accuracy: 26.5430, Test Loss: 1.5944, Test Accuracy: 20.8974\n",
      "Epoch 196, Loss: 2.0256, Accuracy: 26.5443, Test Loss: 1.5944, Test Accuracy: 20.8971\n",
      "Epoch 197, Loss: 2.0232, Accuracy: 26.5455, Test Loss: 1.5944, Test Accuracy: 20.8968\n",
      "Epoch 198, Loss: 2.0207, Accuracy: 26.5467, Test Loss: 1.5944, Test Accuracy: 20.8965\n",
      "Epoch 199, Loss: 2.0184, Accuracy: 26.5479, Test Loss: 1.5944, Test Accuracy: 20.8961\n",
      "Epoch 200, Loss: 2.0160, Accuracy: 26.5491, Test Loss: 1.5944, Test Accuracy: 20.8958\n"
     ]
    }
   ],
   "source": [
    "accuracy_dict = dict()\n",
    "num = 15\n",
    "for i in range(1,num+1):\n",
    "    @tf.function\n",
    "    def train_step(model, images, labels, loss_object, optimizer, train_loss, train_accuracy):\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = model(images, training=True)\n",
    "            loss = loss_object(labels, predictions)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        train_loss(loss)\n",
    "        train_accuracy(labels, predictions)\n",
    "    # print(\"Training loss (for one batch) at step %d: %.4f\" % (step, float(loss)))\n",
    "    @tf.function\n",
    "    def test_step(model, images, labels, loss_object, test_loss, test_accuracy):\n",
    "        predictions = model(images, training=False)\n",
    "\n",
    "        t_loss = loss_object(labels, predictions)\n",
    "        test_loss(t_loss)\n",
    "        test_accuracy(labels, predictions)\n",
    "    print('average of %d each' % (i))\n",
    "    X, Y =  readNpyMean(dir_path, i)\n",
    "    maximum = np.max(np.abs(X))\n",
    "    # maximum = 1\n",
    "    Split_X = dataSeperator(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Split_X, Y, test_size = 0.3)\n",
    "    ap_model = AP_ResNet()\n",
    "    loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "    train_loss = tf.keras.metrics.Mean(name = 'train_loss')\n",
    "    train_accuracy = tf.keras.metrics.CategoricalAccuracy(name = 'train_accuracy')\n",
    "\n",
    "    test_loss = tf.keras.metrics.Mean(name = 'test_loss')\n",
    "    test_accuracy = tf.keras.metrics.CategoricalAccuracy(name = 'test_accuracy')\n",
    "    EPOCHS = 200\n",
    "    batch_size = 32\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((X_test,y_test))\n",
    "    val_dataset = val_dataset.batch(batch_size)\n",
    "\n",
    "    train_accuracy_arr = list()\n",
    "    test_accuracy_arr = list()\n",
    "    for epoch in range(EPOCHS):\n",
    "        for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "            train_step(ap_model, x_batch_train, y_batch_train, loss_fn, optimizer, train_loss, train_accuracy)\n",
    "\n",
    "        for step ,(x_batch_test, y_batch_test) in enumerate(val_dataset):\n",
    "            test_step(ap_model, x_batch_test, y_batch_test, loss_fn, test_loss, test_accuracy)\n",
    "        train_accuracy_arr.append(train_accuracy.result())\n",
    "        test_accuracy_arr.append(test_accuracy.result())\n",
    "        template = \"Epoch {}, Loss: {:.4f}, Accuracy: {:.4f}, Test Loss: {:.4f}, Test Accuracy: {:.4f}\"\n",
    "        print(template.format(epoch+1,\n",
    "                                train_loss.result(),\n",
    "                                train_accuracy.result() * 100,\n",
    "                                test_loss.result(),\n",
    "                                test_accuracy.result() * 100))\n",
    "    accuracy_dict[i] = {\n",
    "        'train_acc' : np.max(train_accuracy),\n",
    "        'test_acc' : np.max(test_accuracy),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(np.min(np.abs(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average of 1 each\n",
      "0 :  (32, 414, 1)\n",
      "1 :  (32, 414, 8)\n",
      "2 :  (32, 414, 16)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/tmp/ipykernel_711025/142296036.py\", line 7, in train_step  *\n        loss = loss_object(labels, predictions)\n    File \"/data_disk/home/joongho/.conda/envs/radar/lib/python3.8/site-packages/keras/losses.py\", line 139, in __call__  **\n        losses = call_fn(y_true, y_pred)\n    File \"/data_disk/home/joongho/.conda/envs/radar/lib/python3.8/site-packages/keras/losses.py\", line 243, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/data_disk/home/joongho/.conda/envs/radar/lib/python3.8/site-packages/keras/losses.py\", line 1787, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/data_disk/home/joongho/.conda/envs/radar/lib/python3.8/site-packages/keras/backend.py\", line 5119, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (32, 5) and (32, 10) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/data_disk/home/joongho/Intelligent_Radar/gui/service_modules/training_road.ipynb 셀 20\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baisl_gpu_server/data_disk/home/joongho/Intelligent_Radar/gui/service_modules/training_road.ipynb#ch0000018vscode-remote?line=45'>46</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(EPOCHS):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baisl_gpu_server/data_disk/home/joongho/Intelligent_Radar/gui/service_modules/training_road.ipynb#ch0000018vscode-remote?line=46'>47</a>\u001b[0m     \u001b[39mfor\u001b[39;00m step, (x_batch_train, y_batch_train) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_dataset):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Baisl_gpu_server/data_disk/home/joongho/Intelligent_Radar/gui/service_modules/training_road.ipynb#ch0000018vscode-remote?line=47'>48</a>\u001b[0m         train_step(ap_model, x_batch_train, y_batch_train, loss_fn, optimizer, train_loss, train_accuracy)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baisl_gpu_server/data_disk/home/joongho/Intelligent_Radar/gui/service_modules/training_road.ipynb#ch0000018vscode-remote?line=49'>50</a>\u001b[0m     \u001b[39mfor\u001b[39;00m step ,(x_batch_test, y_batch_test) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(val_dataset):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baisl_gpu_server/data_disk/home/joongho/Intelligent_Radar/gui/service_modules/training_road.ipynb#ch0000018vscode-remote?line=50'>51</a>\u001b[0m         test_step(ap_model, x_batch_test, y_batch_test, loss_fn, test_loss, test_accuracy)\n",
      "File \u001b[0;32m~/.conda/envs/radar/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file4jjmwx47.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step\u001b[0;34m(model, images, labels, loss_object, optimizer, train_loss, train_accuracy)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mwith\u001b[39;00m ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[1;32m      9\u001b[0m     predictions \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(model), (ag__\u001b[39m.\u001b[39mld(images),), \u001b[39mdict\u001b[39m(training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m), fscope)\n\u001b[0;32m---> 10\u001b[0m     loss \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(loss_object), (ag__\u001b[39m.\u001b[39mld(labels), ag__\u001b[39m.\u001b[39mld(predictions)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     11\u001b[0m gradients \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tape)\u001b[39m.\u001b[39mgradient, (ag__\u001b[39m.\u001b[39mld(loss), ag__\u001b[39m.\u001b[39mld(model)\u001b[39m.\u001b[39mtrainable_variables), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     12\u001b[0m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(optimizer)\u001b[39m.\u001b[39mapply_gradients, (ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mzip\u001b[39m), (ag__\u001b[39m.\u001b[39mld(gradients), ag__\u001b[39m.\u001b[39mld(model)\u001b[39m.\u001b[39mtrainable_variables), \u001b[39mNone\u001b[39;00m, fscope),), \u001b[39mNone\u001b[39;00m, fscope)\n",
      "File \u001b[0;32m~/.conda/envs/radar/lib/python3.8/site-packages/keras/losses.py:139\u001b[0m, in \u001b[0;36mLoss.__call__\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m   call_fn \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mtf_convert(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall, tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mcontrol_status_ctx())\n\u001b[0;32m--> 139\u001b[0m losses \u001b[39m=\u001b[39m call_fn(y_true, y_pred)\n\u001b[1;32m    140\u001b[0m \u001b[39mreturn\u001b[39;00m losses_utils\u001b[39m.\u001b[39mcompute_weighted_loss(\n\u001b[1;32m    141\u001b[0m     losses, sample_weight, reduction\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_reduction())\n",
      "File \u001b[0;32m~/.conda/envs/radar/lib/python3.8/site-packages/keras/losses.py:243\u001b[0m, in \u001b[0;36mLossFunctionWrapper.call\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m    240\u001b[0m   y_pred, y_true \u001b[39m=\u001b[39m losses_utils\u001b[39m.\u001b[39msqueeze_or_expand_dimensions(y_pred, y_true)\n\u001b[1;32m    242\u001b[0m ag_fn \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mtf_convert(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn, tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mcontrol_status_ctx())\n\u001b[0;32m--> 243\u001b[0m \u001b[39mreturn\u001b[39;00m ag_fn(y_true, y_pred, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fn_kwargs)\n",
      "File \u001b[0;32m~/.conda/envs/radar/lib/python3.8/site-packages/keras/losses.py:1787\u001b[0m, in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(y_true, y_pred, from_logits, label_smoothing, axis)\u001b[0m\n\u001b[1;32m   1782\u001b[0m   \u001b[39mreturn\u001b[39;00m y_true \u001b[39m*\u001b[39m (\u001b[39m1.0\u001b[39m \u001b[39m-\u001b[39m label_smoothing) \u001b[39m+\u001b[39m (label_smoothing \u001b[39m/\u001b[39m num_classes)\n\u001b[1;32m   1784\u001b[0m y_true \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39msmart_cond\u001b[39m.\u001b[39msmart_cond(label_smoothing, _smooth_labels,\n\u001b[1;32m   1785\u001b[0m                                \u001b[39mlambda\u001b[39;00m: y_true)\n\u001b[0;32m-> 1787\u001b[0m \u001b[39mreturn\u001b[39;00m backend\u001b[39m.\u001b[39;49mcategorical_crossentropy(\n\u001b[1;32m   1788\u001b[0m     y_true, y_pred, from_logits\u001b[39m=\u001b[39;49mfrom_logits, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m~/.conda/envs/radar/lib/python3.8/site-packages/keras/backend.py:5119\u001b[0m, in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m   5117\u001b[0m target \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconvert_to_tensor(target)\n\u001b[1;32m   5118\u001b[0m output \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconvert_to_tensor(output)\n\u001b[0;32m-> 5119\u001b[0m target\u001b[39m.\u001b[39;49mshape\u001b[39m.\u001b[39;49massert_is_compatible_with(output\u001b[39m.\u001b[39;49mshape)\n\u001b[1;32m   5121\u001b[0m \u001b[39m# Use logits whenever they are available. `softmax` and `sigmoid`\u001b[39;00m\n\u001b[1;32m   5122\u001b[0m \u001b[39m# activations cache logits on the `output` Tensor.\u001b[39;00m\n\u001b[1;32m   5123\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(output, \u001b[39m'\u001b[39m\u001b[39m_keras_logits\u001b[39m\u001b[39m'\u001b[39m):\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_711025/142296036.py\", line 7, in train_step  *\n        loss = loss_object(labels, predictions)\n    File \"/data_disk/home/joongho/.conda/envs/radar/lib/python3.8/site-packages/keras/losses.py\", line 139, in __call__  **\n        losses = call_fn(y_true, y_pred)\n    File \"/data_disk/home/joongho/.conda/envs/radar/lib/python3.8/site-packages/keras/losses.py\", line 243, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/data_disk/home/joongho/.conda/envs/radar/lib/python3.8/site-packages/keras/losses.py\", line 1787, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/data_disk/home/joongho/.conda/envs/radar/lib/python3.8/site-packages/keras/backend.py\", line 5119, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (32, 5) and (32, 10) are incompatible\n"
     ]
    }
   ],
   "source": [
    "accuracy_dict = dict()\n",
    "for i in range(1,16):\n",
    "    @tf.function\n",
    "    def train_step(model, images, labels, loss_object, optimizer, train_loss, train_accuracy):\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = model(images, training=True)\n",
    "            loss = loss_object(labels, predictions)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        train_loss(loss)\n",
    "        train_accuracy(labels, predictions)\n",
    "    # print(\"Training loss (for one batch) at step %d: %.4f\" % (step, float(loss)))\n",
    "    @tf.function\n",
    "    def test_step(model, images, labels, loss_object, test_loss, test_accuracy):\n",
    "        predictions = model(images, training=False)\n",
    "\n",
    "        t_loss = loss_object(labels, predictions)\n",
    "        test_loss(t_loss)\n",
    "        test_accuracy(labels, predictions)\n",
    "    print('average of %d each' % (i))\n",
    "    X, Y =  readNpyMean(dir_path, i)\n",
    "    maximum = np.max(np.abs(X))\n",
    "    # maximum = 1\n",
    "    Split_X = dataSeperator(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Split_X, Y, test_size = 0.3)\n",
    "    ap_model = ResNet()\n",
    "    loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "    train_loss = tf.keras.metrics.Mean(name = 'train_loss')\n",
    "    train_accuracy = tf.keras.metrics.CategoricalAccuracy(name = 'train_accuracy')\n",
    "\n",
    "    test_loss = tf.keras.metrics.Mean(name = 'test_loss')\n",
    "    test_accuracy = tf.keras.metrics.CategoricalAccuracy(name = 'test_accuracy')\n",
    "    EPOCHS = 50\n",
    "    batch_size = 32\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((X_test,y_test))\n",
    "    val_dataset = val_dataset.batch(batch_size)\n",
    "\n",
    "    train_accuracy_arr = list()\n",
    "    test_accuracy_arr = list()\n",
    "    for epoch in range(EPOCHS):\n",
    "        for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "            train_step(ap_model, x_batch_train, y_batch_train, loss_fn, optimizer, train_loss, train_accuracy)\n",
    "\n",
    "        for step ,(x_batch_test, y_batch_test) in enumerate(val_dataset):\n",
    "            test_step(ap_model, x_batch_test, y_batch_test, loss_fn, test_loss, test_accuracy)\n",
    "        train_accuracy_arr.append(train_accuracy.result())\n",
    "        test_accuracy_arr.append(test_accuracy.result())\n",
    "        template = \"Epoch {}, Loss: {:.4f}, Accuracy: {:.4f}, Test Loss: {:.4f}, Test Accuracy: {:.4f}\"\n",
    "        print(template.format(epoch+1,\n",
    "                                train_loss.result(),\n",
    "                                train_accuracy.result() * 100,\n",
    "                                test_loss.result(),\n",
    "                                test_accuracy.result() * 100))\n",
    "    accuracy_dict[i] = {\n",
    "        'train_acc' : np.max(train_accuracy),\n",
    "        'test_acc' : np.max(test_accuracy),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-02 06:59:00.186680: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-02 06:59:00.678162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22304 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:d8:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 414, 1)\n",
      "414\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 2, 414)]     0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None, 414)         0           ['input_1[0][0]']                \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1 (Sl  (None, 414)         0           ['input_1[0][0]']                \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.expand_dims (TFOpLambda)    (None, 414, 1)       0           ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.expand_dims_1 (TFOpLambda)  (None, 414, 1)       0           ['tf.__operators__.getitem_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 414, 64)      256         ['tf.expand_dims[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 414, 64)      256         ['tf.expand_dims_1[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 414, 64)      12352       ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)              (None, 414, 64)      12352       ['conv1d_8[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 207, 64)      0           ['conv1d_1[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 207, 64)     0           ['conv1d_9[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 207, 128)     24704       ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)             (None, 207, 128)     24704       ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 207, 128)     49280       ['conv1d_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)             (None, 207, 128)     49280       ['conv1d_10[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 103, 128)    0           ['conv1d_3[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 103, 128)    0           ['conv1d_11[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 103, 256)     98560       ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)             (None, 103, 256)     98560       ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 103, 256)     196864      ['conv1d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)             (None, 103, 256)     196864      ['conv1d_12[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 103, 256)     196864      ['conv1d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_14 (Conv1D)             (None, 103, 256)     196864      ['conv1d_13[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 103, 256)     196864      ['conv1d_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)             (None, 103, 256)     196864      ['conv1d_14[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 51, 256)     0           ['conv1d_7[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 51, 256)     0           ['conv1d_15[0][0]']              \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 13056)        0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 13056)        0           ['max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 26112)        0           ['flatten[0][0]',                \n",
      "                                                                  'flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 4096)         106958848   ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 4096)         0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 4096)         16781312    ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 4096)         0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " material_output (Dense)        (None, 5)            20485       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 125,312,133\n",
      "Trainable params: 125,312,133\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "model = VGG_branch(Split_X.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-02 06:59:21.040976: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8301\n",
      "2022-08-02 06:59:22.469548: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - ETA: 0s - loss: 1.5777 - accuracy: 0.2381"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/ap_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/ap_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 29s 484ms/step - loss: 1.5777 - accuracy: 0.2381 - val_loss: 1.5660 - val_accuracy: 0.2389\n",
      "Epoch 2/100\n",
      "51/53 [===========================>..] - ETA: 0s - loss: 1.5288 - accuracy: 0.3045"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/ap_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/ap_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 13s 255ms/step - loss: 1.5304 - accuracy: 0.3030 - val_loss: 1.5590 - val_accuracy: 0.2611\n",
      "Epoch 3/100\n",
      "53/53 [==============================] - 17s 324ms/step - loss: 1.5431 - accuracy: 0.3042 - val_loss: 1.5657 - val_accuracy: 0.2375\n",
      "Epoch 4/100\n",
      "53/53 [==============================] - 25s 471ms/step - loss: 1.5780 - accuracy: 0.2440 - val_loss: 1.5649 - val_accuracy: 0.2444\n",
      "Epoch 5/100\n",
      "53/53 [==============================] - 7s 135ms/step - loss: 1.5718 - accuracy: 0.2464 - val_loss: 1.5678 - val_accuracy: 0.2444\n",
      "Epoch 6/100\n",
      "53/53 [==============================] - 23s 449ms/step - loss: 1.5734 - accuracy: 0.2589 - val_loss: 1.5649 - val_accuracy: 0.2611\n",
      "Epoch 7/100\n",
      "53/53 [==============================] - 7s 131ms/step - loss: 1.5709 - accuracy: 0.2458 - val_loss: 1.5656 - val_accuracy: 0.2375\n",
      "Epoch 8/100\n",
      "53/53 [==============================] - 7s 129ms/step - loss: 1.5667 - accuracy: 0.2643 - val_loss: 1.5671 - val_accuracy: 0.2375\n",
      "Epoch 9/100\n",
      "53/53 [==============================] - 7s 125ms/step - loss: 1.5689 - accuracy: 0.2548 - val_loss: 1.5652 - val_accuracy: 0.2375\n",
      "Epoch 10/100\n",
      "53/53 [==============================] - 6s 123ms/step - loss: 1.5760 - accuracy: 0.2375 - val_loss: 1.5665 - val_accuracy: 0.2375\n",
      "Epoch 11/100\n",
      "53/53 [==============================] - 7s 128ms/step - loss: 1.5627 - accuracy: 0.2583 - val_loss: 1.5671 - val_accuracy: 0.2375\n",
      "Epoch 12/100\n",
      "53/53 [==============================] - 6s 123ms/step - loss: 1.5652 - accuracy: 0.2405 - val_loss: 1.5671 - val_accuracy: 0.2375\n",
      "Epoch 13/100\n",
      "53/53 [==============================] - 7s 125ms/step - loss: 1.5696 - accuracy: 0.2423 - val_loss: 1.5656 - val_accuracy: 0.2375\n",
      "Epoch 14/100\n",
      "53/53 [==============================] - 7s 125ms/step - loss: 1.5650 - accuracy: 0.2560 - val_loss: 1.5644 - val_accuracy: 0.2611\n",
      "Epoch 15/100\n",
      "53/53 [==============================] - 7s 138ms/step - loss: 1.5647 - accuracy: 0.2518 - val_loss: 1.5665 - val_accuracy: 0.2375\n",
      "Epoch 16/100\n",
      "53/53 [==============================] - 7s 133ms/step - loss: 1.5627 - accuracy: 0.2524 - val_loss: 1.5657 - val_accuracy: 0.2444\n",
      "Epoch 17/100\n",
      "53/53 [==============================] - 7s 131ms/step - loss: 1.5605 - accuracy: 0.2548 - val_loss: 1.5654 - val_accuracy: 0.2375\n",
      "Epoch 18/100\n",
      "53/53 [==============================] - 7s 129ms/step - loss: 1.5689 - accuracy: 0.2423 - val_loss: 1.5645 - val_accuracy: 0.2611\n",
      "Epoch 19/100\n",
      "53/53 [==============================] - 7s 127ms/step - loss: 1.5614 - accuracy: 0.2524 - val_loss: 1.5657 - val_accuracy: 0.2375\n",
      "Epoch 20/100\n",
      "53/53 [==============================] - 12s 237ms/step - loss: 1.5653 - accuracy: 0.2488 - val_loss: 1.5661 - val_accuracy: 0.2375\n",
      "Epoch 21/100\n",
      "53/53 [==============================] - 7s 138ms/step - loss: 1.5645 - accuracy: 0.2554 - val_loss: 1.5661 - val_accuracy: 0.2375\n",
      "Epoch 22/100\n",
      "53/53 [==============================] - 12s 221ms/step - loss: 1.5664 - accuracy: 0.2554 - val_loss: 1.5653 - val_accuracy: 0.2375\n",
      "Epoch 23/100\n",
      "53/53 [==============================] - 9s 178ms/step - loss: 1.5684 - accuracy: 0.2214 - val_loss: 1.5661 - val_accuracy: 0.2444\n",
      "Epoch 24/100\n",
      "53/53 [==============================] - 11s 213ms/step - loss: 1.5647 - accuracy: 0.2530 - val_loss: 1.5668 - val_accuracy: 0.2444\n",
      "Epoch 25/100\n",
      "53/53 [==============================] - 10s 197ms/step - loss: 1.5638 - accuracy: 0.2399 - val_loss: 1.5664 - val_accuracy: 0.2375\n",
      "Epoch 26/100\n",
      "53/53 [==============================] - 11s 212ms/step - loss: 1.5636 - accuracy: 0.2530 - val_loss: 1.5660 - val_accuracy: 0.2375\n",
      "Epoch 27/100\n",
      "53/53 [==============================] - 14s 260ms/step - loss: 1.5570 - accuracy: 0.2792 - val_loss: 1.5661 - val_accuracy: 0.2375\n",
      "Epoch 28/100\n",
      "53/53 [==============================] - 8s 159ms/step - loss: 1.5653 - accuracy: 0.2506 - val_loss: 1.5659 - val_accuracy: 0.2444\n",
      "Epoch 29/100\n",
      "53/53 [==============================] - 12s 236ms/step - loss: 1.5634 - accuracy: 0.2369 - val_loss: 1.5654 - val_accuracy: 0.2375\n",
      "Epoch 30/100\n",
      "53/53 [==============================] - 12s 221ms/step - loss: 1.5597 - accuracy: 0.2601 - val_loss: 1.5661 - val_accuracy: 0.2375\n",
      "Epoch 31/100\n",
      "53/53 [==============================] - 9s 178ms/step - loss: 1.5650 - accuracy: 0.2649 - val_loss: 1.5654 - val_accuracy: 0.2444\n",
      "Epoch 32/100\n",
      "53/53 [==============================] - 13s 257ms/step - loss: 1.5638 - accuracy: 0.2512 - val_loss: 1.5655 - val_accuracy: 0.2375\n",
      "Epoch 33/100\n",
      "53/53 [==============================] - 9s 169ms/step - loss: 1.5627 - accuracy: 0.2423 - val_loss: 1.5653 - val_accuracy: 0.2444\n",
      "Epoch 34/100\n",
      "53/53 [==============================] - 12s 223ms/step - loss: 1.5624 - accuracy: 0.2500 - val_loss: 1.5656 - val_accuracy: 0.2375\n",
      "Epoch 35/100\n",
      "53/53 [==============================] - 13s 241ms/step - loss: 1.5646 - accuracy: 0.2685 - val_loss: 1.5657 - val_accuracy: 0.2375\n",
      "Epoch 36/100\n",
      "53/53 [==============================] - 10s 184ms/step - loss: 1.5655 - accuracy: 0.2280 - val_loss: 1.5661 - val_accuracy: 0.2375\n",
      "Epoch 37/100\n",
      "53/53 [==============================] - 13s 254ms/step - loss: 1.5632 - accuracy: 0.2470 - val_loss: 1.5656 - val_accuracy: 0.2375\n",
      "Epoch 38/100\n",
      "53/53 [==============================] - 14s 269ms/step - loss: 1.5620 - accuracy: 0.2536 - val_loss: 1.5660 - val_accuracy: 0.2444\n",
      "Epoch 39/100\n",
      "53/53 [==============================] - 10s 186ms/step - loss: 1.5612 - accuracy: 0.2530 - val_loss: 1.5655 - val_accuracy: 0.2375\n",
      "Epoch 40/100\n",
      "53/53 [==============================] - 11s 217ms/step - loss: 1.5644 - accuracy: 0.2518 - val_loss: 1.5660 - val_accuracy: 0.2444\n",
      "Epoch 41/100\n",
      "53/53 [==============================] - 11s 219ms/step - loss: 1.5620 - accuracy: 0.2440 - val_loss: 1.5654 - val_accuracy: 0.2444\n",
      "Epoch 42/100\n",
      "53/53 [==============================] - 10s 199ms/step - loss: 1.5622 - accuracy: 0.2577 - val_loss: 1.5657 - val_accuracy: 0.2375\n",
      "Epoch 43/100\n",
      "53/53 [==============================] - 12s 225ms/step - loss: 1.5640 - accuracy: 0.2417 - val_loss: 1.5657 - val_accuracy: 0.2375\n",
      "Epoch 44/100\n",
      "53/53 [==============================] - 12s 229ms/step - loss: 1.5596 - accuracy: 0.2560 - val_loss: 1.5654 - val_accuracy: 0.2375\n",
      "Epoch 45/100\n",
      "53/53 [==============================] - 10s 184ms/step - loss: 1.5650 - accuracy: 0.2512 - val_loss: 1.5650 - val_accuracy: 0.2375\n",
      "Epoch 46/100\n",
      "53/53 [==============================] - 10s 200ms/step - loss: 1.5657 - accuracy: 0.2560 - val_loss: 1.5650 - val_accuracy: 0.2444\n",
      "Epoch 47/100\n",
      "53/53 [==============================] - 12s 238ms/step - loss: 1.5606 - accuracy: 0.2548 - val_loss: 1.5657 - val_accuracy: 0.2375\n",
      "Epoch 48/100\n",
      "53/53 [==============================] - 9s 178ms/step - loss: 1.5619 - accuracy: 0.2310 - val_loss: 1.5657 - val_accuracy: 0.2444\n",
      "Epoch 49/100\n",
      "53/53 [==============================] - 11s 209ms/step - loss: 1.5584 - accuracy: 0.2571 - val_loss: 1.5661 - val_accuracy: 0.2375\n",
      "Epoch 50/100\n",
      "53/53 [==============================] - 13s 250ms/step - loss: 1.5649 - accuracy: 0.2530 - val_loss: 1.5653 - val_accuracy: 0.2375\n",
      "Epoch 51/100\n",
      "53/53 [==============================] - 11s 216ms/step - loss: 1.5543 - accuracy: 0.2548 - val_loss: 1.5664 - val_accuracy: 0.2444\n",
      "Epoch 52/100\n",
      "53/53 [==============================] - 9s 171ms/step - loss: 1.5594 - accuracy: 0.2524 - val_loss: 1.5654 - val_accuracy: 0.2444\n",
      "Epoch 53/100\n",
      "53/53 [==============================] - 13s 249ms/step - loss: 1.5619 - accuracy: 0.2435 - val_loss: 1.5660 - val_accuracy: 0.2375\n",
      "Epoch 54/100\n",
      "53/53 [==============================] - 13s 257ms/step - loss: 1.5627 - accuracy: 0.2446 - val_loss: 1.5660 - val_accuracy: 0.2375\n",
      "Epoch 55/100\n",
      "53/53 [==============================] - 8s 152ms/step - loss: 1.5640 - accuracy: 0.2512 - val_loss: 1.5654 - val_accuracy: 0.2375\n",
      "Epoch 56/100\n",
      "53/53 [==============================] - 12s 222ms/step - loss: 1.5613 - accuracy: 0.2530 - val_loss: 1.5656 - val_accuracy: 0.2375\n",
      "Epoch 57/100\n",
      "53/53 [==============================] - 11s 208ms/step - loss: 1.5612 - accuracy: 0.2542 - val_loss: 1.5659 - val_accuracy: 0.2375\n",
      "Epoch 58/100\n",
      "53/53 [==============================] - 10s 189ms/step - loss: 1.5648 - accuracy: 0.2494 - val_loss: 1.5657 - val_accuracy: 0.2375\n",
      "Epoch 59/100\n",
      "53/53 [==============================] - 12s 222ms/step - loss: 1.5628 - accuracy: 0.2637 - val_loss: 1.5660 - val_accuracy: 0.2375\n",
      "Epoch 60/100\n",
      "53/53 [==============================] - 13s 241ms/step - loss: 1.5610 - accuracy: 0.2577 - val_loss: 1.5656 - val_accuracy: 0.2375\n",
      "Epoch 61/100\n",
      "53/53 [==============================] - 7s 142ms/step - loss: 1.5610 - accuracy: 0.2399 - val_loss: 1.5656 - val_accuracy: 0.2444\n",
      "Epoch 62/100\n",
      "53/53 [==============================] - 13s 245ms/step - loss: 1.5587 - accuracy: 0.2613 - val_loss: 1.5655 - val_accuracy: 0.2375\n",
      "Epoch 63/100\n",
      "53/53 [==============================] - 11s 211ms/step - loss: 1.5618 - accuracy: 0.2613 - val_loss: 1.5660 - val_accuracy: 0.2375\n",
      "Epoch 64/100\n",
      "53/53 [==============================] - 10s 194ms/step - loss: 1.5621 - accuracy: 0.2494 - val_loss: 1.5659 - val_accuracy: 0.2444\n",
      "Epoch 65/100\n",
      "53/53 [==============================] - 12s 235ms/step - loss: 1.5607 - accuracy: 0.2595 - val_loss: 1.5659 - val_accuracy: 0.2444\n",
      "Epoch 66/100\n",
      "53/53 [==============================] - 13s 258ms/step - loss: 1.5608 - accuracy: 0.2661 - val_loss: 1.5656 - val_accuracy: 0.2375\n",
      "Epoch 67/100\n",
      "53/53 [==============================] - 10s 196ms/step - loss: 1.5574 - accuracy: 0.2685 - val_loss: 1.5658 - val_accuracy: 0.2375\n",
      "Epoch 68/100\n",
      "53/53 [==============================] - 10s 193ms/step - loss: 1.5624 - accuracy: 0.2458 - val_loss: 1.5659 - val_accuracy: 0.2375\n",
      "Epoch 69/100\n",
      "53/53 [==============================] - 12s 222ms/step - loss: 1.5615 - accuracy: 0.2536 - val_loss: 1.5654 - val_accuracy: 0.2375\n",
      "Epoch 70/100\n",
      "53/53 [==============================] - 12s 223ms/step - loss: 1.5595 - accuracy: 0.2518 - val_loss: 1.5655 - val_accuracy: 0.2375\n",
      "Epoch 71/100\n",
      "53/53 [==============================] - 8s 161ms/step - loss: 1.5614 - accuracy: 0.2524 - val_loss: 1.5656 - val_accuracy: 0.2375\n",
      "Epoch 72/100\n",
      "53/53 [==============================] - 11s 212ms/step - loss: 1.5597 - accuracy: 0.2500 - val_loss: 1.5661 - val_accuracy: 0.2375\n",
      "Epoch 73/100\n",
      "53/53 [==============================] - 9s 165ms/step - loss: 1.5626 - accuracy: 0.2423 - val_loss: 1.5656 - val_accuracy: 0.2375\n",
      "Epoch 74/100\n",
      "53/53 [==============================] - 11s 214ms/step - loss: 1.5627 - accuracy: 0.2363 - val_loss: 1.5654 - val_accuracy: 0.2444\n",
      "Epoch 75/100\n",
      "53/53 [==============================] - 14s 265ms/step - loss: 1.5642 - accuracy: 0.2536 - val_loss: 1.5655 - val_accuracy: 0.2375\n",
      "Epoch 76/100\n",
      "53/53 [==============================] - 8s 148ms/step - loss: 1.5596 - accuracy: 0.2589 - val_loss: 1.5653 - val_accuracy: 0.2444\n",
      "Epoch 77/100\n",
      "53/53 [==============================] - 10s 193ms/step - loss: 1.5604 - accuracy: 0.2577 - val_loss: 1.5654 - val_accuracy: 0.2375\n",
      "Epoch 78/100\n",
      "53/53 [==============================] - 11s 204ms/step - loss: 1.5570 - accuracy: 0.2494 - val_loss: 1.5656 - val_accuracy: 0.2375\n",
      "Epoch 79/100\n",
      "53/53 [==============================] - 8s 157ms/step - loss: 1.5583 - accuracy: 0.2494 - val_loss: 1.5659 - val_accuracy: 0.2444\n",
      "Epoch 80/100\n",
      "53/53 [==============================] - 11s 214ms/step - loss: 1.5634 - accuracy: 0.2476 - val_loss: 1.5658 - val_accuracy: 0.2375\n",
      "Epoch 81/100\n",
      "53/53 [==============================] - 10s 189ms/step - loss: 1.5591 - accuracy: 0.2542 - val_loss: 1.5656 - val_accuracy: 0.2375\n",
      "Epoch 82/100\n",
      "53/53 [==============================] - 9s 182ms/step - loss: 1.5597 - accuracy: 0.2565 - val_loss: 1.5654 - val_accuracy: 0.2375\n",
      "Epoch 83/100\n",
      "53/53 [==============================] - 11s 209ms/step - loss: 1.5611 - accuracy: 0.2363 - val_loss: 1.5657 - val_accuracy: 0.2375\n",
      "Epoch 84/100\n",
      "53/53 [==============================] - 10s 188ms/step - loss: 1.5614 - accuracy: 0.2542 - val_loss: 1.5656 - val_accuracy: 0.2375\n",
      "Epoch 85/100\n",
      "53/53 [==============================] - 11s 205ms/step - loss: 1.5598 - accuracy: 0.2506 - val_loss: 1.5660 - val_accuracy: 0.2375\n",
      "Epoch 86/100\n",
      "53/53 [==============================] - 12s 236ms/step - loss: 1.5601 - accuracy: 0.2530 - val_loss: 1.5656 - val_accuracy: 0.2375\n",
      "Epoch 87/100\n",
      "53/53 [==============================] - 10s 188ms/step - loss: 1.5619 - accuracy: 0.2571 - val_loss: 1.5653 - val_accuracy: 0.2375\n",
      "Epoch 88/100\n",
      "53/53 [==============================] - 11s 203ms/step - loss: 1.5602 - accuracy: 0.2583 - val_loss: 1.5652 - val_accuracy: 0.2444\n",
      "Epoch 89/100\n",
      "53/53 [==============================] - 13s 258ms/step - loss: 1.5612 - accuracy: 0.2506 - val_loss: 1.5656 - val_accuracy: 0.2444\n",
      "Epoch 90/100\n",
      "53/53 [==============================] - 9s 182ms/step - loss: 1.5602 - accuracy: 0.2571 - val_loss: 1.5657 - val_accuracy: 0.2375\n",
      "Epoch 91/100\n",
      "53/53 [==============================] - 10s 193ms/step - loss: 1.5601 - accuracy: 0.2548 - val_loss: 1.5655 - val_accuracy: 0.2375\n",
      "Epoch 92/100\n",
      "53/53 [==============================] - 14s 269ms/step - loss: 1.5606 - accuracy: 0.2446 - val_loss: 1.5656 - val_accuracy: 0.2375\n",
      "Epoch 93/100\n",
      "53/53 [==============================] - 13s 242ms/step - loss: 1.5617 - accuracy: 0.2464 - val_loss: 1.5655 - val_accuracy: 0.2375\n",
      "Epoch 94/100\n",
      "53/53 [==============================] - 7s 139ms/step - loss: 1.5613 - accuracy: 0.2464 - val_loss: 1.5651 - val_accuracy: 0.2375\n",
      "Epoch 95/100\n",
      "53/53 [==============================] - 11s 211ms/step - loss: 1.5585 - accuracy: 0.2476 - val_loss: 1.5652 - val_accuracy: 0.2375\n",
      "Epoch 96/100\n",
      "53/53 [==============================] - 9s 172ms/step - loss: 1.5601 - accuracy: 0.2327 - val_loss: 1.5652 - val_accuracy: 0.2375\n",
      "Epoch 97/100\n",
      "53/53 [==============================] - 10s 195ms/step - loss: 1.5588 - accuracy: 0.2506 - val_loss: 1.5655 - val_accuracy: 0.2375\n",
      "Epoch 98/100\n",
      "53/53 [==============================] - 13s 245ms/step - loss: 1.5605 - accuracy: 0.2488 - val_loss: 1.5652 - val_accuracy: 0.2375\n",
      "Epoch 99/100\n",
      "53/53 [==============================] - 8s 148ms/step - loss: 1.5583 - accuracy: 0.2435 - val_loss: 1.5654 - val_accuracy: 0.2375\n",
      "Epoch 100/100\n",
      "53/53 [==============================] - 12s 232ms/step - loss: 1.5593 - accuracy: 0.2458 - val_loss: 1.5656 - val_accuracy: 0.2375\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(\n",
    "    Split_X,\n",
    "    Y,\n",
    "    batch_size = 32,\n",
    "    epochs=100,\n",
    "    validation_split = 0.3,\n",
    "    shuffle = True,\n",
    "    callbacks = [callback, tensorboard_callback]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('radar')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dea347e98226a0e23d2c967d9a0ab2a62ac04f9a7895aa5011026f33e6be1d75"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
