{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import copy\n",
    "from math import pi\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 414) (600, 4)\n",
      "(200, 414) (200, 4)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Can = list()\n",
    "Paper = list()\n",
    "Glass = list()\n",
    "Plastic = list()\n",
    "Can = np.array(Can)\n",
    "Paper = np.array(Paper)\n",
    "Glass = np.array(Glass)\n",
    "Plastic = np.array(Plastic)\n",
    "\n",
    "Can_test = copy.deepcopy(Can)\n",
    "Paper_test = copy.deepcopy(Paper)\n",
    "Plastic_test = copy.deepcopy(Plastic)\n",
    "Glass_test = copy.deepcopy(Glass)\n",
    "\n",
    "\n",
    "Class = 4\n",
    "\n",
    "lableDict = {\n",
    "                'can' : 0,\n",
    "                'paper' : 1,\n",
    "                'glass' : 2,\n",
    "                'plastic' : 3,\n",
    "            }\n",
    "\n",
    "test = np.zeros(4)\n",
    "\n",
    "def Label2Idx(label):\n",
    "    idx = np.zeros(4)\n",
    "    idx[label] = 1\n",
    "    return idx\n",
    "\n",
    "dir_path = './data/train'\n",
    "test_dir_path = './data/test'\n",
    "\n",
    "def readNpy(dir_path, Can, Paper, Glass, Plastic):\n",
    "    for dir in os.listdir(dir_path):\n",
    "        d_path = os.path.join(dir_path, dir)\n",
    "        file_list = os.listdir(d_path)\n",
    "        for file in file_list:\n",
    "            file_path = os.path.join(d_path, file)\n",
    "            if dir == 'test_c':\n",
    "                if len(Can) == 0:\n",
    "                    Can = np.load(file_path)\n",
    "                else :\n",
    "                    Can = np.append(Can, np.load(file_path), axis = 0)\n",
    "            elif dir == 'test_a':\n",
    "                if len(Paper) == 0:\n",
    "                    Paper = np.load(file_path)\n",
    "                else :\n",
    "                    Paper = np.append(Paper, np.load(file_path), axis = 0)\n",
    "            # elif dir == 'glass':\n",
    "            #     if len(Glass) == 0:\n",
    "            #         Glass = np.load(file_path)\n",
    "            #     else:\n",
    "            #         Glass = np.append(Glass, np.load(file_path), axis = 0)\n",
    "            # elif dir == 'plastic':\n",
    "            #     if len(Plastic) == 0:\n",
    "            #         Plastic = np.load(file_path)\n",
    "            #     else:\n",
    "            #         Plastic = np.append(Plastic, np.load(file_path), axis = 0)\n",
    "    \n",
    "    # Can = np.append(Can, Can_label, axis=1)\n",
    "    # Paper = np.append(Paper, Paper_label, axis=1)\n",
    "    # Glass = np.append(Glass, Glass_label, axis=1)\n",
    "    # Plastic = np.append(Plastic, Plastic_label, axis=1\n",
    "    # print(Can)\n",
    "    # Can = np.expand_dims(Can, axis=0)\n",
    "    # Paper = np.expand_dims(Paper, axis=0)\n",
    "    # Glass = np.expand_dims(Glass, axis=0)\n",
    "    # Plastic = np.expand_dims(Plastic, axis=0)\n",
    "    # print(Can.shape)\n",
    "\n",
    "    Can_label = np.tile(np.array([1, 0, 0, 0]), reps=[Can.shape[0], 1])\n",
    "    Paper_label = np.tile(np.array([0, 1, 0, 0]), reps=[Paper.shape[0], 1])\n",
    "    # Glass_label = np.tile(np.array([0, 0, 1, 0]), reps=[Glass.shape[0], 1])\n",
    "    # Plastic_label = np.tile(np.array([0, 0, 0, 1]), reps=[Plastic.shape[0], 1])\n",
    "    # print(Can_label)\n",
    "    \n",
    "\n",
    "    label_arr = np.append(Can_label, Paper_label, axis = 0)\n",
    "    # label_arr = np.append(label_arr, Glass_label, axis = 0)\n",
    "    # label_arr = np.append(label_arr, Plastic_label, axis = 0)\n",
    "\n",
    "    # print(label_arr)\n",
    "\n",
    "    array = list()\n",
    "    array = np.array(array)\n",
    "    array = Can\n",
    "    # array = np.append(Can,[Plastic, Glass, Plastic], axis = 0)\n",
    "    # array = np.append(array, Can)\n",
    "    array = np.append(array, Paper, axis = 0)\n",
    "    # array = np.append(array, Glass, axis = 0)\n",
    "    # array = np.append(array, Plastic, axis = 0)\n",
    "    return array, label_arr\n",
    "\n",
    "Data, Label= readNpy(dir_path, Can, Paper, Glass, Plastic)\n",
    "print(Data.shape, Label.shape)\n",
    "# print(Data)\n",
    "# Data_len = Data.shape[1]\n",
    "# Can_label = np.expand_dims(np.full((Data_len, Class), Label2Idx(lableDict['can']), dtype='int'),axis=0)\n",
    "# Paper_label = np.expand_dims(np.full((Data_len, Class), Label2Idx(lableDict['paper']), dtype='int'), axis=0)\n",
    "# Glass_label = np.expand_dims(np.full((Data_len, Class), Label2Idx(lableDict['glass']), dtype='int'), axis=0)\n",
    "# Plastic_label = np.expand_dims(np.full((Data_len, Class), Label2Idx(lableDict['plastic']), dtype='int'), axis=0)\n",
    "\n",
    "test_Data, test_Label= readNpy(test_dir_path, Can_test, Paper_test, Glass_test, Plastic_test)\n",
    "print(test_Data.shape, test_Label.shape)\n",
    "# test_Data_len = test_Data.shape[1]\n",
    "# test_Can_label = np.expand_dims(np.full((test_Data_len, Class), Label2Idx(lableDict['can']), dtype='int'),axis=0)\n",
    "# test_Paper_label = np.expand_dims(np.full((test_Data_len, Class), Label2Idx(lableDict['paper']), dtype='int'), axis=0)\n",
    "# test_Glass_label = np.expand_dims(np.full((test_Data_len, Class), Label2Idx(lableDict['glass']), dtype='int'), axis=0)\n",
    "# test_Plastic_label = np.expand_dims(np.full((test_Data_len, Class), Label2Idx(lableDict['plastic']), dtype='int'), axis=0)\n",
    "\n",
    "# Label = np.append(Can_label, Paper_label, axis=0)\n",
    "# Label = np.append(Label, Glass_label, axis=0)\n",
    "# Label = np.append(Label, Plastic_label, axis=0)\n",
    "\n",
    "# test_Label = np.append(test_Can_label, test_Paper_label, axis=0)\n",
    "# test_Label = np.append(test_Label, test_Glass_label, axis=0)\n",
    "# test_Label = np.append(test_Label, test_Plastic_label, axis=0)\n",
    "\n",
    "X = Data\n",
    "# Y = np.reshape(Label, (-1, Label.shape[2]))\n",
    "Y = Label\n",
    "\n",
    "test_X = test_Data\n",
    "test_Y = test_Label\n",
    "\n",
    "# print(X.shape)\n",
    "# print(Y.shape)\n",
    "s = np.arange(X.shape[0])\n",
    "np.random.shuffle(s)\n",
    "X_s = X[s]\n",
    "Y_s = Y[s]\n",
    "\n",
    "test_s = np.arange(test_X.shape[0])\n",
    "np.random.shuffle(test_s)\n",
    "test_X_s = test_X[test_s]\n",
    "test_Y_s = test_Y[test_s]\n",
    "# test_X_s = X_s\n",
    "# test_Y_s = Y_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(X, Y, test_X, test_Y, EPOCHS, cp_filepath):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv1D(6, (3), activation = 'relu', input_shape=(X.shape[1], 1)))\n",
    "    # model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Conv1D(16, (3), activation = 'relu'))\n",
    "    # model.add(layers.Dropout(0.2))\n",
    "    # model.add(layers.Conv1D(64, (3), activation = 'relu'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(4, activation='softmax'))\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])\n",
    "    checkpoint_filepath = cp_filepath\n",
    "\n",
    "    callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath = checkpoint_filepath,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        save_best_only = True,\n",
    "        save_weigths_only = False,\n",
    "\n",
    "    )\n",
    "\n",
    "    return model.fit(X, Y, epochs=EPOCHS, validation_data = (test_X, test_Y), callbacks=[callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperater(queue):\n",
    "    data = list()\n",
    "    data = np.arrya(data)\n",
    "    while True:\n",
    "        pre_data = queue.pop\n",
    "        amp = np.abs(pre_data)\n",
    "        amp = amp / 3417.2854724181298\n",
    "        phs = np.angle(pre_data)\n",
    "        phs = (phs - (- pi)) / (pi - (- pi))\n",
    "        seperated_data = np.append(amp, phs, axis = 0)\n",
    "        return np.array(seperated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting(history):\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(['Train', 'Test'], loc='upperleft')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_2 (Conv1D)           (None, 412, 6)            24        \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 410, 16)           304       \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 6560)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 26244     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,572\n",
      "Trainable params: 26,572\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      " 5/19 [======>.......................] - ETA: 0s - loss: 63.4885 - accuracy: 0.5125"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 21:02:30.637349: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/19 [=========================>....] - ETA: 0s - loss: 22.2168 - accuracy: 0.7923"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 21:02:30.987447: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./non_normalization/assets\n",
      "19/19 [==============================] - 1s 41ms/step - loss: 20.1501 - accuracy: 0.8100 - val_loss: 60.5358 - val_accuracy: 0.5000\n",
      "Epoch 2/30\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.0274 - accuracy: 0.9961INFO:tensorflow:Assets written to: ./non_normalization/assets\n",
      "19/19 [==============================] - 0s 26ms/step - loss: 0.0234 - accuracy: 0.9967 - val_loss: 18.4482 - val_accuracy: 0.5450\n",
      "Epoch 3/30\n",
      "16/19 [========================>.....] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000INFO:tensorflow:Assets written to: ./non_normalization/assets\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 12.1809 - val_accuracy: 0.6300\n",
      "Epoch 4/30\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000INFO:tensorflow:Assets written to: ./non_normalization/assets\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 11.3376 - val_accuracy: 0.6600\n",
      "Epoch 5/30\n",
      "17/19 [=========================>....] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000INFO:tensorflow:Assets written to: ./non_normalization/assets\n",
      "19/19 [==============================] - 0s 26ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 11.2132 - val_accuracy: 0.6650\n",
      "Epoch 6/30\n",
      "19/19 [==============================] - 0s 15ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 11.1946 - val_accuracy: 0.6650\n",
      "Epoch 7/30\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 11.1919 - val_accuracy: 0.6650\n",
      "Epoch 8/30\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 11.1915 - val_accuracy: 0.6650\n",
      "Epoch 9/30\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 11.1915 - val_accuracy: 0.6650\n",
      "Epoch 10/30\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 11.1915 - val_accuracy: 0.6650\n",
      "Epoch 11/30\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 11.1915 - val_accuracy: 0.6650\n",
      "Epoch 12/30\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 11.1915 - val_accuracy: 0.6650\n",
      "Epoch 13/30\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 11.1915 - val_accuracy: 0.6650\n",
      "Epoch 14/30\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 11.1915 - val_accuracy: 0.6650\n",
      "Epoch 15/30\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 11.1915 - val_accuracy: 0.6650\n",
      "Epoch 16/30\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 11.1915 - val_accuracy: 0.6650\n",
      "Epoch 17/30\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 11.1915 - val_accuracy: 0.6650\n",
      "Epoch 18/30\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 11.1915 - val_accuracy: 0.6650\n",
      "Epoch 19/30\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 11.1915 - val_accuracy: 0.6650\n",
      "Epoch 20/30\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 11.1915 - val_accuracy: 0.6650\n",
      "Epoch 21/30\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 11.1915 - val_accuracy: 0.6650\n",
      "Epoch 22/30\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 11.1915 - val_accuracy: 0.6650\n",
      "Epoch 23/30\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 11.1915 - val_accuracy: 0.6650\n",
      "Epoch 24/30\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 11.1915 - val_accuracy: 0.6650\n",
      "Epoch 25/30\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 11.1915 - val_accuracy: 0.6650\n",
      "Epoch 26/30\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 11.1915 - val_accuracy: 0.6650\n",
      "Epoch 27/30\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 11.1915 - val_accuracy: 0.6650\n",
      "Epoch 28/30\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 11.1915 - val_accuracy: 0.6650\n",
      "Epoch 29/30\n",
      "19/19 [==============================] - 0s 13ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 11.1915 - val_accuracy: 0.6650\n",
      "Epoch 30/30\n",
      "19/19 [==============================] - 0s 12ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 11.1915 - val_accuracy: 0.6650\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'upperleft' is not a valid value for loc; supported values are 'best', 'upper right', 'upper left', 'lower left', 'lower right', 'right', 'center left', 'center right', 'lower center', 'upper center', 'center'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cs/n7lxyhm16zn37_l0t4m0jrhr0000gn/T/ipykernel_65407/65475412.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhistory1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_X_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_Y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_Y_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcp_filepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./non_normalization'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplotting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/cs/n7lxyhm16zn37_l0t4m0jrhr0000gn/T/ipykernel_65407/2085578841.py\u001b[0m in \u001b[0;36mplotting\u001b[0;34m(history)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'upperleft'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/radar/lib/python3.9/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mlegend\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2653\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2654\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2655\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/radar/lib/python3.9/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mlegend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextra_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'legend only accepts two non-keyword arguments'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlegend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_remove_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_remove_legend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/radar/lib/python3.9/site-packages/matplotlib/legend.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, parent, handles, labels, loc, numpoints, markerscale, markerfirst, scatterpoints, scatteryoffsets, prop, fontsize, labelcolor, borderpad, labelspacing, handlelength, handleheight, handletextpad, borderaxespad, columnspacing, ncol, mode, fancybox, shadow, title, title_fontsize, framealpha, edgecolor, facecolor, bbox_to_anchor, bbox_transform, frameon, handler_map, title_fontproperties)\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'upper right'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_getitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misaxes\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mloc\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             raise ValueError(\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/radar/lib/python3.9/site-packages/matplotlib/_api/__init__.py\u001b[0m in \u001b[0;36mcheck_getitem\u001b[0;34m(_mapping, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    189\u001b[0m             \u001b[0;34m\"{!r} is not a valid value for {}; supported values are {}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             .format(v, k, ', '.join(map(repr, mapping)))) from None\n",
      "\u001b[0;31mValueError\u001b[0m: 'upperleft' is not a valid value for loc; supported values are 'best', 'upper right', 'upper left', 'lower left', 'lower right', 'right', 'center left', 'center right', 'lower center', 'upper center', 'center'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEWCAYAAACEz/viAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAcyUlEQVR4nO3de3hddZ3v8fenaUtTLm0hkUsvpEARUEEwB9FxhAFhuCgdRaH1MICDoh5RZ/CG83gcZcbxjMcLI3L0AWW4g4CXqVBAB2EQr02xIC0tljaxraUkoS00KU0v3/PHWoHdkJ3spllZ2Xt9Xs+TJ3td9t7fxS77k9/6rfX7KSIwM7NiG5N3AWZmlj+HgZmZOQzMzMxhYGZmOAzMzAyHgZmZ4TCwgpDUJCkkja1g34skPTISdZmNFg4DG3UktUrqkdTQZ/3v0y/0ppxKM6tZDgMbrVYCc3sXJL0OmJhfOaNDJS0bs6FwGNhodRNwQcnyhcCNpTtImiTpRkntktokfU7SmHRbnaSvSuqQtAI4q5/nfk/SWklrJP2LpLpKCpN0p6RnJG2U9LCk15Rsq5f0tbSejZIekVSfbnuLpF9J2iBplaSL0vUPSXp/yWvsdJoqbQ19RNIfgT+m6/49fY3nJS2U9Jcl+9dJ+kdJT0t6Id0+XdLVkr7W51jmSfqHSo7bapvDwEar3wD7SDoy/ZKeA9zcZ5+rgEnAIcCJJOHxvnTbB4C3A8cCzcC7+zz3emAbcFi6z2nA+6nMvcAs4FXAo8AtJdu+CrwBeDOwL/BpYIekg9PnXQU0Aq8HFlX4fgB/A7wROCpdXpC+xr7ArcCdkiak2y4jaVWdCewD/B3QDdwAzC0JzAbgbenzregiwj/+GVU/QCvJl9TngC8DpwM/A8YCATQBdUAPcFTJ8z4IPJQ+/jnwoZJtp6XPHQvsD2wB6ku2zwUeTB9fBDxSYa2T09edRPLH1WbgmH72+yzwozKv8RDw/pLlnd4/ff2TB6ljfe/7AsuA2WX2exI4NX18KTA/78/bP6Pjx+cfbTS7CXgYmEmfU0RAAzAOaCtZ1wZMTR8fBKzqs63Xwelz10rqXTemz/79SlspXwLeQ/IX/o6SevYAJgBP9/PU6WXWV2qn2iR9EriY5DiDpAXQ2+E+0HvdAJxPEq7nA/++GzVZDfFpIhu1IqKNpCP5TOCHfTZ3AFtJvth7zQDWpI/Xknwplm7rtYqkZdAQEZPTn30i4jUM7r3AbJKWyySSVgqA0ppeBA7t53mryqwH6GLnzvED+tnnpeGF0/6BTwPnAlMiYjKwMa1hsPe6GZgt6RjgSODHZfazgnEY2Gh3Mckpkq7SlRGxHbgD+JKkvdNz8pfxcr/CHcDHJE2TNAW4vOS5a4GfAl+TtI+kMZIOlXRiBfXsTRIknSRf4P9a8ro7gOuAr0s6KO3IfZOkPUj6Fd4m6VxJYyXtJ+n16VMXAe+SNFHSYekxD1bDNqAdGCvp8yQtg17fBf5Z0iwljpa0X1rjapL+hpuAH0TE5gqO2QrAYWCjWkQ8HREtZTZ/lOSv6hXAIyQdodel264F7gceI+nk7duyuAAYDywhOd9+F3BgBSXdSHLKaU363N/02f5J4A8kX7jPAf8GjImIP5G0cD6Rrl8EHJM+5xsk/R/rSE7j3MLA7gfuA55Ka3mRnU8jfZ0kDH8KPA98D6gv2X4D8DqSQDADQBGe3MasSCS9laQFdXD4C8BSbhmYFYikccDHge86CKyUw8CsICQdCWwgOR12Za7F2Kjj00RmZuaWgZmZUX03nTU0NERTU1PeZZiZVZWFCxd2RERjue1VFwZNTU20tJS70tDMzPojqW2g7T5NZGZmDgMzM3MYmJkZDgMzM8NhYGZmZBgGkq6T9KykJ8psl6RvSlou6XFJx2VVi5mZDSzLlsH1JDNUlXMGydSBs4BLgG9nWIuZmQ0gs/sMIuJhSU0D7DIbuDEdLOs3kiZLOjAda37U6u7Zxpr1m1m9fjOr13fTvqkHPKSHmY2AU47cn2OmT87ktfO86WwqO4/Bvjpd94owkHQJSeuBGTNm9N087J59/kUWr32e1c91p1/6yRf/6vWb6ezqecX+L8+caGaWnVftM6Emw6BiEXENcA1Ac3Nzpn+GRwR/feXDrO/eCsD4ujFMm1LP1Cn1nHbQJKZNqU9/JjJ933oa9tyDMWOcBmZW3fIMgzXsPEftNF6evzY3657fwvrurXzkrw7lgjc10biXv+zNrPbleWnpPOCC9KqiE4CNo6G/oLUzmWr3hEP2Y/99JjgIzKwQMmsZSLoNOAlokLQa+CdgHEBEfAeYTzIn7HKgG3hfVrXsitaOJAya9tsz50rMzEZOllcTzR1kewAfyer9h6q1s5vxdWM4aHL94DubmdUI34HcR1tnF9P3rafOp4fMrEAcBn2s7OjyKSIzKxyHQYmIoK2zm4MdBmZWMA6DEs++sIXNW7czs2Fi3qWYmY0oh0GJ3iuJ3DIws6JxGJRo6+wGYGaDw8DMisVhUGJlZxfj6sSBkybkXYqZ2YhyGJRo6+xi+pSJjK3zfxYzKxZ/65VY2dFNk08RmVkBOQxSyWWlXRy8n68kMrPicRik2jdtobtnuzuPzayQHAap1o7kSiJfVmpmReQwSPUOXd3k00RmVkAOg1RrRxdjx4ipHq3UzArIYZBq6+xm+r6+rNTMisnffKnWzi6fIjKzwnIYkFxW2trR5c5jMysshwHQsamHrp7tbhmYWWE5DCi5ksj3GJhZQTkMeHnoas9wZmZF5TAgaRmMHSOmTfFlpWZWTA4DoLWzm2lT6n1ZqZkVlr/9SIaudn+BmRVZ4cMguay02/0FZlZohQ+Dzq4eNm3Z5qGrzazQCh8GL11J5NNEZlZgDoPOZOhqnyYysyIrfBi0dXZR58tKzazgCh8GKzu6mDalnnG+rNTMCqzw34Btnd0eoM7MCq/QYdA7WulMX0lkZgWXaRhIOl3SMknLJV3ez/aDJT0g6XFJD0malmU9fT3X1cMLW7a5ZWBmhZdZGEiqA64GzgCOAuZKOqrPbl8FboyIo4ErgC9nVU9/eq8kmunLSs2s4LJsGRwPLI+IFRHRA9wOzO6zz1HAz9PHD/azPVO99xj4hjMzK7osw2AqsKpkeXW6rtRjwLvSx+8E9pa0X98XknSJpBZJLe3t7cNWYFtnF2ME06Y4DMys2PLuQP4kcKKk3wMnAmuA7X13iohrIqI5IpobGxuH7c1XdnYzbcpExo/N+z+DmVm+xmb42muA6SXL09J1L4mIP5O2DCTtBZwTERsyrGknbZ1dPkVkZka2LYMFwCxJMyWNB+YA80p3kNQgqbeGzwLXZVjPTiKClR1d7jw2MyPDMIiIbcClwP3Ak8AdEbFY0hWSzk53OwlYJukpYH/gS1nV09f67q288KIvKzUzg2xPExER84H5fdZ9vuTxXcBdWdZQTmtn77zHPk1kZlbYnlMPXW1m9rLihkFnN2ME031ZqZlZgcOgo4upU+p9WamZGQUOg7bOLk9oY2aWKmwYtHZ2+x4DM7NUIcNgfVcPGzdvdcvAzCxVyDB4+bJSh4GZGRQ9DHxZqZkZUNQw6OhGgun71uddipnZqFDIMGjr7OKgSfXsMbYu71LMzEaFQobBys5uD1BnZlaikGHgoavNzHZWuDDY0N3Dhu6tbhmYmZUoXBi0dnYDeOhqM7MShQuDNg9dbWb2CoULg5UdXellpQ4DM7NehQuDts5uDppUz4RxvqzUzKxX4cJgZUcXTQ1uFZiZlSpcGCSXlbrz2MysVKHCYGP3VtZ3b2Wmw8DMbCeFCoPeAep8w5mZ2c4KGQYerdTMbGfFCoN0tNIZvqzUzGwnhQqDts4uDtxngi8rNTPro1BhsLKzy6eIzMz6UagwaOvs9mWlZmb9KEwYbNy8lee6ejwmkZlZPwoTBm2+ksjMrKzChEHv0NVNPk1kZvYKxQmDDt9wZmZWTqZhIOl0ScskLZd0eT/bZ0h6UNLvJT0u6cysavnQiYfy3586yZeVmpn1I7MwkFQHXA2cARwFzJV0VJ/dPgfcERHHAnOA/5dVPePHjvGVRGZmZWTZMjgeWB4RKyKiB7gdmN1nnwD2SR9PAv6cYT1mZlbGoGEg6R2ShhIaU4FVJcur03WlvgCcL2k1MB/4aJkaLpHUIqmlvb19CKWYmdlAKvmSPw/4o6SvSDpimN9/LnB9REwDzgRu6i94IuKaiGiOiObGxsZhLsHMzAYNg4g4HzgWeBq4XtKv07/U9x7kqWuA6SXL09J1pS4G7kjf59fABKChwtrNzGyYVHT6JyKeB+4iOe9/IPBO4FFJ/Z7WSS0AZkmaKWk8SQfxvD77/Ak4BUDSkSRh4PNAZmYjrJI+g7Ml/Qh4CBgHHB8RZwDHAJ8o97yI2AZcCtwPPEly1dBiSVdIOjvd7RPAByQ9BtwGXBQRsTsHZGZmu25sBfucA3wjIh4uXRkR3ZIuHuiJETGfpGO4dN3nSx4vAf6i8nLNzCwLlYTBF4C1vQuS6oH9I6I1Ih7IqjAzMxs5lfQZ3AnsKFnenq4zM7MaUUkYjE1vGgMgfTw+u5LMzGykVRIG7SUdvkiaDXRkV5KZmY20SvoMPgTcIulbgEjuKr4g06rMzGxEDRoGEfE0cIKkvdLlTZlXZWZmI6qSlgGSzgJeA0yQBEBEXJFhXWZmNoIquensOyTjE32U5DTRe4CDM67LzMxGUCUdyG+OiAuA9RHxReBNwOHZlmVmZiOpkjB4Mf3dLekgYCvJ+ERmZlYjKukz+ImkycD/BR4lmZDm2iyLMjOzkTVgGKRzCzwQERuAH0i6G5gQERtHojgzMxsZA54miogdJPMY9y5vcRCYmdWeSvoMHpB0jnqvKTUzs5pTSRh8kGRgui2Snpf0gqTnM67LzMxGUCV3IA82vaWZmVW5QcNA0lv7W993shszM6telVxa+qmSxxOA44GFwMmZVGRmZiOuktNE7yhdljQduDKrgszMbORV0oHc12rgyOEuxMzM8lNJn8FVJHcdQxIerye5E9nMzGpEJX0GLSWPtwG3RcQvM6rHzMxyUEkY3AW8GBHbASTVSZoYEd3ZlmZmZiOlojuQgfqS5Xrgv7Ipx8zM8lBJGEwoneoyfTwxu5LMzGykVRIGXZKO612Q9AZgc3YlmZnZSKukz+DvgTsl/Zlk2ssDSKbBNDOzGlHJTWcLJB0BvDpdtSwitmZblpmZjaRBTxNJ+giwZ0Q8ERFPAHtJ+l/Zl2ZmZiOlkj6DD6QznQEQEeuBD2RWkZmZjbhKwqCudGIbSXXA+OxKMjOzkVZJGNwHfF/SKZJOAW4D7q3kxSWdLmmZpOWSLu9n+zckLUp/npK0YZeqNzOzYVHJ1USfAS4BPpQuP05yRdGA0hbE1cCpJIPbLZA0LyKW9O4TEf9Qsv9HgWMrL93MzIbLoC2DiNgB/BZoJZnL4GTgyQpe+3hgeUSsiIge4HZg9gD7zyVpdZiZ2Qgr2zKQdDjJF/RcoAP4PkBE/FWFrz0VWFWyvBp4Y5n3OhiYCfy8zPZLSFonzJgxo8K3NzOzSg3UMlhK0gp4e0S8JSKuArZnVMcc4K7ewfD6iohrIqI5IpobGxszKsHMrLgGCoN3AWuBByVdm3Yea4D9+1oDTC9Znpau688cfIrIzCw3ZcMgIn4cEXOAI4AHSYaleJWkb0s6rYLXXgDMkjRT0niSL/x5fXdK726eAvx6CPWbmdkwqKQDuSsibk3nQp4G/J7kCqPBnrcNuBS4n6TD+Y6IWCzpCklnl+w6B7g9IqK/1zEzs+yp2r6Dm5ubo6WlZfAdzczsJZIWRkRzue2V3HRmZmY1zmFgZmYOAzMzcxiYmRkOAzMzw2FgZmZUNmqpjaQIeHEjUF2X/JrZCBg3EcbukclLOwzytH0rtC+DZ/4Azzz+8u8XN+ZdmZmNRmd9Hf7HxZm8tMNgpGzZ9PIX/trHk8ftS2F7T7J9bD0c8Fp47Tmw76Ewpi7fes1s9Jne78DPw8JhMBLan4L/OAO6O5LliQ1w4NFw6IfhgKOTn/0cAGaWH4dB1l5YBzefAxLMuQ0OOhb2PiBZNjMbJRwGWdryAtzybujuhIvuhqnH5V2RmVm/HAZZ2b4V7rgQ1i2G937fQWBmo5rDIAsR8JOPw9MPwNlXwaxT867IzGxAvuksCw/+Kyy6BU68HI67IO9qzMwG5TAYbguvh4e/AseeDyddnnc1ZmYVcRgMp6fuh7svg8PeBm+/0lcMmVnVcBgMlzUL4c6LkhvH3nMD1I3LuyIzs4o5DIbDcyvglnNhzwZ4752wx155V2RmtkscBrurqyO5qSy2w/k/hL33z7siM7Nd5ktLd0dPN9x6Hjz/Z7hgHjTMyrsiM7MhcRjsjl9/K+krOO8mmJHdAFJmZlnzaaLdsWQezDgBjnxH3pWYme0Wh8FQrW+FdX+AI87KuxIzs93mMBiqpfOT368+M986zMyGgcNgqJbeA686KpmHwMysyjkMhqL7OfjTr9wqMLOa4TAYiqfug9jh/gIzqxkOg6FYeg/sfVAya5mZWQ1wGOyqnm5Y/kDSKvBAdGZWIzINA0mnS1omabmkfsdzlnSupCWSFku6Nct6hsWKB2HbZp8iMrOaktkdyJLqgKuBU4HVwAJJ8yJiSck+s4DPAn8REeslvSqreobN0ntgj0nQ9Ja8KzEzGzZZtgyOB5ZHxIqI6AFuB2b32ecDwNURsR4gIp7NsJ7dt30bLLsXDv9rD1FtZjUlyzCYCqwqWV6drit1OHC4pF9K+o2k0/t7IUmXSGqR1NLe3p5RuRVY9RvY/JxPEZlZzcm7A3ksMAs4CZgLXCtpct+dIuKaiGiOiObGxsaRrbDU0nugbg847JT8ajAzy0CWYbAGmF6yPC1dV2o1MC8itkbESuApknAYfSJg6d1wyEmwx955V2NmNqyyDIMFwCxJMyWNB+YA8/rs82OSVgGSGkhOG63IsKahW/cEbPiTTxGZWU3KLAwiYhtwKXA/8CRwR0QslnSFpLPT3e4HOiUtAR4EPhURnVnVtFuW3gMIXn1G3pWYmQ27TCe3iYj5wPw+6z5f8jiAy9Kf0W3p3TD9jbDX6L/61cxsV+XdgVwd1rfBM567wMxql8OgEsvSxo3DwMxqlMOgEkvvgcYjPXeBmdUsh8Fgup+Dtl+6VWBmNc1hMBjPXWBmBeAwGIznLjCzAnAYDMRzF5hZQTgMBrLiIc9dYGaF4DAYiOcuMLOCcBiUs31bcn+B5y4wswJwGJSz6reeu8DMCsNhUI7nLjCzAnEY9MdzF5hZwTgM+rNuMWxo8ykiMysMh0F/PHeBmRWMw6CvCFj6E89dYGaF4jDoa9n8ZO6Co9+TdyVmZiPGYVBq62a477PQeAQcd2He1ZiZjZhMp72sOr+6Kuk4vmCebzQzs0Jxy6DXhj/BL74OR82GQ07MuxozsxHlMOj1088lv0/7Ur51mJnlwGEAyeikS/4T/vIymDw972rMzEacw2D7Vrj3MzD5YHjzx/KuxswsF+5A/t210L4U5twK4ybkXY2ZWS6K3TLY9Cw89GU49BR49Zl5V2Nmlptih8F/fTG5t+CMf/O0lmZWaMUNg9UtsOhmOOHD0DAr72rMzHJVzDDYsQPmfwr2OgBO/HTe1ZiZ5a6YHciLboY/PwrvvMbzFZiZUcSWweYNSV/B9BPg6HPzrsbMbFQoXsvgoS9Ddyf87Q/daWxmlsq0ZSDpdEnLJC2XdHk/2y+S1C5pUfrz/izrYd2S5L6C5vfBgcdk+lZmZtUks5aBpDrgauBUYDWwQNK8iFjSZ9fvR8SlWdXxkgi499MwYR84+X9n/nZmZtUky5bB8cDyiFgRET3A7cDsDN9vYIt/BK2/gJM/BxP3za0MM7PRKMswmAqsKllena7r6xxJj0u6S1K/o8RJukRSi6SW9vb2oVWzx97w6rPgDe8b2vPNzGpY3lcT/QRoioijgZ8BN/S3U0RcExHNEdHc2Ng4tHeadSrMvRXG1A25WDOzWpVlGKwBSv/Sn5aue0lEdEbElnTxu8AbMqzHzMzKyDIMFgCzJM2UNB6YA8wr3UHSgSWLZwNPZliPmZmVkdnVRBGxTdKlwP1AHXBdRCyWdAXQEhHzgI9JOhvYBjwHXJRVPWZmVp4iIu8adklzc3O0tLTkXYaZWVWRtDAimsttz7sD2czMRgGHgZmZOQzMzMxhYGZmVGEHsqR2oG2IT28AOoaxnNGg1o6p1o4Hau+Yau14oPaOqb/jOTgiyt61W3VhsDsktQzUm16Nau2Yau14oPaOqdaOB2rvmIZyPD5NZGZmDgMzMyteGFyTdwEZqLVjqrXjgdo7plo7Hqi9Y9rl4ylUn4GZmfWvaC0DMzPrh8PAzMyKEwaSTpe0TNJySZfnXc/uktQq6Q+SFkmqypH7JF0n6VlJT5Ss21fSzyT9Mf09Jc8ad0WZ4/mCpDXp57RI0pl51rirJE2X9KCkJZIWS/p4ur4qP6cBjqdqPydJEyT9TtJj6TF9MV0/U9Jv0++876dTCZR/nSL0GUiqA54CTiWZfnMBMDciluRa2G6Q1Ao0R0TV3igj6a3AJuDGiHhtuu4rwHMR8X/S0J4SEZ/Js85KlTmeLwCbIuKredY2VOmcIwdGxKOS9gYWAn9DMtx81X1OAxzPuVTp5yRJwJ4RsUnSOOAR4OPAZcAPI+J2Sd8BHouIb5d7naK0DI4HlkfEiojoAW4HZudcU+FFxMMk81iUms3L05/eQPI/alUoczxVLSLWRsSj6eMXSCagmkqVfk4DHE/VisSmdHFc+hPAycBd6fpBP6OihMFUYFXJ8mqq/B8AyYf9U0kLJV2SdzHDaP+IWJs+fgbYP89ihsmlkh5PTyNVxemU/khqAo4FfksNfE59jgeq+HOSVCdpEfAsyXzyTwMbImJbusug33lFCYNa9JaIOA44A/hIeoqipkRyDrPaz2N+GzgUeD2wFvhartUMkaS9gB8Afx8Rz5duq8bPqZ/jqerPKSK2R8TrSeaaPx44YldfoyhhsAaYXrI8LV1XtSJiTfr7WeBHJP8AasG63rmx09/P5lzPbomIden/qDuAa6nCzyk9D/0D4JaI+GG6umo/p/6OpxY+J4CI2AA8CLwJmCypd2rjQb/zihIGC4BZae/6eGAOMC/nmoZM0p5p5xeS9gROA54Y+FlVYx5wYfr4QuA/c6xlt/V+YabeSZV9Tmnn5PeAJyPi6yWbqvJzKnc81fw5SWqUNDl9XE9yocyTJKHw7nS3QT+jQlxNBJBeKnYlUAdcFxFfyreioZN0CElrAGAscGs1Ho+k24CTSIbbXQf8E/Bj4A5gBslQ5edGRFV0ypY5npNITj0E0Ap8sORc+6gn6S3AL4A/ADvS1f9Icp696j6nAY5nLlX6OUk6mqSDuI7kD/w7IuKK9HvidmBf4PfA+RGxpezrFCUMzMysvKKcJjIzswE4DMzMzGFgZmYOAzMzw2FgZmY4DMxeQdL2ktErFw3nKLeSmkpHNTUbLcYOvotZ4WxOb+03Kwy3DMwqlM4h8ZV0HonfSTosXd8k6efpIGcPSJqRrt9f0o/SceYfk/Tm9KXqJF2bjj3/0/SuUbNcOQzMXqm+z2mi80q2bYyI1wHfIrmjHeAq4IaIOBq4Bfhmuv6bwH9HxDHAccDidP0s4OqIeA2wATgn06Mxq4DvQDbrQ9KmiNirn/WtwMkRsSId7OyZiNhPUgfJhClb0/VrI6JBUjswrXQIgHTY5J9FxKx0+TPAuIj4lxE4NLOy3DIw2zVR5vGuKB0fZjvuu7NRwGFgtmvOK/n96/Txr0hGwgX4nyQDoQE8AHwYXpp8ZNJIFWm2q/wXidkr1aezRvW6LyJ6Ly+dIulxkr/u56brPgr8h6RPAe3A+9L1HweukXQxSQvgwyQTp5iNOu4zMKtQ2mfQHBEdeddiNtx8msjMzNwyMDMztwzMzAyHgZmZ4TAwMzMcBmZmhsPAzMyA/w/3BXYTm4M6jAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history1 = training(X_s, Y_s, test_X=test_X_s, test_Y=test_Y_s, EPOCHS = 30, cp_filepath='./non_normalization')\n",
    "plotting(history1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum = np.max(X_s)\n",
    "X_n = X_s/maximum #normalization\n",
    "test_X_n = test_X_s/maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3131+1255j)\n"
     ]
    }
   ],
   "source": [
    "print(maximum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_3 (Conv1D)           (None, 412, 32)           128       \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 412, 32)           0         \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 410, 64)           6208      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 410, 64)           0         \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 408, 64)           12352     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 26112)             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 104452    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 123,140\n",
      "Trainable params: 123,140\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "357/375 [===========================>..] - ETA: 0s - loss: 0.6779 - accuracy: 0.7055INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6606 - accuracy: 0.7132 - val_loss: 0.4708 - val_accuracy: 0.7917\n",
      "Epoch 2/500\n",
      "365/375 [============================>.] - ETA: 0s - loss: 0.2973 - accuracy: 0.8883INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2951 - accuracy: 0.8892 - val_loss: 0.4213 - val_accuracy: 0.8258\n",
      "Epoch 3/500\n",
      "363/375 [============================>.] - ETA: 0s - loss: 0.1994 - accuracy: 0.9320INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1983 - accuracy: 0.9325 - val_loss: 0.2951 - val_accuracy: 0.8725\n",
      "Epoch 4/500\n",
      "368/375 [============================>.] - ETA: 0s - loss: 0.1556 - accuracy: 0.9455INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1554 - accuracy: 0.9456 - val_loss: 0.2587 - val_accuracy: 0.9058\n",
      "Epoch 5/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1549 - accuracy: 0.9480 - val_loss: 0.3985 - val_accuracy: 0.8733\n",
      "Epoch 6/500\n",
      "359/375 [===========================>..] - ETA: 0s - loss: 0.1342 - accuracy: 0.9560INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1337 - accuracy: 0.9562 - val_loss: 0.1613 - val_accuracy: 0.9350\n",
      "Epoch 7/500\n",
      "355/375 [===========================>..] - ETA: 0s - loss: 0.1185 - accuracy: 0.9607INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1230 - accuracy: 0.9601 - val_loss: 0.1437 - val_accuracy: 0.9458\n",
      "Epoch 8/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1209 - accuracy: 0.9613 - val_loss: 0.1785 - val_accuracy: 0.9242\n",
      "Epoch 9/500\n",
      "360/375 [===========================>..] - ETA: 0s - loss: 0.1160 - accuracy: 0.9632INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1139 - accuracy: 0.9638 - val_loss: 0.1449 - val_accuracy: 0.9500\n",
      "Epoch 10/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0989 - accuracy: 0.9678 - val_loss: 0.1552 - val_accuracy: 0.9408\n",
      "Epoch 11/500\n",
      "359/375 [===========================>..] - ETA: 0s - loss: 0.0996 - accuracy: 0.9658INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1028 - accuracy: 0.9653 - val_loss: 0.1086 - val_accuracy: 0.9592\n",
      "Epoch 12/500\n",
      "362/375 [===========================>..] - ETA: 0s - loss: 0.0922 - accuracy: 0.9695INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0934 - accuracy: 0.9687 - val_loss: 0.0975 - val_accuracy: 0.9667\n",
      "Epoch 13/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0937 - accuracy: 0.9678 - val_loss: 0.2439 - val_accuracy: 0.9125\n",
      "Epoch 14/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0984 - accuracy: 0.9681 - val_loss: 0.2814 - val_accuracy: 0.9167\n",
      "Epoch 15/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0924 - accuracy: 0.9688 - val_loss: 0.1317 - val_accuracy: 0.9467\n",
      "Epoch 16/500\n",
      "364/375 [============================>.] - ETA: 0s - loss: 0.0887 - accuracy: 0.9712INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0886 - accuracy: 0.9708 - val_loss: 0.0862 - val_accuracy: 0.9700\n",
      "Epoch 17/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0921 - accuracy: 0.9692 - val_loss: 0.1120 - val_accuracy: 0.9608\n",
      "Epoch 18/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0824 - accuracy: 0.9718 - val_loss: 0.1508 - val_accuracy: 0.9492\n",
      "Epoch 19/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0947 - accuracy: 0.9670 - val_loss: 0.1172 - val_accuracy: 0.9608\n",
      "Epoch 20/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0793 - accuracy: 0.9729 - val_loss: 0.0986 - val_accuracy: 0.9650\n",
      "Epoch 21/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0774 - accuracy: 0.9719 - val_loss: 0.1371 - val_accuracy: 0.9467\n",
      "Epoch 22/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0841 - accuracy: 0.9729 - val_loss: 0.1019 - val_accuracy: 0.9608\n",
      "Epoch 23/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0698 - accuracy: 0.9769 - val_loss: 0.1020 - val_accuracy: 0.9633\n",
      "Epoch 24/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0735 - accuracy: 0.9750 - val_loss: 0.0948 - val_accuracy: 0.9683\n",
      "Epoch 25/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0732 - accuracy: 0.9762 - val_loss: 0.1116 - val_accuracy: 0.9642\n",
      "Epoch 26/500\n",
      "367/375 [============================>.] - ETA: 0s - loss: 0.0730 - accuracy: 0.9753INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0727 - accuracy: 0.9753 - val_loss: 0.0754 - val_accuracy: 0.9717\n",
      "Epoch 27/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0819 - accuracy: 0.9727 - val_loss: 0.0877 - val_accuracy: 0.9642\n",
      "Epoch 28/500\n",
      "367/375 [============================>.] - ETA: 0s - loss: 0.0740 - accuracy: 0.9739INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0739 - accuracy: 0.9739 - val_loss: 0.0863 - val_accuracy: 0.9733\n",
      "Epoch 29/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0675 - accuracy: 0.9768 - val_loss: 0.1381 - val_accuracy: 0.9558\n",
      "Epoch 30/500\n",
      "365/375 [============================>.] - ETA: 0s - loss: 0.0697 - accuracy: 0.9756INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0699 - accuracy: 0.9757 - val_loss: 0.0714 - val_accuracy: 0.9758\n",
      "Epoch 31/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0683 - accuracy: 0.9752 - val_loss: 0.1162 - val_accuracy: 0.9592\n",
      "Epoch 32/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0704 - accuracy: 0.9759 - val_loss: 0.1072 - val_accuracy: 0.9592\n",
      "Epoch 33/500\n",
      "370/375 [============================>.] - ETA: 0s - loss: 0.0698 - accuracy: 0.9774INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0696 - accuracy: 0.9774 - val_loss: 0.0738 - val_accuracy: 0.9783\n",
      "Epoch 34/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0656 - accuracy: 0.9766 - val_loss: 0.1026 - val_accuracy: 0.9650\n",
      "Epoch 35/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0651 - accuracy: 0.9769 - val_loss: 0.1058 - val_accuracy: 0.9633\n",
      "Epoch 36/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0658 - accuracy: 0.9779 - val_loss: 0.1106 - val_accuracy: 0.9633\n",
      "Epoch 37/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0640 - accuracy: 0.9787 - val_loss: 0.1351 - val_accuracy: 0.9600\n",
      "Epoch 38/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0648 - accuracy: 0.9777 - val_loss: 0.1003 - val_accuracy: 0.9733\n",
      "Epoch 39/500\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0623 - accuracy: 0.9783INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0623 - accuracy: 0.9783 - val_loss: 0.0574 - val_accuracy: 0.9800\n",
      "Epoch 40/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0636 - accuracy: 0.9778 - val_loss: 0.1040 - val_accuracy: 0.9675\n",
      "Epoch 41/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0640 - accuracy: 0.9771 - val_loss: 0.0774 - val_accuracy: 0.9742\n",
      "Epoch 42/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0599 - accuracy: 0.9794 - val_loss: 0.0684 - val_accuracy: 0.9783\n",
      "Epoch 43/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0608 - accuracy: 0.9791 - val_loss: 0.0807 - val_accuracy: 0.9767\n",
      "Epoch 44/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0613 - accuracy: 0.9787 - val_loss: 0.1228 - val_accuracy: 0.9617\n",
      "Epoch 45/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0670 - accuracy: 0.9767 - val_loss: 0.1291 - val_accuracy: 0.9575\n",
      "Epoch 46/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0600 - accuracy: 0.9801 - val_loss: 0.1082 - val_accuracy: 0.9600\n",
      "Epoch 47/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0608 - accuracy: 0.9793 - val_loss: 0.0765 - val_accuracy: 0.9717\n",
      "Epoch 48/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0573 - accuracy: 0.9806 - val_loss: 0.0935 - val_accuracy: 0.9658\n",
      "Epoch 49/500\n",
      "359/375 [===========================>..] - ETA: 0s - loss: 0.0562 - accuracy: 0.9807INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0564 - accuracy: 0.9805 - val_loss: 0.0600 - val_accuracy: 0.9808\n",
      "Epoch 50/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0615 - accuracy: 0.9780 - val_loss: 0.0949 - val_accuracy: 0.9717\n",
      "Epoch 51/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0599 - accuracy: 0.9787 - val_loss: 0.0741 - val_accuracy: 0.9758\n",
      "Epoch 52/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0579 - accuracy: 0.9797 - val_loss: 0.1193 - val_accuracy: 0.9567\n",
      "Epoch 53/500\n",
      "370/375 [============================>.] - ETA: 0s - loss: 0.0576 - accuracy: 0.9799INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0570 - accuracy: 0.9802 - val_loss: 0.0547 - val_accuracy: 0.9817\n",
      "Epoch 54/500\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.0582 - accuracy: 0.9800INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0580 - accuracy: 0.9800 - val_loss: 0.0512 - val_accuracy: 0.9825\n",
      "Epoch 55/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0572 - accuracy: 0.9803 - val_loss: 0.1316 - val_accuracy: 0.9575\n",
      "Epoch 56/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0562 - accuracy: 0.9817 - val_loss: 0.0877 - val_accuracy: 0.9750\n",
      "Epoch 57/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0571 - accuracy: 0.9799 - val_loss: 0.0555 - val_accuracy: 0.9825\n",
      "Epoch 58/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0504 - accuracy: 0.9822 - val_loss: 0.0808 - val_accuracy: 0.9708\n",
      "Epoch 59/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0579 - accuracy: 0.9795 - val_loss: 0.1217 - val_accuracy: 0.9617\n",
      "Epoch 60/500\n",
      "365/375 [============================>.] - ETA: 0s - loss: 0.0533 - accuracy: 0.9817INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0530 - accuracy: 0.9817 - val_loss: 0.0547 - val_accuracy: 0.9858\n",
      "Epoch 61/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0575 - accuracy: 0.9802 - val_loss: 0.0585 - val_accuracy: 0.9817\n",
      "Epoch 62/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0509 - accuracy: 0.9824 - val_loss: 0.0847 - val_accuracy: 0.9742\n",
      "Epoch 63/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0558 - accuracy: 0.9798 - val_loss: 0.0759 - val_accuracy: 0.9783\n",
      "Epoch 64/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0532 - accuracy: 0.9822 - val_loss: 0.0918 - val_accuracy: 0.9675\n",
      "Epoch 65/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0534 - accuracy: 0.9808 - val_loss: 0.0836 - val_accuracy: 0.9750\n",
      "Epoch 66/500\n",
      "367/375 [============================>.] - ETA: 0s - loss: 0.0562 - accuracy: 0.9798INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0556 - accuracy: 0.9800 - val_loss: 0.0402 - val_accuracy: 0.9875\n",
      "Epoch 67/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0508 - accuracy: 0.9827 - val_loss: 0.0582 - val_accuracy: 0.9817\n",
      "Epoch 68/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0590 - accuracy: 0.9790 - val_loss: 0.0624 - val_accuracy: 0.9825\n",
      "Epoch 69/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0501 - accuracy: 0.9827 - val_loss: 0.1266 - val_accuracy: 0.9583\n",
      "Epoch 70/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0552 - accuracy: 0.9797 - val_loss: 0.0864 - val_accuracy: 0.9767\n",
      "Epoch 71/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0526 - accuracy: 0.9817 - val_loss: 0.0526 - val_accuracy: 0.9850\n",
      "Epoch 72/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0479 - accuracy: 0.9820 - val_loss: 0.0942 - val_accuracy: 0.9733\n",
      "Epoch 73/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0496 - accuracy: 0.9820 - val_loss: 0.0982 - val_accuracy: 0.9675\n",
      "Epoch 74/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0465 - accuracy: 0.9835 - val_loss: 0.0904 - val_accuracy: 0.9775\n",
      "Epoch 75/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0515 - accuracy: 0.9811 - val_loss: 0.1215 - val_accuracy: 0.9592\n",
      "Epoch 76/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0598 - accuracy: 0.9792 - val_loss: 0.0687 - val_accuracy: 0.9808\n",
      "Epoch 77/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0535 - accuracy: 0.9804 - val_loss: 0.0785 - val_accuracy: 0.9733\n",
      "Epoch 78/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0489 - accuracy: 0.9827 - val_loss: 0.0462 - val_accuracy: 0.9867\n",
      "Epoch 79/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0525 - accuracy: 0.9803 - val_loss: 0.1229 - val_accuracy: 0.9650\n",
      "Epoch 80/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0491 - accuracy: 0.9818 - val_loss: 0.0562 - val_accuracy: 0.9792\n",
      "Epoch 81/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0561 - accuracy: 0.9803 - val_loss: 0.0739 - val_accuracy: 0.9800\n",
      "Epoch 82/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0455 - accuracy: 0.9836 - val_loss: 0.0511 - val_accuracy: 0.9867\n",
      "Epoch 83/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0482 - accuracy: 0.9833 - val_loss: 0.0994 - val_accuracy: 0.9717\n",
      "Epoch 84/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0507 - accuracy: 0.9824 - val_loss: 0.0593 - val_accuracy: 0.9867\n",
      "Epoch 85/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0466 - accuracy: 0.9835 - val_loss: 0.0595 - val_accuracy: 0.9808\n",
      "Epoch 86/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0477 - accuracy: 0.9828 - val_loss: 0.0839 - val_accuracy: 0.9733\n",
      "Epoch 87/500\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.0508 - accuracy: 0.9832INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0506 - accuracy: 0.9833 - val_loss: 0.0312 - val_accuracy: 0.9900\n",
      "Epoch 88/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0499 - accuracy: 0.9811 - val_loss: 0.0449 - val_accuracy: 0.9892\n",
      "Epoch 89/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0436 - accuracy: 0.9858 - val_loss: 0.0734 - val_accuracy: 0.9758\n",
      "Epoch 90/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0464 - accuracy: 0.9837 - val_loss: 0.0623 - val_accuracy: 0.9817\n",
      "Epoch 91/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0464 - accuracy: 0.9847 - val_loss: 0.0526 - val_accuracy: 0.9825\n",
      "Epoch 92/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0465 - accuracy: 0.9835 - val_loss: 0.0841 - val_accuracy: 0.9758\n",
      "Epoch 93/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0505 - accuracy: 0.9822 - val_loss: 0.0595 - val_accuracy: 0.9808\n",
      "Epoch 94/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0484 - accuracy: 0.9836 - val_loss: 0.0552 - val_accuracy: 0.9833\n",
      "Epoch 95/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0500 - accuracy: 0.9823 - val_loss: 0.0818 - val_accuracy: 0.9758\n",
      "Epoch 96/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0501 - accuracy: 0.9818 - val_loss: 0.0886 - val_accuracy: 0.9725\n",
      "Epoch 97/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0434 - accuracy: 0.9838 - val_loss: 0.0439 - val_accuracy: 0.9875\n",
      "Epoch 98/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0493 - accuracy: 0.9834 - val_loss: 0.0544 - val_accuracy: 0.9842\n",
      "Epoch 99/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0505 - accuracy: 0.9820 - val_loss: 0.0536 - val_accuracy: 0.9850\n",
      "Epoch 100/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0464 - accuracy: 0.9833 - val_loss: 0.0688 - val_accuracy: 0.9808\n",
      "Epoch 101/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0401 - accuracy: 0.9843 - val_loss: 0.0874 - val_accuracy: 0.9750\n",
      "Epoch 102/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0450 - accuracy: 0.9830 - val_loss: 0.0720 - val_accuracy: 0.9767\n",
      "Epoch 103/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0445 - accuracy: 0.9828 - val_loss: 0.0677 - val_accuracy: 0.9750\n",
      "Epoch 104/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0446 - accuracy: 0.9850 - val_loss: 0.0859 - val_accuracy: 0.9692\n",
      "Epoch 105/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0474 - accuracy: 0.9837 - val_loss: 0.0382 - val_accuracy: 0.9867\n",
      "Epoch 106/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0443 - accuracy: 0.9838 - val_loss: 0.2014 - val_accuracy: 0.9450\n",
      "Epoch 107/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0462 - accuracy: 0.9834 - val_loss: 0.0488 - val_accuracy: 0.9875\n",
      "Epoch 108/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0437 - accuracy: 0.9840 - val_loss: 0.0768 - val_accuracy: 0.9792\n",
      "Epoch 109/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0448 - accuracy: 0.9844 - val_loss: 0.0680 - val_accuracy: 0.9792\n",
      "Epoch 110/500\n",
      "369/375 [============================>.] - ETA: 0s - loss: 0.0488 - accuracy: 0.9825INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0487 - accuracy: 0.9825 - val_loss: 0.0372 - val_accuracy: 0.9917\n",
      "Epoch 111/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0412 - accuracy: 0.9850 - val_loss: 0.1012 - val_accuracy: 0.9725\n",
      "Epoch 112/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0423 - accuracy: 0.9846 - val_loss: 0.0513 - val_accuracy: 0.9858\n",
      "Epoch 113/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0453 - accuracy: 0.9839 - val_loss: 0.0784 - val_accuracy: 0.9733\n",
      "Epoch 114/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0431 - accuracy: 0.9857 - val_loss: 0.0512 - val_accuracy: 0.9867\n",
      "Epoch 115/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0477 - accuracy: 0.9825 - val_loss: 0.1428 - val_accuracy: 0.9575\n",
      "Epoch 116/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0428 - accuracy: 0.9847 - val_loss: 0.0705 - val_accuracy: 0.9808\n",
      "Epoch 117/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0410 - accuracy: 0.9850 - val_loss: 0.0524 - val_accuracy: 0.9850\n",
      "Epoch 118/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0413 - accuracy: 0.9851 - val_loss: 0.0558 - val_accuracy: 0.9858\n",
      "Epoch 119/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0403 - accuracy: 0.9860 - val_loss: 0.0415 - val_accuracy: 0.9883\n",
      "Epoch 120/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0479 - accuracy: 0.9843 - val_loss: 0.0689 - val_accuracy: 0.9792\n",
      "Epoch 121/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0445 - accuracy: 0.9844 - val_loss: 0.0749 - val_accuracy: 0.9725\n",
      "Epoch 122/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0447 - accuracy: 0.9836 - val_loss: 0.0606 - val_accuracy: 0.9808\n",
      "Epoch 123/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0418 - accuracy: 0.9848 - val_loss: 0.0380 - val_accuracy: 0.9917\n",
      "Epoch 124/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0414 - accuracy: 0.9851 - val_loss: 0.0513 - val_accuracy: 0.9892\n",
      "Epoch 125/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0441 - accuracy: 0.9838 - val_loss: 0.0746 - val_accuracy: 0.9825\n",
      "Epoch 126/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0411 - accuracy: 0.9852 - val_loss: 0.0600 - val_accuracy: 0.9825\n",
      "Epoch 127/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0447 - accuracy: 0.9844 - val_loss: 0.0555 - val_accuracy: 0.9825\n",
      "Epoch 128/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0416 - accuracy: 0.9851 - val_loss: 0.0663 - val_accuracy: 0.9808\n",
      "Epoch 129/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0445 - accuracy: 0.9847 - val_loss: 0.0387 - val_accuracy: 0.9908\n",
      "Epoch 130/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0437 - accuracy: 0.9846 - val_loss: 0.0582 - val_accuracy: 0.9817\n",
      "Epoch 131/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0435 - accuracy: 0.9852 - val_loss: 0.0477 - val_accuracy: 0.9875\n",
      "Epoch 132/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0392 - accuracy: 0.9872 - val_loss: 0.0552 - val_accuracy: 0.9858\n",
      "Epoch 133/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0424 - accuracy: 0.9856 - val_loss: 0.0565 - val_accuracy: 0.9833\n",
      "Epoch 134/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0380 - accuracy: 0.9862 - val_loss: 0.0373 - val_accuracy: 0.9900\n",
      "Epoch 135/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0415 - accuracy: 0.9852 - val_loss: 0.0833 - val_accuracy: 0.9708\n",
      "Epoch 136/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0441 - accuracy: 0.9836 - val_loss: 0.0983 - val_accuracy: 0.9708\n",
      "Epoch 137/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0415 - accuracy: 0.9859 - val_loss: 0.0515 - val_accuracy: 0.9858\n",
      "Epoch 138/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0400 - accuracy: 0.9852 - val_loss: 0.0640 - val_accuracy: 0.9767\n",
      "Epoch 139/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0384 - accuracy: 0.9861 - val_loss: 0.1651 - val_accuracy: 0.9550\n",
      "Epoch 140/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0417 - accuracy: 0.9857 - val_loss: 0.0475 - val_accuracy: 0.9883\n",
      "Epoch 141/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0443 - accuracy: 0.9833 - val_loss: 0.0441 - val_accuracy: 0.9883\n",
      "Epoch 142/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0473 - accuracy: 0.9838 - val_loss: 0.0542 - val_accuracy: 0.9825\n",
      "Epoch 143/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0378 - accuracy: 0.9860 - val_loss: 0.0408 - val_accuracy: 0.9858\n",
      "Epoch 144/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0404 - accuracy: 0.9859 - val_loss: 0.0444 - val_accuracy: 0.9858\n",
      "Epoch 145/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0405 - accuracy: 0.9862 - val_loss: 0.0266 - val_accuracy: 0.9917\n",
      "Epoch 146/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0392 - accuracy: 0.9857 - val_loss: 0.0831 - val_accuracy: 0.9733\n",
      "Epoch 147/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0435 - accuracy: 0.9843 - val_loss: 0.0565 - val_accuracy: 0.9817\n",
      "Epoch 148/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0465 - accuracy: 0.9848 - val_loss: 0.0553 - val_accuracy: 0.9833\n",
      "Epoch 149/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0395 - accuracy: 0.9857 - val_loss: 0.0551 - val_accuracy: 0.9858\n",
      "Epoch 150/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0436 - accuracy: 0.9843 - val_loss: 0.0581 - val_accuracy: 0.9842\n",
      "Epoch 151/500\n",
      "367/375 [============================>.] - ETA: 0s - loss: 0.0435 - accuracy: 0.9843INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0446 - accuracy: 0.9841 - val_loss: 0.0362 - val_accuracy: 0.9925\n",
      "Epoch 152/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0361 - accuracy: 0.9879 - val_loss: 0.0279 - val_accuracy: 0.9917\n",
      "Epoch 153/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0390 - accuracy: 0.9868 - val_loss: 0.1143 - val_accuracy: 0.9633\n",
      "Epoch 154/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0410 - accuracy: 0.9859 - val_loss: 0.0549 - val_accuracy: 0.9817\n",
      "Epoch 155/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0406 - accuracy: 0.9858 - val_loss: 0.0804 - val_accuracy: 0.9733\n",
      "Epoch 156/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0426 - accuracy: 0.9844 - val_loss: 0.0636 - val_accuracy: 0.9825\n",
      "Epoch 157/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0417 - accuracy: 0.9862 - val_loss: 0.0389 - val_accuracy: 0.9900\n",
      "Epoch 158/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0383 - accuracy: 0.9854 - val_loss: 0.0579 - val_accuracy: 0.9842\n",
      "Epoch 159/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0409 - accuracy: 0.9854 - val_loss: 0.0573 - val_accuracy: 0.9825\n",
      "Epoch 160/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0397 - accuracy: 0.9845 - val_loss: 0.0701 - val_accuracy: 0.9767\n",
      "Epoch 161/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0375 - accuracy: 0.9858 - val_loss: 0.0609 - val_accuracy: 0.9783\n",
      "Epoch 162/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0357 - accuracy: 0.9873 - val_loss: 0.0341 - val_accuracy: 0.9925\n",
      "Epoch 163/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0379 - accuracy: 0.9873 - val_loss: 0.0471 - val_accuracy: 0.9875\n",
      "Epoch 164/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0407 - accuracy: 0.9853 - val_loss: 0.0839 - val_accuracy: 0.9775\n",
      "Epoch 165/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0375 - accuracy: 0.9857 - val_loss: 0.0506 - val_accuracy: 0.9850\n",
      "Epoch 166/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0377 - accuracy: 0.9865 - val_loss: 0.0600 - val_accuracy: 0.9842\n",
      "Epoch 167/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0398 - accuracy: 0.9858 - val_loss: 0.0617 - val_accuracy: 0.9808\n",
      "Epoch 168/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0363 - accuracy: 0.9872 - val_loss: 0.0601 - val_accuracy: 0.9825\n",
      "Epoch 169/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0416 - accuracy: 0.9855 - val_loss: 0.0629 - val_accuracy: 0.9767\n",
      "Epoch 170/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0416 - accuracy: 0.9846 - val_loss: 0.0633 - val_accuracy: 0.9800\n",
      "Epoch 171/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0347 - accuracy: 0.9881 - val_loss: 0.0404 - val_accuracy: 0.9892\n",
      "Epoch 172/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0397 - accuracy: 0.9864 - val_loss: 0.0572 - val_accuracy: 0.9817\n",
      "Epoch 173/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0348 - accuracy: 0.9872 - val_loss: 0.0532 - val_accuracy: 0.9867\n",
      "Epoch 174/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0377 - accuracy: 0.9868 - val_loss: 0.0603 - val_accuracy: 0.9817\n",
      "Epoch 175/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0425 - accuracy: 0.9849 - val_loss: 0.0884 - val_accuracy: 0.9683\n",
      "Epoch 176/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0376 - accuracy: 0.9877 - val_loss: 0.0527 - val_accuracy: 0.9875\n",
      "Epoch 177/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0362 - accuracy: 0.9876 - val_loss: 0.0431 - val_accuracy: 0.9875\n",
      "Epoch 178/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0356 - accuracy: 0.9877 - val_loss: 0.0548 - val_accuracy: 0.9825\n",
      "Epoch 179/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0391 - accuracy: 0.9859 - val_loss: 0.0357 - val_accuracy: 0.9908\n",
      "Epoch 180/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0415 - accuracy: 0.9843 - val_loss: 0.0725 - val_accuracy: 0.9767\n",
      "Epoch 181/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0327 - accuracy: 0.9889 - val_loss: 0.0775 - val_accuracy: 0.9742\n",
      "Epoch 182/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0388 - accuracy: 0.9865 - val_loss: 0.0627 - val_accuracy: 0.9817\n",
      "Epoch 183/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0389 - accuracy: 0.9866 - val_loss: 0.0504 - val_accuracy: 0.9842\n",
      "Epoch 184/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0352 - accuracy: 0.9868 - val_loss: 0.0446 - val_accuracy: 0.9850\n",
      "Epoch 185/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0425 - accuracy: 0.9853 - val_loss: 0.0425 - val_accuracy: 0.9883\n",
      "Epoch 186/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0369 - accuracy: 0.9877 - val_loss: 0.0474 - val_accuracy: 0.9875\n",
      "Epoch 187/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0351 - accuracy: 0.9883 - val_loss: 0.0612 - val_accuracy: 0.9867\n",
      "Epoch 188/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0362 - accuracy: 0.9868 - val_loss: 0.0484 - val_accuracy: 0.9833\n",
      "Epoch 189/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0350 - accuracy: 0.9865 - val_loss: 0.0738 - val_accuracy: 0.9792\n",
      "Epoch 190/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0375 - accuracy: 0.9861 - val_loss: 0.0732 - val_accuracy: 0.9775\n",
      "Epoch 191/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0361 - accuracy: 0.9873 - val_loss: 0.0256 - val_accuracy: 0.9917\n",
      "Epoch 192/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0349 - accuracy: 0.9881 - val_loss: 0.1253 - val_accuracy: 0.9642\n",
      "Epoch 193/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0410 - accuracy: 0.9846 - val_loss: 0.0522 - val_accuracy: 0.9858\n",
      "Epoch 194/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0387 - accuracy: 0.9870 - val_loss: 0.0594 - val_accuracy: 0.9850\n",
      "Epoch 195/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0380 - accuracy: 0.9873 - val_loss: 0.0554 - val_accuracy: 0.9842\n",
      "Epoch 196/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0412 - accuracy: 0.9841 - val_loss: 0.0620 - val_accuracy: 0.9817\n",
      "Epoch 197/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0379 - accuracy: 0.9874 - val_loss: 0.0428 - val_accuracy: 0.9883\n",
      "Epoch 198/500\n",
      "358/375 [===========================>..] - ETA: 0s - loss: 0.0386 - accuracy: 0.9852INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0385 - accuracy: 0.9853 - val_loss: 0.0320 - val_accuracy: 0.9933\n",
      "Epoch 199/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0382 - accuracy: 0.9854 - val_loss: 0.0510 - val_accuracy: 0.9817\n",
      "Epoch 200/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0330 - accuracy: 0.9867 - val_loss: 0.1122 - val_accuracy: 0.9583\n",
      "Epoch 201/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0398 - accuracy: 0.9863 - val_loss: 0.0635 - val_accuracy: 0.9825\n",
      "Epoch 202/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0309 - accuracy: 0.9886 - val_loss: 0.0679 - val_accuracy: 0.9817\n",
      "Epoch 203/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0344 - accuracy: 0.9879 - val_loss: 0.0432 - val_accuracy: 0.9867\n",
      "Epoch 204/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0367 - accuracy: 0.9862 - val_loss: 0.0557 - val_accuracy: 0.9817\n",
      "Epoch 205/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0382 - accuracy: 0.9871 - val_loss: 0.0506 - val_accuracy: 0.9825\n",
      "Epoch 206/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0360 - accuracy: 0.9864 - val_loss: 0.0564 - val_accuracy: 0.9792\n",
      "Epoch 207/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0357 - accuracy: 0.9872 - val_loss: 0.0405 - val_accuracy: 0.9900\n",
      "Epoch 208/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0314 - accuracy: 0.9889 - val_loss: 0.0649 - val_accuracy: 0.9825\n",
      "Epoch 209/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0359 - accuracy: 0.9866 - val_loss: 0.0475 - val_accuracy: 0.9850\n",
      "Epoch 210/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0333 - accuracy: 0.9886 - val_loss: 0.1289 - val_accuracy: 0.9550\n",
      "Epoch 211/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0417 - accuracy: 0.9848 - val_loss: 0.0999 - val_accuracy: 0.9692\n",
      "Epoch 212/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0358 - accuracy: 0.9884 - val_loss: 0.0595 - val_accuracy: 0.9867\n",
      "Epoch 213/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0377 - accuracy: 0.9862 - val_loss: 0.0723 - val_accuracy: 0.9750\n",
      "Epoch 214/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0351 - accuracy: 0.9873 - val_loss: 0.0505 - val_accuracy: 0.9833\n",
      "Epoch 215/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0285 - accuracy: 0.9892 - val_loss: 0.0493 - val_accuracy: 0.9850\n",
      "Epoch 216/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0338 - accuracy: 0.9870 - val_loss: 0.0402 - val_accuracy: 0.9883\n",
      "Epoch 217/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0350 - accuracy: 0.9882 - val_loss: 0.0386 - val_accuracy: 0.9892\n",
      "Epoch 218/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0413 - accuracy: 0.9865 - val_loss: 0.0476 - val_accuracy: 0.9867\n",
      "Epoch 219/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0365 - accuracy: 0.9868 - val_loss: 0.0413 - val_accuracy: 0.9842\n",
      "Epoch 220/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0342 - accuracy: 0.9877 - val_loss: 0.0601 - val_accuracy: 0.9833\n",
      "Epoch 221/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0446 - accuracy: 0.9837 - val_loss: 0.0809 - val_accuracy: 0.9725\n",
      "Epoch 222/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0356 - accuracy: 0.9867 - val_loss: 0.0563 - val_accuracy: 0.9833\n",
      "Epoch 223/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0355 - accuracy: 0.9866 - val_loss: 0.0364 - val_accuracy: 0.9883\n",
      "Epoch 224/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0361 - accuracy: 0.9862 - val_loss: 0.0719 - val_accuracy: 0.9775\n",
      "Epoch 225/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0382 - accuracy: 0.9862 - val_loss: 0.1172 - val_accuracy: 0.9617\n",
      "Epoch 226/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0374 - accuracy: 0.9868 - val_loss: 0.0699 - val_accuracy: 0.9783\n",
      "Epoch 227/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0355 - accuracy: 0.9869 - val_loss: 0.0520 - val_accuracy: 0.9850\n",
      "Epoch 228/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0330 - accuracy: 0.9877 - val_loss: 0.0444 - val_accuracy: 0.9858\n",
      "Epoch 229/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0355 - accuracy: 0.9877 - val_loss: 0.0391 - val_accuracy: 0.9908\n",
      "Epoch 230/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0327 - accuracy: 0.9879 - val_loss: 0.0383 - val_accuracy: 0.9892\n",
      "Epoch 231/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0431 - accuracy: 0.9843 - val_loss: 0.0515 - val_accuracy: 0.9850\n",
      "Epoch 232/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0322 - accuracy: 0.9882 - val_loss: 0.0473 - val_accuracy: 0.9875\n",
      "Epoch 233/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0352 - accuracy: 0.9863 - val_loss: 0.0410 - val_accuracy: 0.9842\n",
      "Epoch 234/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0335 - accuracy: 0.9879 - val_loss: 0.0501 - val_accuracy: 0.9850\n",
      "Epoch 235/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0317 - accuracy: 0.9884 - val_loss: 0.0484 - val_accuracy: 0.9842\n",
      "Epoch 236/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0361 - accuracy: 0.9859 - val_loss: 0.0575 - val_accuracy: 0.9858\n",
      "Epoch 237/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0312 - accuracy: 0.9888 - val_loss: 0.0664 - val_accuracy: 0.9775\n",
      "Epoch 238/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0362 - accuracy: 0.9874 - val_loss: 0.0521 - val_accuracy: 0.9833\n",
      "Epoch 239/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0337 - accuracy: 0.9868 - val_loss: 0.1830 - val_accuracy: 0.9533\n",
      "Epoch 240/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0393 - accuracy: 0.9873 - val_loss: 0.0481 - val_accuracy: 0.9825\n",
      "Epoch 241/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0306 - accuracy: 0.9902 - val_loss: 0.0404 - val_accuracy: 0.9875\n",
      "Epoch 242/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0375 - accuracy: 0.9868 - val_loss: 0.0585 - val_accuracy: 0.9833\n",
      "Epoch 243/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0331 - accuracy: 0.9870 - val_loss: 0.0417 - val_accuracy: 0.9858\n",
      "Epoch 244/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0316 - accuracy: 0.9887 - val_loss: 0.0491 - val_accuracy: 0.9850\n",
      "Epoch 245/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0410 - accuracy: 0.9857 - val_loss: 0.0722 - val_accuracy: 0.9825\n",
      "Epoch 246/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0313 - accuracy: 0.9887 - val_loss: 0.0404 - val_accuracy: 0.9900\n",
      "Epoch 247/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0320 - accuracy: 0.9886 - val_loss: 0.0573 - val_accuracy: 0.9850\n",
      "Epoch 248/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0444 - accuracy: 0.9845 - val_loss: 0.0968 - val_accuracy: 0.9708\n",
      "Epoch 249/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0353 - accuracy: 0.9880 - val_loss: 0.0499 - val_accuracy: 0.9867\n",
      "Epoch 250/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0345 - accuracy: 0.9881 - val_loss: 0.0235 - val_accuracy: 0.9925\n",
      "Epoch 251/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0340 - accuracy: 0.9884 - val_loss: 0.0303 - val_accuracy: 0.9900\n",
      "Epoch 252/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0320 - accuracy: 0.9875 - val_loss: 0.0408 - val_accuracy: 0.9900\n",
      "Epoch 253/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0337 - accuracy: 0.9884 - val_loss: 0.0669 - val_accuracy: 0.9792\n",
      "Epoch 254/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0385 - accuracy: 0.9864 - val_loss: 0.0320 - val_accuracy: 0.9908\n",
      "Epoch 255/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0340 - accuracy: 0.9877 - val_loss: 0.0660 - val_accuracy: 0.9783\n",
      "Epoch 256/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0294 - accuracy: 0.9893 - val_loss: 0.0417 - val_accuracy: 0.9858\n",
      "Epoch 257/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0348 - accuracy: 0.9874 - val_loss: 0.0368 - val_accuracy: 0.9883\n",
      "Epoch 258/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0362 - accuracy: 0.9875 - val_loss: 0.0678 - val_accuracy: 0.9833\n",
      "Epoch 259/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0349 - accuracy: 0.9875 - val_loss: 0.0983 - val_accuracy: 0.9667\n",
      "Epoch 260/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0321 - accuracy: 0.9892 - val_loss: 0.0582 - val_accuracy: 0.9783\n",
      "Epoch 261/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0344 - accuracy: 0.9872 - val_loss: 0.0314 - val_accuracy: 0.9925\n",
      "Epoch 262/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0317 - accuracy: 0.9881 - val_loss: 0.0346 - val_accuracy: 0.9908\n",
      "Epoch 263/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0334 - accuracy: 0.9884 - val_loss: 0.0554 - val_accuracy: 0.9833\n",
      "Epoch 264/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0348 - accuracy: 0.9868 - val_loss: 0.0352 - val_accuracy: 0.9925\n",
      "Epoch 265/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0340 - accuracy: 0.9877 - val_loss: 0.1325 - val_accuracy: 0.9608\n",
      "Epoch 266/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0339 - accuracy: 0.9874 - val_loss: 0.0490 - val_accuracy: 0.9842\n",
      "Epoch 267/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0310 - accuracy: 0.9899 - val_loss: 0.0481 - val_accuracy: 0.9850\n",
      "Epoch 268/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0321 - accuracy: 0.9885 - val_loss: 0.0531 - val_accuracy: 0.9833\n",
      "Epoch 269/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0346 - accuracy: 0.9874 - val_loss: 0.0516 - val_accuracy: 0.9833\n",
      "Epoch 270/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0342 - accuracy: 0.9878 - val_loss: 0.1504 - val_accuracy: 0.9508\n",
      "Epoch 271/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0363 - accuracy: 0.9866 - val_loss: 0.0415 - val_accuracy: 0.9892\n",
      "Epoch 272/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0338 - accuracy: 0.9869 - val_loss: 0.0615 - val_accuracy: 0.9775\n",
      "Epoch 273/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0318 - accuracy: 0.9891 - val_loss: 0.1373 - val_accuracy: 0.9508\n",
      "Epoch 274/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0367 - accuracy: 0.9858 - val_loss: 0.1214 - val_accuracy: 0.9583\n",
      "Epoch 275/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0350 - accuracy: 0.9875 - val_loss: 0.0863 - val_accuracy: 0.9783\n",
      "Epoch 276/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0336 - accuracy: 0.9878 - val_loss: 0.0916 - val_accuracy: 0.9742\n",
      "Epoch 277/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0362 - accuracy: 0.9858 - val_loss: 0.0617 - val_accuracy: 0.9792\n",
      "Epoch 278/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0330 - accuracy: 0.9877 - val_loss: 0.0747 - val_accuracy: 0.9725\n",
      "Epoch 279/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0328 - accuracy: 0.9876 - val_loss: 0.0543 - val_accuracy: 0.9833\n",
      "Epoch 280/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0326 - accuracy: 0.9881 - val_loss: 0.0633 - val_accuracy: 0.9808\n",
      "Epoch 281/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0352 - accuracy: 0.9876 - val_loss: 0.0351 - val_accuracy: 0.9917\n",
      "Epoch 282/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0342 - accuracy: 0.9895 - val_loss: 0.0791 - val_accuracy: 0.9750\n",
      "Epoch 283/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0328 - accuracy: 0.9883 - val_loss: 0.0748 - val_accuracy: 0.9717\n",
      "Epoch 284/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0322 - accuracy: 0.9885 - val_loss: 0.0662 - val_accuracy: 0.9783\n",
      "Epoch 285/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0293 - accuracy: 0.9898 - val_loss: 0.0662 - val_accuracy: 0.9783\n",
      "Epoch 286/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0319 - accuracy: 0.9887 - val_loss: 0.0775 - val_accuracy: 0.9717\n",
      "Epoch 287/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0444 - accuracy: 0.9852 - val_loss: 0.0355 - val_accuracy: 0.9892\n",
      "Epoch 288/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0332 - accuracy: 0.9881 - val_loss: 0.0945 - val_accuracy: 0.9742\n",
      "Epoch 289/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0354 - accuracy: 0.9878 - val_loss: 0.0677 - val_accuracy: 0.9775\n",
      "Epoch 290/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0313 - accuracy: 0.9887 - val_loss: 0.0586 - val_accuracy: 0.9792\n",
      "Epoch 291/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0366 - accuracy: 0.9872 - val_loss: 0.0502 - val_accuracy: 0.9850\n",
      "Epoch 292/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0326 - accuracy: 0.9880 - val_loss: 0.0472 - val_accuracy: 0.9867\n",
      "Epoch 293/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0338 - accuracy: 0.9877 - val_loss: 0.0482 - val_accuracy: 0.9867\n",
      "Epoch 294/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0343 - accuracy: 0.9885 - val_loss: 0.0462 - val_accuracy: 0.9867\n",
      "Epoch 295/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0322 - accuracy: 0.9879 - val_loss: 0.0676 - val_accuracy: 0.9742\n",
      "Epoch 296/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0276 - accuracy: 0.9896 - val_loss: 0.0292 - val_accuracy: 0.9883\n",
      "Epoch 297/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0309 - accuracy: 0.9883 - val_loss: 0.0645 - val_accuracy: 0.9817\n",
      "Epoch 298/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0298 - accuracy: 0.9896 - val_loss: 0.0496 - val_accuracy: 0.9833\n",
      "Epoch 299/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0336 - accuracy: 0.9887 - val_loss: 0.0225 - val_accuracy: 0.9908\n",
      "Epoch 300/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0340 - accuracy: 0.9874 - val_loss: 0.1130 - val_accuracy: 0.9650\n",
      "Epoch 301/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0316 - accuracy: 0.9896 - val_loss: 0.0414 - val_accuracy: 0.9892\n",
      "Epoch 302/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0341 - accuracy: 0.9877 - val_loss: 0.0473 - val_accuracy: 0.9825\n",
      "Epoch 303/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0325 - accuracy: 0.9880 - val_loss: 0.0484 - val_accuracy: 0.9850\n",
      "Epoch 304/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0321 - accuracy: 0.9892 - val_loss: 0.0428 - val_accuracy: 0.9825\n",
      "Epoch 305/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0334 - accuracy: 0.9873 - val_loss: 0.0336 - val_accuracy: 0.9892\n",
      "Epoch 306/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0303 - accuracy: 0.9890 - val_loss: 0.0336 - val_accuracy: 0.9900\n",
      "Epoch 307/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0315 - accuracy: 0.9886 - val_loss: 0.0425 - val_accuracy: 0.9892\n",
      "Epoch 308/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0335 - accuracy: 0.9872 - val_loss: 0.0676 - val_accuracy: 0.9742\n",
      "Epoch 309/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0319 - accuracy: 0.9885 - val_loss: 0.0737 - val_accuracy: 0.9792\n",
      "Epoch 310/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0396 - accuracy: 0.9865 - val_loss: 0.0537 - val_accuracy: 0.9817\n",
      "Epoch 311/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0332 - accuracy: 0.9879 - val_loss: 0.0556 - val_accuracy: 0.9842\n",
      "Epoch 312/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0286 - accuracy: 0.9889 - val_loss: 0.0616 - val_accuracy: 0.9800\n",
      "Epoch 313/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0296 - accuracy: 0.9886 - val_loss: 0.0443 - val_accuracy: 0.9875\n",
      "Epoch 314/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0381 - accuracy: 0.9855 - val_loss: 0.0498 - val_accuracy: 0.9858\n",
      "Epoch 315/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0290 - accuracy: 0.9894 - val_loss: 0.0371 - val_accuracy: 0.9892\n",
      "Epoch 316/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0295 - accuracy: 0.9887 - val_loss: 0.0572 - val_accuracy: 0.9825\n",
      "Epoch 317/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0308 - accuracy: 0.9885 - val_loss: 0.0409 - val_accuracy: 0.9908\n",
      "Epoch 318/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0291 - accuracy: 0.9893 - val_loss: 0.0601 - val_accuracy: 0.9800\n",
      "Epoch 319/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0302 - accuracy: 0.9894 - val_loss: 0.0488 - val_accuracy: 0.9858\n",
      "Epoch 320/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0292 - accuracy: 0.9894 - val_loss: 0.0334 - val_accuracy: 0.9917\n",
      "Epoch 321/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0348 - accuracy: 0.9884 - val_loss: 0.0410 - val_accuracy: 0.9892\n",
      "Epoch 322/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0426 - accuracy: 0.9859 - val_loss: 0.0456 - val_accuracy: 0.9850\n",
      "Epoch 323/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0262 - accuracy: 0.9907 - val_loss: 0.0621 - val_accuracy: 0.9800\n",
      "Epoch 324/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0304 - accuracy: 0.9885 - val_loss: 0.0538 - val_accuracy: 0.9842\n",
      "Epoch 325/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0362 - accuracy: 0.9868 - val_loss: 0.0582 - val_accuracy: 0.9808\n",
      "Epoch 326/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0296 - accuracy: 0.9882 - val_loss: 0.0429 - val_accuracy: 0.9883\n",
      "Epoch 327/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0285 - accuracy: 0.9896 - val_loss: 0.0320 - val_accuracy: 0.9917\n",
      "Epoch 328/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0290 - accuracy: 0.9899 - val_loss: 0.0489 - val_accuracy: 0.9825\n",
      "Epoch 329/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0319 - accuracy: 0.9885 - val_loss: 0.0796 - val_accuracy: 0.9758\n",
      "Epoch 330/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0317 - accuracy: 0.9887 - val_loss: 0.0936 - val_accuracy: 0.9767\n",
      "Epoch 331/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0318 - accuracy: 0.9894 - val_loss: 0.0408 - val_accuracy: 0.9867\n",
      "Epoch 332/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0314 - accuracy: 0.9892 - val_loss: 0.0695 - val_accuracy: 0.9775\n",
      "Epoch 333/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0270 - accuracy: 0.9896 - val_loss: 0.1373 - val_accuracy: 0.9617\n",
      "Epoch 334/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0300 - accuracy: 0.9892 - val_loss: 0.0531 - val_accuracy: 0.9800\n",
      "Epoch 335/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0275 - accuracy: 0.9899 - val_loss: 0.0282 - val_accuracy: 0.9900\n",
      "Epoch 336/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0290 - accuracy: 0.9893 - val_loss: 0.0370 - val_accuracy: 0.9892\n",
      "Epoch 337/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0334 - accuracy: 0.9883 - val_loss: 0.1194 - val_accuracy: 0.9617\n",
      "Epoch 338/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0309 - accuracy: 0.9893 - val_loss: 0.0405 - val_accuracy: 0.9900\n",
      "Epoch 339/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0296 - accuracy: 0.9887 - val_loss: 0.0891 - val_accuracy: 0.9750\n",
      "Epoch 340/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0389 - accuracy: 0.9855 - val_loss: 0.1150 - val_accuracy: 0.9633\n",
      "Epoch 341/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0322 - accuracy: 0.9878 - val_loss: 0.0794 - val_accuracy: 0.9742\n",
      "Epoch 342/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0290 - accuracy: 0.9898 - val_loss: 0.0509 - val_accuracy: 0.9817\n",
      "Epoch 343/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0294 - accuracy: 0.9899 - val_loss: 0.1023 - val_accuracy: 0.9650\n",
      "Epoch 344/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0283 - accuracy: 0.9894 - val_loss: 0.0427 - val_accuracy: 0.9842\n",
      "Epoch 345/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0340 - accuracy: 0.9872 - val_loss: 0.1200 - val_accuracy: 0.9667\n",
      "Epoch 346/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0301 - accuracy: 0.9884 - val_loss: 0.1371 - val_accuracy: 0.9567\n",
      "Epoch 347/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0361 - accuracy: 0.9877 - val_loss: 0.0305 - val_accuracy: 0.9900\n",
      "Epoch 348/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0309 - accuracy: 0.9889 - val_loss: 0.1290 - val_accuracy: 0.9692\n",
      "Epoch 349/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0343 - accuracy: 0.9879 - val_loss: 0.0586 - val_accuracy: 0.9833\n",
      "Epoch 350/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0279 - accuracy: 0.9897 - val_loss: 0.0863 - val_accuracy: 0.9750\n",
      "Epoch 351/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0309 - accuracy: 0.9891 - val_loss: 0.0755 - val_accuracy: 0.9742\n",
      "Epoch 352/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0297 - accuracy: 0.9892 - val_loss: 0.0955 - val_accuracy: 0.9725\n",
      "Epoch 353/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0271 - accuracy: 0.9904 - val_loss: 0.1324 - val_accuracy: 0.9567\n",
      "Epoch 354/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0347 - accuracy: 0.9866 - val_loss: 0.0664 - val_accuracy: 0.9808\n",
      "Epoch 355/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0305 - accuracy: 0.9887 - val_loss: 0.0473 - val_accuracy: 0.9817\n",
      "Epoch 356/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0289 - accuracy: 0.9899 - val_loss: 0.0644 - val_accuracy: 0.9775\n",
      "Epoch 357/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0362 - accuracy: 0.9869 - val_loss: 0.0766 - val_accuracy: 0.9792\n",
      "Epoch 358/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0310 - accuracy: 0.9886 - val_loss: 0.0815 - val_accuracy: 0.9692\n",
      "Epoch 359/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0342 - accuracy: 0.9871 - val_loss: 0.0764 - val_accuracy: 0.9792\n",
      "Epoch 360/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0291 - accuracy: 0.9883 - val_loss: 0.0989 - val_accuracy: 0.9733\n",
      "Epoch 361/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0299 - accuracy: 0.9894 - val_loss: 0.0711 - val_accuracy: 0.9767\n",
      "Epoch 362/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0310 - accuracy: 0.9885 - val_loss: 0.0613 - val_accuracy: 0.9792\n",
      "Epoch 363/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0266 - accuracy: 0.9905 - val_loss: 0.1655 - val_accuracy: 0.9600\n",
      "Epoch 364/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0307 - accuracy: 0.9890 - val_loss: 0.0559 - val_accuracy: 0.9883\n",
      "Epoch 365/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0386 - accuracy: 0.9862 - val_loss: 0.1200 - val_accuracy: 0.9642\n",
      "Epoch 366/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0279 - accuracy: 0.9889 - val_loss: 0.0563 - val_accuracy: 0.9833\n",
      "Epoch 367/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0395 - accuracy: 0.9854 - val_loss: 0.0761 - val_accuracy: 0.9733\n",
      "Epoch 368/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0286 - accuracy: 0.9902 - val_loss: 0.0631 - val_accuracy: 0.9792\n",
      "Epoch 369/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0269 - accuracy: 0.9902 - val_loss: 0.0845 - val_accuracy: 0.9733\n",
      "Epoch 370/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0266 - accuracy: 0.9902 - val_loss: 0.1156 - val_accuracy: 0.9642\n",
      "Epoch 371/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0312 - accuracy: 0.9877 - val_loss: 0.0470 - val_accuracy: 0.9817\n",
      "Epoch 372/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0275 - accuracy: 0.9902 - val_loss: 0.0786 - val_accuracy: 0.9717\n",
      "Epoch 373/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0307 - accuracy: 0.9882 - val_loss: 0.0951 - val_accuracy: 0.9700\n",
      "Epoch 374/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0302 - accuracy: 0.9893 - val_loss: 0.0799 - val_accuracy: 0.9742\n",
      "Epoch 375/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0297 - accuracy: 0.9897 - val_loss: 0.1540 - val_accuracy: 0.9492\n",
      "Epoch 376/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0297 - accuracy: 0.9898 - val_loss: 0.0486 - val_accuracy: 0.9850\n",
      "Epoch 377/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0281 - accuracy: 0.9892 - val_loss: 0.1279 - val_accuracy: 0.9558\n",
      "Epoch 378/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0317 - accuracy: 0.9886 - val_loss: 0.0534 - val_accuracy: 0.9850\n",
      "Epoch 379/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0280 - accuracy: 0.9908 - val_loss: 0.1181 - val_accuracy: 0.9617\n",
      "Epoch 380/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0321 - accuracy: 0.9890 - val_loss: 0.0678 - val_accuracy: 0.9808\n",
      "Epoch 381/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0286 - accuracy: 0.9891 - val_loss: 0.0865 - val_accuracy: 0.9700\n",
      "Epoch 382/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0367 - accuracy: 0.9873 - val_loss: 0.1135 - val_accuracy: 0.9667\n",
      "Epoch 383/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0321 - accuracy: 0.9889 - val_loss: 0.0628 - val_accuracy: 0.9800\n",
      "Epoch 384/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0266 - accuracy: 0.9907 - val_loss: 0.0658 - val_accuracy: 0.9800\n",
      "Epoch 385/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0265 - accuracy: 0.9904 - val_loss: 0.0466 - val_accuracy: 0.9833\n",
      "Epoch 386/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0329 - accuracy: 0.9883 - val_loss: 0.1373 - val_accuracy: 0.9583\n",
      "Epoch 387/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0286 - accuracy: 0.9892 - val_loss: 0.0390 - val_accuracy: 0.9883\n",
      "Epoch 388/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0323 - accuracy: 0.9888 - val_loss: 0.1122 - val_accuracy: 0.9708\n",
      "Epoch 389/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0298 - accuracy: 0.9889 - val_loss: 0.0765 - val_accuracy: 0.9767\n",
      "Epoch 390/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0303 - accuracy: 0.9889 - val_loss: 0.4070 - val_accuracy: 0.9092\n",
      "Epoch 391/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0302 - accuracy: 0.9892 - val_loss: 0.1169 - val_accuracy: 0.9525\n",
      "Epoch 392/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0342 - accuracy: 0.9880 - val_loss: 0.0936 - val_accuracy: 0.9650\n",
      "Epoch 393/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0287 - accuracy: 0.9898 - val_loss: 0.0445 - val_accuracy: 0.9867\n",
      "Epoch 394/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0335 - accuracy: 0.9872 - val_loss: 0.0463 - val_accuracy: 0.9867\n",
      "Epoch 395/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0281 - accuracy: 0.9898 - val_loss: 0.1056 - val_accuracy: 0.9625\n",
      "Epoch 396/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0292 - accuracy: 0.9893 - val_loss: 0.1186 - val_accuracy: 0.9567\n",
      "Epoch 397/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0263 - accuracy: 0.9899 - val_loss: 0.1138 - val_accuracy: 0.9658\n",
      "Epoch 398/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0280 - accuracy: 0.9889 - val_loss: 0.1072 - val_accuracy: 0.9700\n",
      "Epoch 399/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0332 - accuracy: 0.9884 - val_loss: 0.0708 - val_accuracy: 0.9800\n",
      "Epoch 400/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0266 - accuracy: 0.9896 - val_loss: 0.1554 - val_accuracy: 0.9492\n",
      "Epoch 401/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0288 - accuracy: 0.9894 - val_loss: 0.0571 - val_accuracy: 0.9817\n",
      "Epoch 402/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0285 - accuracy: 0.9897 - val_loss: 0.0678 - val_accuracy: 0.9767\n",
      "Epoch 403/500\n",
      "362/375 [===========================>..] - ETA: 0s - loss: 0.0281 - accuracy: 0.9890INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0280 - accuracy: 0.9889 - val_loss: 0.0263 - val_accuracy: 0.9950\n",
      "Epoch 404/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0309 - accuracy: 0.9881 - val_loss: 0.1427 - val_accuracy: 0.9500\n",
      "Epoch 405/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0268 - accuracy: 0.9907 - val_loss: 0.0390 - val_accuracy: 0.9850\n",
      "Epoch 406/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0362 - accuracy: 0.9861 - val_loss: 0.0482 - val_accuracy: 0.9875\n",
      "Epoch 407/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0299 - accuracy: 0.9886 - val_loss: 0.0912 - val_accuracy: 0.9775\n",
      "Epoch 408/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0334 - accuracy: 0.9883 - val_loss: 0.0875 - val_accuracy: 0.9767\n",
      "Epoch 409/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0324 - accuracy: 0.9890 - val_loss: 0.0942 - val_accuracy: 0.9700\n",
      "Epoch 410/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0287 - accuracy: 0.9897 - val_loss: 0.0554 - val_accuracy: 0.9825\n",
      "Epoch 411/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0244 - accuracy: 0.9910 - val_loss: 0.0342 - val_accuracy: 0.9917\n",
      "Epoch 412/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0300 - accuracy: 0.9892 - val_loss: 0.0446 - val_accuracy: 0.9842\n",
      "Epoch 413/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0266 - accuracy: 0.9897 - val_loss: 0.1835 - val_accuracy: 0.9433\n",
      "Epoch 414/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0261 - accuracy: 0.9899 - val_loss: 0.0693 - val_accuracy: 0.9775\n",
      "Epoch 415/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0264 - accuracy: 0.9903 - val_loss: 0.0712 - val_accuracy: 0.9792\n",
      "Epoch 416/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0307 - accuracy: 0.9887 - val_loss: 0.1503 - val_accuracy: 0.9575\n",
      "Epoch 417/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0284 - accuracy: 0.9885 - val_loss: 0.0766 - val_accuracy: 0.9758\n",
      "Epoch 418/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0331 - accuracy: 0.9877 - val_loss: 0.0417 - val_accuracy: 0.9917\n",
      "Epoch 419/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0305 - accuracy: 0.9882 - val_loss: 0.1153 - val_accuracy: 0.9667\n",
      "Epoch 420/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0272 - accuracy: 0.9903 - val_loss: 0.0641 - val_accuracy: 0.9783\n",
      "Epoch 421/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0277 - accuracy: 0.9899 - val_loss: 0.0800 - val_accuracy: 0.9750\n",
      "Epoch 422/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0257 - accuracy: 0.9898 - val_loss: 0.0627 - val_accuracy: 0.9808\n",
      "Epoch 423/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0279 - accuracy: 0.9897 - val_loss: 0.1130 - val_accuracy: 0.9633\n",
      "Epoch 424/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0322 - accuracy: 0.9872 - val_loss: 0.0556 - val_accuracy: 0.9867\n",
      "Epoch 425/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0266 - accuracy: 0.9901 - val_loss: 0.0700 - val_accuracy: 0.9792\n",
      "Epoch 426/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0339 - accuracy: 0.9882 - val_loss: 0.0986 - val_accuracy: 0.9700\n",
      "Epoch 427/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0295 - accuracy: 0.9893 - val_loss: 0.0703 - val_accuracy: 0.9792\n",
      "Epoch 428/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0282 - accuracy: 0.9893 - val_loss: 0.0719 - val_accuracy: 0.9792\n",
      "Epoch 429/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0266 - accuracy: 0.9902 - val_loss: 0.0716 - val_accuracy: 0.9783\n",
      "Epoch 430/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0318 - accuracy: 0.9896 - val_loss: 0.1095 - val_accuracy: 0.9692\n",
      "Epoch 431/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0293 - accuracy: 0.9900 - val_loss: 0.0545 - val_accuracy: 0.9892\n",
      "Epoch 432/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0278 - accuracy: 0.9908 - val_loss: 0.0350 - val_accuracy: 0.9883\n",
      "Epoch 433/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0281 - accuracy: 0.9905 - val_loss: 0.1625 - val_accuracy: 0.9425\n",
      "Epoch 434/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0280 - accuracy: 0.9904 - val_loss: 0.1506 - val_accuracy: 0.9542\n",
      "Epoch 435/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0318 - accuracy: 0.9884 - val_loss: 0.1187 - val_accuracy: 0.9650\n",
      "Epoch 436/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0290 - accuracy: 0.9891 - val_loss: 0.1236 - val_accuracy: 0.9717\n",
      "Epoch 437/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0310 - accuracy: 0.9893 - val_loss: 0.0624 - val_accuracy: 0.9817\n",
      "Epoch 438/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0268 - accuracy: 0.9904 - val_loss: 0.0830 - val_accuracy: 0.9808\n",
      "Epoch 439/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0283 - accuracy: 0.9890 - val_loss: 0.0547 - val_accuracy: 0.9833\n",
      "Epoch 440/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0291 - accuracy: 0.9903 - val_loss: 0.1196 - val_accuracy: 0.9642\n",
      "Epoch 441/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0293 - accuracy: 0.9893 - val_loss: 0.0610 - val_accuracy: 0.9825\n",
      "Epoch 442/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0340 - accuracy: 0.9877 - val_loss: 0.3372 - val_accuracy: 0.9142\n",
      "Epoch 443/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0276 - accuracy: 0.9898 - val_loss: 0.0734 - val_accuracy: 0.9750\n",
      "Epoch 444/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0301 - accuracy: 0.9890 - val_loss: 0.0543 - val_accuracy: 0.9792\n",
      "Epoch 445/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0304 - accuracy: 0.9901 - val_loss: 0.0723 - val_accuracy: 0.9817\n",
      "Epoch 446/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0293 - accuracy: 0.9896 - val_loss: 0.0714 - val_accuracy: 0.9775\n",
      "Epoch 447/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0308 - accuracy: 0.9899 - val_loss: 0.0619 - val_accuracy: 0.9767\n",
      "Epoch 448/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0318 - accuracy: 0.9900 - val_loss: 0.1561 - val_accuracy: 0.9642\n",
      "Epoch 449/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0328 - accuracy: 0.9896 - val_loss: 0.0589 - val_accuracy: 0.9800\n",
      "Epoch 450/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0239 - accuracy: 0.9907 - val_loss: 0.0473 - val_accuracy: 0.9867\n",
      "Epoch 451/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0275 - accuracy: 0.9898 - val_loss: 0.0606 - val_accuracy: 0.9808\n",
      "Epoch 452/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0254 - accuracy: 0.9907 - val_loss: 0.1508 - val_accuracy: 0.9650\n",
      "Epoch 453/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0265 - accuracy: 0.9902 - val_loss: 0.0733 - val_accuracy: 0.9783\n",
      "Epoch 454/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0299 - accuracy: 0.9899 - val_loss: 0.0988 - val_accuracy: 0.9658\n",
      "Epoch 455/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0275 - accuracy: 0.9895 - val_loss: 0.0380 - val_accuracy: 0.9883\n",
      "Epoch 456/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0260 - accuracy: 0.9915 - val_loss: 0.0860 - val_accuracy: 0.9717\n",
      "Epoch 457/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0337 - accuracy: 0.9878 - val_loss: 0.0717 - val_accuracy: 0.9808\n",
      "Epoch 458/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0274 - accuracy: 0.9901 - val_loss: 0.1026 - val_accuracy: 0.9633\n",
      "Epoch 459/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0242 - accuracy: 0.9910 - val_loss: 0.0781 - val_accuracy: 0.9758\n",
      "Epoch 460/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0251 - accuracy: 0.9909 - val_loss: 0.1265 - val_accuracy: 0.9575\n",
      "Epoch 461/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0306 - accuracy: 0.9896 - val_loss: 0.2047 - val_accuracy: 0.9425\n",
      "Epoch 462/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0318 - accuracy: 0.9884 - val_loss: 0.1012 - val_accuracy: 0.9667\n",
      "Epoch 463/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0251 - accuracy: 0.9915 - val_loss: 0.1662 - val_accuracy: 0.9500\n",
      "Epoch 464/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0274 - accuracy: 0.9909 - val_loss: 0.0574 - val_accuracy: 0.9883\n",
      "Epoch 465/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0330 - accuracy: 0.9884 - val_loss: 0.0988 - val_accuracy: 0.9658\n",
      "Epoch 466/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0267 - accuracy: 0.9912 - val_loss: 0.1465 - val_accuracy: 0.9642\n",
      "Epoch 467/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0312 - accuracy: 0.9888 - val_loss: 0.0865 - val_accuracy: 0.9700\n",
      "Epoch 468/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0344 - accuracy: 0.9873 - val_loss: 0.0488 - val_accuracy: 0.9833\n",
      "Epoch 469/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0244 - accuracy: 0.9913 - val_loss: 0.0997 - val_accuracy: 0.9667\n",
      "Epoch 470/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0264 - accuracy: 0.9902 - val_loss: 0.0520 - val_accuracy: 0.9833\n",
      "Epoch 471/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0342 - accuracy: 0.9873 - val_loss: 0.0574 - val_accuracy: 0.9825\n",
      "Epoch 472/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0280 - accuracy: 0.9897 - val_loss: 0.0436 - val_accuracy: 0.9858\n",
      "Epoch 473/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0252 - accuracy: 0.9916 - val_loss: 0.0782 - val_accuracy: 0.9792\n",
      "Epoch 474/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0302 - accuracy: 0.9888 - val_loss: 0.1022 - val_accuracy: 0.9717\n",
      "Epoch 475/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0246 - accuracy: 0.9910 - val_loss: 0.1037 - val_accuracy: 0.9683\n",
      "Epoch 476/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0256 - accuracy: 0.9906 - val_loss: 0.0613 - val_accuracy: 0.9808\n",
      "Epoch 477/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0248 - accuracy: 0.9918 - val_loss: 0.0803 - val_accuracy: 0.9767\n",
      "Epoch 478/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0250 - accuracy: 0.9908 - val_loss: 0.1777 - val_accuracy: 0.9550\n",
      "Epoch 479/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0315 - accuracy: 0.9893 - val_loss: 0.0605 - val_accuracy: 0.9808\n",
      "Epoch 480/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0288 - accuracy: 0.9899 - val_loss: 0.0544 - val_accuracy: 0.9867\n",
      "Epoch 481/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0304 - accuracy: 0.9891 - val_loss: 0.0966 - val_accuracy: 0.9700\n",
      "Epoch 482/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0296 - accuracy: 0.9894 - val_loss: 0.0916 - val_accuracy: 0.9750\n",
      "Epoch 483/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0272 - accuracy: 0.9899 - val_loss: 0.0419 - val_accuracy: 0.9883\n",
      "Epoch 484/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0317 - accuracy: 0.9890 - val_loss: 0.0769 - val_accuracy: 0.9783\n",
      "Epoch 485/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0294 - accuracy: 0.9895 - val_loss: 0.0740 - val_accuracy: 0.9792\n",
      "Epoch 486/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0301 - accuracy: 0.9901 - val_loss: 0.0653 - val_accuracy: 0.9808\n",
      "Epoch 487/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0269 - accuracy: 0.9902 - val_loss: 0.0908 - val_accuracy: 0.9733\n",
      "Epoch 488/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0245 - accuracy: 0.9908 - val_loss: 0.0435 - val_accuracy: 0.9883\n",
      "Epoch 489/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0292 - accuracy: 0.9899 - val_loss: 0.0540 - val_accuracy: 0.9858\n",
      "Epoch 490/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0290 - accuracy: 0.9904 - val_loss: 0.0550 - val_accuracy: 0.9825\n",
      "Epoch 491/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0333 - accuracy: 0.9882 - val_loss: 0.1158 - val_accuracy: 0.9683\n",
      "Epoch 492/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0237 - accuracy: 0.9917 - val_loss: 0.1238 - val_accuracy: 0.9608\n",
      "Epoch 493/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0266 - accuracy: 0.9902 - val_loss: 0.1039 - val_accuracy: 0.9683\n",
      "Epoch 494/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0251 - accuracy: 0.9913 - val_loss: 0.0942 - val_accuracy: 0.9733\n",
      "Epoch 495/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0266 - accuracy: 0.9905 - val_loss: 0.0522 - val_accuracy: 0.9867\n",
      "Epoch 496/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0255 - accuracy: 0.9912 - val_loss: 0.1299 - val_accuracy: 0.9608\n",
      "Epoch 497/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0294 - accuracy: 0.9897 - val_loss: 0.0538 - val_accuracy: 0.9858\n",
      "Epoch 498/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0246 - accuracy: 0.9901 - val_loss: 0.0744 - val_accuracy: 0.9725\n",
      "Epoch 499/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0282 - accuracy: 0.9904 - val_loss: 0.0959 - val_accuracy: 0.9717\n",
      "Epoch 500/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0270 - accuracy: 0.9905 - val_loss: 0.0675 - val_accuracy: 0.9808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ipykernel_launcher:7: MatplotlibDeprecationWarning: Unrecognized location 'upperleft'. Falling back on 'best'; valid locations are\n",
      "\tbest\n",
      "\tupper right\n",
      "\tupper left\n",
      "\tlower left\n",
      "\tlower right\n",
      "\tright\n",
      "\tcenter left\n",
      "\tcenter right\n",
      "\tlower center\n",
      "\tupper center\n",
      "\tcenter\n",
      "This will raise an exception in 3.3.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history2 = training(X_n, Y_s, test_X = test_X_n, test_Y = test_Y_s, EPOCHS = 500, cp_filepath='./normalization')\n",
    "plotting(history2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9908333420753479\n"
     ]
    }
   ],
   "source": [
    "print(max(history1.history['val_accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9950000047683716\n"
     ]
    }
   ],
   "source": [
    "print(max(history2.history['val_accuracy']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dbaacea5468811a017cc0f00a46fb9836d3190ef101d6642ac152db43eb38baa"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('radar')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
