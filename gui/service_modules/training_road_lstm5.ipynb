{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import copy\n",
    "from math import pi\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from pandas import DataFrame as DF\n",
    "from models import AP_ResNet, ResNet, VGG_branch, ResNetLSTM, ConvLSTM, ConvLSTM_dropout\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "from classifier import preprocessing as prep\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['asphalt','bicycle','block','floor','ground']\n",
    "bound = 414"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(matrix,title):\n",
    "    df=DF(matrix, index = class_names, columns = class_names)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    sns.heatmap(df, annot=True)\n",
    "    plt.tick_params(axis='x', top=True, labeltop = True,bottom=False, labelbottom=False)\n",
    "    plt.xticks(np.arange(0.5, len(df.columns), 1), df.columns)\n",
    "    plt.yticks(np.arange(0.5, len(df.index), 1), df.index)\n",
    "    plt.xlabel(\"Prediction\",position = (0.5,1.0+0.05))\n",
    "    plt.ylabel(\"Object\")\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2idx_Dict = {\n",
    "                'asphalt' : 0,\n",
    "                'bicycle' : 1,\n",
    "                'block' : 2,\n",
    "                'floor' : 3,\n",
    "                'ground' : 4,\n",
    "            }\n",
    "\n",
    "idx2label_Dict = {\n",
    "    0 : 'asphalt',\n",
    "    1 : 'bicycle',\n",
    "    2 : 'block',\n",
    "    3 : 'floor',\n",
    "    4 : 'ground',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = './road_data'\n",
    "def readNpy(dir_path):\n",
    "    class_num = len(idx2label_Dict)\n",
    "\n",
    "    Asphalt = list()\n",
    "    Bicycle = list()\n",
    "    Block = list()\n",
    "    Floor = list()\n",
    "    Ground = list()\n",
    "    Asphalt = np.array(Asphalt)\n",
    "    Bicycle = np.array(Bicycle)\n",
    "    Block = np.array(Block)\n",
    "    Floor = np.array(Floor)\n",
    "    Ground = np.array(Ground)\n",
    "    \n",
    "\n",
    "    for dir in os.listdir(dir_path):\n",
    "        d_path = os.path.join(dir_path, dir)\n",
    "        file_list = os.listdir(d_path)\n",
    "        for file in file_list:\n",
    "            file_path = os.path.join(d_path, file)\n",
    "            if dir == idx2label_Dict[0] :\n",
    "                if len(Asphalt) == 0:\n",
    "                    Asphalt = np.load(file_path, allow_pickle=True)\n",
    "                else :\n",
    "                    Asphalt = np.append(Asphalt, np.load(file_path), axis = 0)\n",
    "            elif dir == idx2label_Dict[1]:\n",
    "                if len(Bicycle) == 0:\n",
    "                    Bicycle = np.load(file_path, allow_pickle=True)\n",
    "                else :\n",
    "                    Bicycle = np.append(Bicycle, np.load(file_path), axis = 0)\n",
    "            elif dir == idx2label_Dict[2]:\n",
    "                if len(Block) == 0:\n",
    "                    Block = np.load(file_path, allow_pickle=True)\n",
    "                else:\n",
    "                    Block = np.append(Block, np.load(file_path), axis = 0)\n",
    "            elif dir == idx2label_Dict[3]:\n",
    "                if len(Floor) == 0:\n",
    "                    Floor = np.load(file_path, allow_pickle=True)\n",
    "                else:\n",
    "                    Floor = np.append(Floor, np.load(file_path), axis = 0)\n",
    "            elif dir == idx2label_Dict[4]:\n",
    "                if len(Ground) == 0:\n",
    "                    Ground = np.load(file_path, allow_pickle=True)\n",
    "                else:\n",
    "                    Ground = np.append(Ground, np.load(file_path), axis = 0)\n",
    "\n",
    "    bound = Asphalt.shape[1]\n",
    "\n",
    "    Ground_label = np.full((Ground.shape[0], class_num), np.eye(len(label2idx_Dict))[label2idx_Dict['ground']])\n",
    "    Asphalt_label = np.full((Asphalt.shape[0],class_num), np.eye(len(label2idx_Dict))[label2idx_Dict['asphalt']])\n",
    "    Bicycle_label = np.full((Bicycle.shape[0],class_num), np.eye(len(label2idx_Dict))[label2idx_Dict['bicycle']])\n",
    "    Block_label = np.full((Block.shape[0],class_num), np.eye(len(label2idx_Dict))[label2idx_Dict['block']])\n",
    "    Floor_label = np.full((Floor.shape[0],class_num), np.eye(len(label2idx_Dict))[label2idx_Dict['floor']])\n",
    "\n",
    "    Ground = np.concatenate((Ground, Ground_label), axis=1)\n",
    "    Asphalt = np.concatenate((Asphalt, Asphalt_label), axis=1)\n",
    "    Bicycle = np.concatenate((Bicycle, Bicycle_label), axis=1)\n",
    "    Block = np.concatenate((Block, Block_label), axis=1)\n",
    "    Floor = np.concatenate((Floor, Floor_label), axis=1)\n",
    "    \n",
    "    array = Asphalt\n",
    "    array = np.append(array, Bicycle, axis = 0)\n",
    "    array = np.append(array, Block, axis = 0)\n",
    "    array = np.append(array, Floor, axis = 0)\n",
    "    array = np.append(array, Ground, axis = 0)\n",
    "    s = np.arange(array.shape[0])\n",
    "    np.random.shuffle(s)\n",
    "    array_s = array[s]\n",
    "\n",
    "    X = array_s[:,:bound]\n",
    "    Y = np.real(array_s[:,bound:])\n",
    "    return copy.deepcopy(X), copy.deepcopy(Y)\n",
    "\n",
    "X, y = readNpy(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperater(arr):\n",
    "    # global maximum\n",
    "    pre_data = arr\n",
    "    amp = np.abs(pre_data)\n",
    "    # amp = amp / maximum\n",
    "    phs = np.angle(pre_data)\n",
    "    # phs = (phs - (- pi)) / (pi - (- pi))\n",
    "    sin = np.sin(phs)\n",
    "    sin = (sin + 1) / 2\n",
    "    seperated_data = np.stack((amp.T,sin.T), axis=0)\n",
    "    seperated_data = np.expand_dims(seperated_data, axis=0)\n",
    "    return np.array(seperated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataSeperator(arr):\n",
    "    temp = copy.deepcopy(seperater(arr[0]))\n",
    "    for i in range(1, len(arr)):\n",
    "        temp = np.concatenate((temp, seperater(arr[i])), axis=0)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Split_X = dataSeperator(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = 'road_detection_lstm'\n",
    "callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = './model/' + checkpoint_filepath,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only = True,\n",
    "    save_weigths_only = False,\n",
    ")\n",
    "log_dir = './logs/fit/'\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = log_dir, histogram_freq = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for i in range(len(data[0])-seq_length-1):\n",
    "        x = data[0][:][i:(i+seq_length)]\n",
    "        y = data[1][i+seq_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 10\n",
    "X, Y = create_sequences((Split_X, y), seq_length = seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2389, 10, 2, 414) (2389, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model, X, Y,\n",
    "    # test_X, test_Y, \n",
    "    batch_size = 64, history_dict = None\n",
    "    ):\n",
    "    Epoch = 1\n",
    "    callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath = './model/' + 'Resnet_LSTM',\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        save_best_only = True,\n",
    "        save_weigths_only = False,\n",
    "    )\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "    model.compile(optimizer = optimizer , loss = loss, \n",
    "                metrics = ['accuracy', 'categorical_crossentropy'])\n",
    "    history = model.fit(X, Y,  batch_size = batch_size, epochs = Epoch,\n",
    "                callbacks = callback, \n",
    "                # validation_data = (test_X, test_Y),\n",
    "                validation_split = 0.3\n",
    "                )\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[:, :, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_len = 100\n",
    "train_X, test_X = X[:-100], X[-100:]\n",
    "train_Y, test_Y = Y[:-100], Y[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2289, 10, 414) (100, 10, 414) (2289, 5) (100, 5)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape, test_X.shape, train_Y.shape, test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-15 07:08:26.009292: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8301\n",
      "2022-08-15 07:08:27.547109: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - ETA: 0s - loss: 4.9791 - accuracy: 0.2117 - categorical_crossentropy: 4.9791INFO:tensorflow:Assets written to: ./model/Resnet_LSTM/assets\n",
      "53/53 [==============================] - 34s 475ms/step - loss: 4.9791 - accuracy: 0.2117 - categorical_crossentropy: 4.9791 - val_loss: 1.5985 - val_accuracy: 0.2483 - val_categorical_crossentropy: 1.5985\n"
     ]
    }
   ],
   "source": [
    "cl_model = ConvLSTM_dropout()\n",
    "history = train(cl_model, X, Y, batch_size = 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"conv_lstm_dropout_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv_lstm1d_9 (ConvLSTM1D)  multiple                  50176     \n",
      "                                                                 \n",
      " conv_lstm1d_10 (ConvLSTM1D)  multiple                 295424    \n",
      "                                                                 \n",
      " conv_lstm1d_11 (ConvLSTM1D)  multiple                 1180672   \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  multiple                 256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  multiple                 512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  multiple                 1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         multiple                  0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             multiple                  108528640 \n",
      "                                                                 \n",
      " dense_10 (Dense)            multiple                  524800    \n",
      "                                                                 \n",
      " dense_11 (Dense)            multiple                  2565      \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 110,584,069\n",
      "Trainable params: 110,583,173\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. 셀의 코드를 검토하여 오류의 가능한 원인을 식별하세요. 자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'> 여기 </a> 를 클릭하세요. 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "cl_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_rate = dict()\n",
    "for i in range(8):\n",
    "    dropout = i / 10\n",
    "    print(dropout)\n",
    "    model_amp = ResNet(dropout = dropout)\n",
    "    history = train(model_amp, Split_X, y)\n",
    "    dropout_rate[dropout] = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dropout_rate[0.0].history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(dropout_rate[0.0].history['val_accuracy']))\n",
    "print(np.max(dropout_rate[0.1].history['val_accuracy']))\n",
    "print(np.max(dropout_rate[0.2].history['val_accuracy']))\n",
    "print(np.max(dropout_rate[0.3].history['val_accuracy']))\n",
    "print(np.max(dropout_rate[0.4].history['val_accuracy']))\n",
    "print(np.max(dropout_rate[0.5].history['val_accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNetLSTM()\n",
    "history = train(model, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('radar')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dea347e98226a0e23d2c967d9a0ab2a62ac04f9a7895aa5011026f33e6be1d75"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
