{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import copy\n",
    "from math import pi\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 208)\n",
      "(30, 208)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Can = list()\n",
    "Paper = list()\n",
    "Glass = list()\n",
    "Plastic = list()\n",
    "Can = np.array(Can)\n",
    "Paper = np.array(Paper)\n",
    "Glass = np.array(Glass)\n",
    "Plastic = np.array(Plastic)\n",
    "\n",
    "Can_test = copy.deepcopy(Can)\n",
    "Paper_test = copy.deepcopy(Paper)\n",
    "Plastic_test = copy.deepcopy(Plastic)\n",
    "Glass_test = copy.deepcopy(Glass)\n",
    "\n",
    "\n",
    "Class = 4\n",
    "\n",
    "lableDict = {\n",
    "                'can' : 0,\n",
    "                'paper' : 1,\n",
    "                'glass' : 2,\n",
    "                'plastic' : 3,\n",
    "            }\n",
    "\n",
    "test = np.zeros(4)\n",
    "\n",
    "def Label2Idx(label):\n",
    "    idx = np.zeros(4)\n",
    "    idx[label] = 1\n",
    "    return idx\n",
    "\n",
    "dir_path = './data/train'\n",
    "test_dir_path = './data/test'\n",
    "\n",
    "def readNpy(dir_path, Can, Paper, Glass, Plastic):\n",
    "    for dir in os.listdir(dir_path):\n",
    "        d_path = os.path.join(dir_path, dir)\n",
    "        file_list = os.listdir(d_path)\n",
    "        for file in file_list:\n",
    "            file_path = os.path.join(d_path, file)\n",
    "            if dir == 'can':\n",
    "                if len(Can) == 0:\n",
    "                    Can = np.load(file_path)\n",
    "                else :\n",
    "                    Can = np.append(Can, np.load(file_path), axis = 0)\n",
    "            elif dir == 'paper':\n",
    "                if len(Paper) == 0:\n",
    "                    Paper = np.load(file_path)\n",
    "                else :\n",
    "                    Paper = np.append(Paper, np.load(file_path), axis = 0)\n",
    "            elif dir == 'glass':\n",
    "                if len(Glass) == 0:\n",
    "                    Glass = np.load(file_path)\n",
    "                else:\n",
    "                    Glass = np.append(Glass, np.load(file_path), axis = 0)\n",
    "            elif dir == 'plastic':\n",
    "                if len(Plastic) == 0:\n",
    "                    Plastic = np.load(file_path)\n",
    "                else:\n",
    "                    Plastic = np.append(Plastic, np.load(file_path), axis = 0)\n",
    "    \n",
    "    # Can = np.append(Can, Can_label, axis=1)\n",
    "    # Paper = np.append(Paper, Paper_label, axis=1)\n",
    "    # Glass = np.append(Glass, Glass_label, axis=1)\n",
    "    # Plastic = np.append(Plastic, Plastic_label, axis=1\n",
    "    # print(Can)\n",
    "    # Can = np.expand_dims(Can, axis=0)\n",
    "    # Paper = np.expand_dims(Paper, axis=0)\n",
    "    # Glass = np.expand_dims(Glass, axis=0)\n",
    "    # Plastic = np.expand_dims(Plastic, axis=0)\n",
    "    print(Can.shape)\n",
    "\n",
    "    Can_label = np.tile(np.array([1, 0, 0, 0]), reps=[Can.shape[0], 1])\n",
    "    Paper_label = np.tile(np.array([0, 1, 0, 0]), reps=[Paper.shape[0], 1])\n",
    "    Glass_label = np.tile(np.array([0, 0, 1, 0]), reps=[Glass.shape[0], 1])\n",
    "    Plastic_label = np.tile(np.array([0, 0, 0, 1]), reps=[Plastic.shape[0], 1])\n",
    "    # print(Can_label)\n",
    "    \n",
    "\n",
    "    label_arr = np.append(Can_label, Paper_label, axis = 0)\n",
    "    label_arr = np.append(label_arr, Glass_label, axis = 0)\n",
    "    label_arr = np.append(label_arr, Plastic_label, axis = 0)\n",
    "\n",
    "    # print(label_arr)\n",
    "\n",
    "    array = list()\n",
    "    array = np.array(array)\n",
    "    array = Can\n",
    "    # array = np.append(Can,[Plastic, Glass, Plastic], axis = 0)\n",
    "    # array = np.append(array, Can)\n",
    "    array = np.append(array, Paper, axis = 0)\n",
    "    array = np.append(array, Glass, axis = 0)\n",
    "    array = np.append(array, Plastic, axis = 0)\n",
    "    return array, label_arr\n",
    "\n",
    "Data, Label= readNpy(dir_path, Can, Paper, Glass, Plastic)\n",
    "# print(Data)\n",
    "# Data_len = Data.shape[1]\n",
    "# Can_label = np.expand_dims(np.full((Data_len, Class), Label2Idx(lableDict['can']), dtype='int'),axis=0)\n",
    "# Paper_label = np.expand_dims(np.full((Data_len, Class), Label2Idx(lableDict['paper']), dtype='int'), axis=0)\n",
    "# Glass_label = np.expand_dims(np.full((Data_len, Class), Label2Idx(lableDict['glass']), dtype='int'), axis=0)\n",
    "# Plastic_label = np.expand_dims(np.full((Data_len, Class), Label2Idx(lableDict['plastic']), dtype='int'), axis=0)\n",
    "\n",
    "test_Data, test_Label= readNpy(test_dir_path, Can_test, Paper_test, Glass_test, Plastic_test)\n",
    "# test_Data_len = test_Data.shape[1]\n",
    "# test_Can_label = np.expand_dims(np.full((test_Data_len, Class), Label2Idx(lableDict['can']), dtype='int'),axis=0)\n",
    "# test_Paper_label = np.expand_dims(np.full((test_Data_len, Class), Label2Idx(lableDict['paper']), dtype='int'), axis=0)\n",
    "# test_Glass_label = np.expand_dims(np.full((test_Data_len, Class), Label2Idx(lableDict['glass']), dtype='int'), axis=0)\n",
    "# test_Plastic_label = np.expand_dims(np.full((test_Data_len, Class), Label2Idx(lableDict['plastic']), dtype='int'), axis=0)\n",
    "\n",
    "# Label = np.append(Can_label, Paper_label, axis=0)\n",
    "# Label = np.append(Label, Glass_label, axis=0)\n",
    "# Label = np.append(Label, Plastic_label, axis=0)\n",
    "\n",
    "# test_Label = np.append(test_Can_label, test_Paper_label, axis=0)\n",
    "# test_Label = np.append(test_Label, test_Glass_label, axis=0)\n",
    "# test_Label = np.append(test_Label, test_Plastic_label, axis=0)\n",
    "\n",
    "X = Data\n",
    "# Y = np.reshape(Label, (-1, Label.shape[2]))\n",
    "Y = Label\n",
    "\n",
    "test_X = test_Data\n",
    "test_Y = test_Label\n",
    "\n",
    "# print(X.shape)\n",
    "# print(Y.shape)\n",
    "s = np.arange(X.shape[0])\n",
    "np.random.shuffle(s)\n",
    "X_s = X[s]\n",
    "Y_s = Y[s]\n",
    "\n",
    "test_s = np.arange(test_X.shape[0])\n",
    "np.random.shuffle(test_s)\n",
    "test_X_s = test_X[test_s]\n",
    "test_Y_s = test_Y[test_s]\n",
    "# test_X_s = X_s\n",
    "# test_Y_s = Y_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_X = np.mean(X, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(X, Y, test_X, test_Y, EPOCHS, cp_filepath):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv1D(6, (3), activation = 'relu', input_shape=(X.shape[1], 1)))\n",
    "    # model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Conv1D(16, (3), activation = 'relu'))\n",
    "    # model.add(layers.Dropout(0.2))\n",
    "    # model.add(layers.Conv1D(64, (3), activation = 'relu'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(4, activation='softmax'))\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])\n",
    "    checkpoint_filepath = cp_filepath\n",
    "\n",
    "    callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath = checkpoint_filepath,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        save_best_only = True,\n",
    "        save_weigths_only = False,\n",
    "\n",
    "    )\n",
    "\n",
    "    return model.fit(X, Y, epochs=EPOCHS, validation_data = (test_X, test_Y), callbacks=[callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2846.9073817038725\n",
      "3.141592653589793\n"
     ]
    }
   ],
   "source": [
    "print(np.max(np.abs(X_s)))\n",
    "print(np.max(np.angle(X_s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperater(queue):\n",
    "    data = list()\n",
    "    data = np.arrya(data)\n",
    "    while True:\n",
    "        pre_data = queue.pop\n",
    "        amp = np.abs(pre_data)\n",
    "        amp = amp / 2847\n",
    "        phs = np.angle(pre_data)\n",
    "        phs = (phs - (- pi)) / (pi - (- pi))\n",
    "        seperated_data = np.append(amp, phs, axis = 0)\n",
    "        return np.array(seperated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting(history):\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(['Train', 'Test'], loc='upperleft')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_8 (Conv1D)           (None, 412, 6)            24        \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 410, 16)           304       \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 6560)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4)                 26244     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,572\n",
      "Trainable params: 26,572\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "  5/338 [..............................] - ETA: 5s - loss: 146.4796 - accuracy: 0.2562  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 20:40:07.777876: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338/338 [==============================] - ETA: 0s - loss: 11.0490 - accuracy: 0.5418"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 20:40:11.229965: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./non_normalization/assets\n",
      "338/338 [==============================] - 4s 11ms/step - loss: 11.0490 - accuracy: 0.5418 - val_loss: 23.9970 - val_accuracy: 0.2733\n",
      "Epoch 2/30\n",
      "338/338 [==============================] - 3s 10ms/step - loss: 1.0227 - accuracy: 0.6884 - val_loss: 17.1418 - val_accuracy: 0.1442\n",
      "Epoch 3/30\n",
      "337/338 [============================>.] - ETA: 0s - loss: 0.6882 - accuracy: 0.7528INFO:tensorflow:Assets written to: ./non_normalization/assets\n",
      "338/338 [==============================] - 3s 10ms/step - loss: 0.6877 - accuracy: 0.7531 - val_loss: 13.0832 - val_accuracy: 0.3100\n",
      "Epoch 4/30\n",
      "338/338 [==============================] - 3s 10ms/step - loss: 0.5470 - accuracy: 0.7809 - val_loss: 12.1226 - val_accuracy: 0.1667\n",
      "Epoch 5/30\n",
      "338/338 [==============================] - 3s 9ms/step - loss: 0.4891 - accuracy: 0.8060 - val_loss: 11.0183 - val_accuracy: 0.2325\n",
      "Epoch 6/30\n",
      "338/338 [==============================] - 3s 9ms/step - loss: 0.4517 - accuracy: 0.8219 - val_loss: 11.3787 - val_accuracy: 0.2892\n",
      "Epoch 7/30\n",
      "338/338 [==============================] - 3s 10ms/step - loss: 0.5105 - accuracy: 0.8228 - val_loss: 11.6208 - val_accuracy: 0.1408\n",
      "Epoch 8/30\n",
      "338/338 [==============================] - 3s 9ms/step - loss: 0.4206 - accuracy: 0.8396 - val_loss: 11.7335 - val_accuracy: 0.2142\n",
      "Epoch 9/30\n",
      "338/338 [==============================] - 3s 9ms/step - loss: 0.4083 - accuracy: 0.8474 - val_loss: 12.8078 - val_accuracy: 0.2850\n",
      "Epoch 10/30\n",
      "335/338 [============================>.] - ETA: 0s - loss: 0.3690 - accuracy: 0.8605INFO:tensorflow:Assets written to: ./non_normalization/assets\n",
      "338/338 [==============================] - 3s 10ms/step - loss: 0.3685 - accuracy: 0.8606 - val_loss: 11.3031 - val_accuracy: 0.3283\n",
      "Epoch 11/30\n",
      "338/338 [==============================] - 3s 10ms/step - loss: 0.3229 - accuracy: 0.8776 - val_loss: 12.9955 - val_accuracy: 0.2950\n",
      "Epoch 12/30\n",
      "338/338 [==============================] - 3s 9ms/step - loss: 0.3280 - accuracy: 0.8786 - val_loss: 11.6981 - val_accuracy: 0.3033\n",
      "Epoch 13/30\n",
      "338/338 [==============================] - 3s 10ms/step - loss: 0.3263 - accuracy: 0.8757 - val_loss: 12.9045 - val_accuracy: 0.3117\n",
      "Epoch 14/30\n",
      "338/338 [==============================] - 3s 9ms/step - loss: 0.2890 - accuracy: 0.8925 - val_loss: 13.0552 - val_accuracy: 0.2950\n",
      "Epoch 15/30\n",
      "338/338 [==============================] - 3s 9ms/step - loss: 0.2892 - accuracy: 0.8905 - val_loss: 14.3873 - val_accuracy: 0.3008\n",
      "Epoch 16/30\n",
      "338/338 [==============================] - 3s 10ms/step - loss: 0.2786 - accuracy: 0.8935 - val_loss: 12.1219 - val_accuracy: 0.3108\n",
      "Epoch 17/30\n",
      "338/338 [==============================] - 3s 9ms/step - loss: 0.2963 - accuracy: 0.8883 - val_loss: 13.5258 - val_accuracy: 0.3175\n",
      "Epoch 18/30\n",
      "338/338 [==============================] - 3s 9ms/step - loss: 0.2673 - accuracy: 0.9004 - val_loss: 13.8220 - val_accuracy: 0.3100\n",
      "Epoch 19/30\n",
      "338/338 [==============================] - 3s 9ms/step - loss: 0.2755 - accuracy: 0.8961 - val_loss: 14.9220 - val_accuracy: 0.2875\n",
      "Epoch 20/30\n",
      "338/338 [==============================] - 3s 10ms/step - loss: 0.2655 - accuracy: 0.9013 - val_loss: 12.0231 - val_accuracy: 0.3000\n",
      "Epoch 21/30\n",
      "338/338 [==============================] - 4s 13ms/step - loss: 0.2492 - accuracy: 0.9037 - val_loss: 13.8186 - val_accuracy: 0.3058\n",
      "Epoch 22/30\n",
      "338/338 [==============================] - 3s 10ms/step - loss: 0.2744 - accuracy: 0.8977 - val_loss: 14.7804 - val_accuracy: 0.2983\n",
      "Epoch 23/30\n",
      "338/338 [==============================] - 4s 11ms/step - loss: 0.2518 - accuracy: 0.9056 - val_loss: 14.3249 - val_accuracy: 0.3000\n",
      "Epoch 24/30\n",
      "338/338 [==============================] - 3s 9ms/step - loss: 0.2313 - accuracy: 0.9158 - val_loss: 15.9371 - val_accuracy: 0.2983\n",
      "Epoch 25/30\n",
      "338/338 [==============================] - 3s 9ms/step - loss: 0.2332 - accuracy: 0.9151 - val_loss: 13.1817 - val_accuracy: 0.3075\n",
      "Epoch 26/30\n",
      "338/338 [==============================] - 3s 9ms/step - loss: 0.2275 - accuracy: 0.9165 - val_loss: 14.2249 - val_accuracy: 0.2975\n",
      "Epoch 27/30\n",
      "338/338 [==============================] - 3s 9ms/step - loss: 0.3333 - accuracy: 0.8845 - val_loss: 13.0211 - val_accuracy: 0.3075\n",
      "Epoch 28/30\n",
      "338/338 [==============================] - 3s 9ms/step - loss: 0.4233 - accuracy: 0.8379 - val_loss: 14.0680 - val_accuracy: 0.2867\n",
      "Epoch 29/30\n",
      "338/338 [==============================] - 3s 9ms/step - loss: 0.3596 - accuracy: 0.8582 - val_loss: 12.0402 - val_accuracy: 0.2942\n",
      "Epoch 30/30\n",
      "338/338 [==============================] - 4s 12ms/step - loss: 0.3284 - accuracy: 0.8810 - val_loss: 14.1052 - val_accuracy: 0.2850\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'upperleft' is not a valid value for loc; supported values are 'best', 'upper right', 'upper left', 'lower left', 'lower right', 'right', 'center left', 'center right', 'lower center', 'upper center', 'center'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cs/n7lxyhm16zn37_l0t4m0jrhr0000gn/T/ipykernel_55681/65475412.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhistory1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_X_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_Y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_Y_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcp_filepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./non_normalization'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplotting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/cs/n7lxyhm16zn37_l0t4m0jrhr0000gn/T/ipykernel_55681/2085578841.py\u001b[0m in \u001b[0;36mplotting\u001b[0;34m(history)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'upperleft'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/radar/lib/python3.9/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mlegend\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2653\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2654\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2655\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/radar/lib/python3.9/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mlegend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextra_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'legend only accepts two non-keyword arguments'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlegend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_remove_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_remove_legend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/radar/lib/python3.9/site-packages/matplotlib/legend.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, parent, handles, labels, loc, numpoints, markerscale, markerfirst, scatterpoints, scatteryoffsets, prop, fontsize, labelcolor, borderpad, labelspacing, handlelength, handleheight, handletextpad, borderaxespad, columnspacing, ncol, mode, fancybox, shadow, title, title_fontsize, framealpha, edgecolor, facecolor, bbox_to_anchor, bbox_transform, frameon, handler_map, title_fontproperties)\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'upper right'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_getitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misaxes\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mloc\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             raise ValueError(\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/radar/lib/python3.9/site-packages/matplotlib/_api/__init__.py\u001b[0m in \u001b[0;36mcheck_getitem\u001b[0;34m(_mapping, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    189\u001b[0m             \u001b[0;34m\"{!r} is not a valid value for {}; supported values are {}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             .format(v, k, ', '.join(map(repr, mapping)))) from None\n",
      "\u001b[0;31mValueError\u001b[0m: 'upperleft' is not a valid value for loc; supported values are 'best', 'upper right', 'upper left', 'lower left', 'lower right', 'right', 'center left', 'center right', 'lower center', 'upper center', 'center'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history1 = training(X_s, Y_s, test_X=test_X_s, test_Y=test_Y_s, EPOCHS = 30, cp_filepath='./non_normalization')\n",
    "plotting(history1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum = np.max(X_s)\n",
    "X_n = X_s/maximum #normalization\n",
    "test_X_n = test_X_s/maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3131+1255j)\n"
     ]
    }
   ],
   "source": [
    "print(maximum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_3 (Conv1D)           (None, 412, 32)           128       \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 412, 32)           0         \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 410, 64)           6208      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 410, 64)           0         \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 408, 64)           12352     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 26112)             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 104452    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 123,140\n",
      "Trainable params: 123,140\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "357/375 [===========================>..] - ETA: 0s - loss: 0.6779 - accuracy: 0.7055INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6606 - accuracy: 0.7132 - val_loss: 0.4708 - val_accuracy: 0.7917\n",
      "Epoch 2/500\n",
      "365/375 [============================>.] - ETA: 0s - loss: 0.2973 - accuracy: 0.8883INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2951 - accuracy: 0.8892 - val_loss: 0.4213 - val_accuracy: 0.8258\n",
      "Epoch 3/500\n",
      "363/375 [============================>.] - ETA: 0s - loss: 0.1994 - accuracy: 0.9320INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1983 - accuracy: 0.9325 - val_loss: 0.2951 - val_accuracy: 0.8725\n",
      "Epoch 4/500\n",
      "368/375 [============================>.] - ETA: 0s - loss: 0.1556 - accuracy: 0.9455INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1554 - accuracy: 0.9456 - val_loss: 0.2587 - val_accuracy: 0.9058\n",
      "Epoch 5/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1549 - accuracy: 0.9480 - val_loss: 0.3985 - val_accuracy: 0.8733\n",
      "Epoch 6/500\n",
      "359/375 [===========================>..] - ETA: 0s - loss: 0.1342 - accuracy: 0.9560INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1337 - accuracy: 0.9562 - val_loss: 0.1613 - val_accuracy: 0.9350\n",
      "Epoch 7/500\n",
      "355/375 [===========================>..] - ETA: 0s - loss: 0.1185 - accuracy: 0.9607INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1230 - accuracy: 0.9601 - val_loss: 0.1437 - val_accuracy: 0.9458\n",
      "Epoch 8/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1209 - accuracy: 0.9613 - val_loss: 0.1785 - val_accuracy: 0.9242\n",
      "Epoch 9/500\n",
      "360/375 [===========================>..] - ETA: 0s - loss: 0.1160 - accuracy: 0.9632INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1139 - accuracy: 0.9638 - val_loss: 0.1449 - val_accuracy: 0.9500\n",
      "Epoch 10/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0989 - accuracy: 0.9678 - val_loss: 0.1552 - val_accuracy: 0.9408\n",
      "Epoch 11/500\n",
      "359/375 [===========================>..] - ETA: 0s - loss: 0.0996 - accuracy: 0.9658INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1028 - accuracy: 0.9653 - val_loss: 0.1086 - val_accuracy: 0.9592\n",
      "Epoch 12/500\n",
      "362/375 [===========================>..] - ETA: 0s - loss: 0.0922 - accuracy: 0.9695INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0934 - accuracy: 0.9687 - val_loss: 0.0975 - val_accuracy: 0.9667\n",
      "Epoch 13/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0937 - accuracy: 0.9678 - val_loss: 0.2439 - val_accuracy: 0.9125\n",
      "Epoch 14/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0984 - accuracy: 0.9681 - val_loss: 0.2814 - val_accuracy: 0.9167\n",
      "Epoch 15/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0924 - accuracy: 0.9688 - val_loss: 0.1317 - val_accuracy: 0.9467\n",
      "Epoch 16/500\n",
      "364/375 [============================>.] - ETA: 0s - loss: 0.0887 - accuracy: 0.9712INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0886 - accuracy: 0.9708 - val_loss: 0.0862 - val_accuracy: 0.9700\n",
      "Epoch 17/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0921 - accuracy: 0.9692 - val_loss: 0.1120 - val_accuracy: 0.9608\n",
      "Epoch 18/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0824 - accuracy: 0.9718 - val_loss: 0.1508 - val_accuracy: 0.9492\n",
      "Epoch 19/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0947 - accuracy: 0.9670 - val_loss: 0.1172 - val_accuracy: 0.9608\n",
      "Epoch 20/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0793 - accuracy: 0.9729 - val_loss: 0.0986 - val_accuracy: 0.9650\n",
      "Epoch 21/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0774 - accuracy: 0.9719 - val_loss: 0.1371 - val_accuracy: 0.9467\n",
      "Epoch 22/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0841 - accuracy: 0.9729 - val_loss: 0.1019 - val_accuracy: 0.9608\n",
      "Epoch 23/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0698 - accuracy: 0.9769 - val_loss: 0.1020 - val_accuracy: 0.9633\n",
      "Epoch 24/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0735 - accuracy: 0.9750 - val_loss: 0.0948 - val_accuracy: 0.9683\n",
      "Epoch 25/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0732 - accuracy: 0.9762 - val_loss: 0.1116 - val_accuracy: 0.9642\n",
      "Epoch 26/500\n",
      "367/375 [============================>.] - ETA: 0s - loss: 0.0730 - accuracy: 0.9753INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0727 - accuracy: 0.9753 - val_loss: 0.0754 - val_accuracy: 0.9717\n",
      "Epoch 27/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0819 - accuracy: 0.9727 - val_loss: 0.0877 - val_accuracy: 0.9642\n",
      "Epoch 28/500\n",
      "367/375 [============================>.] - ETA: 0s - loss: 0.0740 - accuracy: 0.9739INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0739 - accuracy: 0.9739 - val_loss: 0.0863 - val_accuracy: 0.9733\n",
      "Epoch 29/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0675 - accuracy: 0.9768 - val_loss: 0.1381 - val_accuracy: 0.9558\n",
      "Epoch 30/500\n",
      "365/375 [============================>.] - ETA: 0s - loss: 0.0697 - accuracy: 0.9756INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0699 - accuracy: 0.9757 - val_loss: 0.0714 - val_accuracy: 0.9758\n",
      "Epoch 31/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0683 - accuracy: 0.9752 - val_loss: 0.1162 - val_accuracy: 0.9592\n",
      "Epoch 32/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0704 - accuracy: 0.9759 - val_loss: 0.1072 - val_accuracy: 0.9592\n",
      "Epoch 33/500\n",
      "370/375 [============================>.] - ETA: 0s - loss: 0.0698 - accuracy: 0.9774INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0696 - accuracy: 0.9774 - val_loss: 0.0738 - val_accuracy: 0.9783\n",
      "Epoch 34/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0656 - accuracy: 0.9766 - val_loss: 0.1026 - val_accuracy: 0.9650\n",
      "Epoch 35/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0651 - accuracy: 0.9769 - val_loss: 0.1058 - val_accuracy: 0.9633\n",
      "Epoch 36/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0658 - accuracy: 0.9779 - val_loss: 0.1106 - val_accuracy: 0.9633\n",
      "Epoch 37/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0640 - accuracy: 0.9787 - val_loss: 0.1351 - val_accuracy: 0.9600\n",
      "Epoch 38/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0648 - accuracy: 0.9777 - val_loss: 0.1003 - val_accuracy: 0.9733\n",
      "Epoch 39/500\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0623 - accuracy: 0.9783INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0623 - accuracy: 0.9783 - val_loss: 0.0574 - val_accuracy: 0.9800\n",
      "Epoch 40/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0636 - accuracy: 0.9778 - val_loss: 0.1040 - val_accuracy: 0.9675\n",
      "Epoch 41/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0640 - accuracy: 0.9771 - val_loss: 0.0774 - val_accuracy: 0.9742\n",
      "Epoch 42/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0599 - accuracy: 0.9794 - val_loss: 0.0684 - val_accuracy: 0.9783\n",
      "Epoch 43/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0608 - accuracy: 0.9791 - val_loss: 0.0807 - val_accuracy: 0.9767\n",
      "Epoch 44/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0613 - accuracy: 0.9787 - val_loss: 0.1228 - val_accuracy: 0.9617\n",
      "Epoch 45/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0670 - accuracy: 0.9767 - val_loss: 0.1291 - val_accuracy: 0.9575\n",
      "Epoch 46/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0600 - accuracy: 0.9801 - val_loss: 0.1082 - val_accuracy: 0.9600\n",
      "Epoch 47/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0608 - accuracy: 0.9793 - val_loss: 0.0765 - val_accuracy: 0.9717\n",
      "Epoch 48/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0573 - accuracy: 0.9806 - val_loss: 0.0935 - val_accuracy: 0.9658\n",
      "Epoch 49/500\n",
      "359/375 [===========================>..] - ETA: 0s - loss: 0.0562 - accuracy: 0.9807INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0564 - accuracy: 0.9805 - val_loss: 0.0600 - val_accuracy: 0.9808\n",
      "Epoch 50/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0615 - accuracy: 0.9780 - val_loss: 0.0949 - val_accuracy: 0.9717\n",
      "Epoch 51/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0599 - accuracy: 0.9787 - val_loss: 0.0741 - val_accuracy: 0.9758\n",
      "Epoch 52/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0579 - accuracy: 0.9797 - val_loss: 0.1193 - val_accuracy: 0.9567\n",
      "Epoch 53/500\n",
      "370/375 [============================>.] - ETA: 0s - loss: 0.0576 - accuracy: 0.9799INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0570 - accuracy: 0.9802 - val_loss: 0.0547 - val_accuracy: 0.9817\n",
      "Epoch 54/500\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.0582 - accuracy: 0.9800INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0580 - accuracy: 0.9800 - val_loss: 0.0512 - val_accuracy: 0.9825\n",
      "Epoch 55/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0572 - accuracy: 0.9803 - val_loss: 0.1316 - val_accuracy: 0.9575\n",
      "Epoch 56/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0562 - accuracy: 0.9817 - val_loss: 0.0877 - val_accuracy: 0.9750\n",
      "Epoch 57/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0571 - accuracy: 0.9799 - val_loss: 0.0555 - val_accuracy: 0.9825\n",
      "Epoch 58/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0504 - accuracy: 0.9822 - val_loss: 0.0808 - val_accuracy: 0.9708\n",
      "Epoch 59/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0579 - accuracy: 0.9795 - val_loss: 0.1217 - val_accuracy: 0.9617\n",
      "Epoch 60/500\n",
      "365/375 [============================>.] - ETA: 0s - loss: 0.0533 - accuracy: 0.9817INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0530 - accuracy: 0.9817 - val_loss: 0.0547 - val_accuracy: 0.9858\n",
      "Epoch 61/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0575 - accuracy: 0.9802 - val_loss: 0.0585 - val_accuracy: 0.9817\n",
      "Epoch 62/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0509 - accuracy: 0.9824 - val_loss: 0.0847 - val_accuracy: 0.9742\n",
      "Epoch 63/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0558 - accuracy: 0.9798 - val_loss: 0.0759 - val_accuracy: 0.9783\n",
      "Epoch 64/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0532 - accuracy: 0.9822 - val_loss: 0.0918 - val_accuracy: 0.9675\n",
      "Epoch 65/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0534 - accuracy: 0.9808 - val_loss: 0.0836 - val_accuracy: 0.9750\n",
      "Epoch 66/500\n",
      "367/375 [============================>.] - ETA: 0s - loss: 0.0562 - accuracy: 0.9798INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0556 - accuracy: 0.9800 - val_loss: 0.0402 - val_accuracy: 0.9875\n",
      "Epoch 67/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0508 - accuracy: 0.9827 - val_loss: 0.0582 - val_accuracy: 0.9817\n",
      "Epoch 68/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0590 - accuracy: 0.9790 - val_loss: 0.0624 - val_accuracy: 0.9825\n",
      "Epoch 69/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0501 - accuracy: 0.9827 - val_loss: 0.1266 - val_accuracy: 0.9583\n",
      "Epoch 70/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0552 - accuracy: 0.9797 - val_loss: 0.0864 - val_accuracy: 0.9767\n",
      "Epoch 71/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0526 - accuracy: 0.9817 - val_loss: 0.0526 - val_accuracy: 0.9850\n",
      "Epoch 72/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0479 - accuracy: 0.9820 - val_loss: 0.0942 - val_accuracy: 0.9733\n",
      "Epoch 73/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0496 - accuracy: 0.9820 - val_loss: 0.0982 - val_accuracy: 0.9675\n",
      "Epoch 74/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0465 - accuracy: 0.9835 - val_loss: 0.0904 - val_accuracy: 0.9775\n",
      "Epoch 75/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0515 - accuracy: 0.9811 - val_loss: 0.1215 - val_accuracy: 0.9592\n",
      "Epoch 76/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0598 - accuracy: 0.9792 - val_loss: 0.0687 - val_accuracy: 0.9808\n",
      "Epoch 77/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0535 - accuracy: 0.9804 - val_loss: 0.0785 - val_accuracy: 0.9733\n",
      "Epoch 78/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0489 - accuracy: 0.9827 - val_loss: 0.0462 - val_accuracy: 0.9867\n",
      "Epoch 79/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0525 - accuracy: 0.9803 - val_loss: 0.1229 - val_accuracy: 0.9650\n",
      "Epoch 80/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0491 - accuracy: 0.9818 - val_loss: 0.0562 - val_accuracy: 0.9792\n",
      "Epoch 81/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0561 - accuracy: 0.9803 - val_loss: 0.0739 - val_accuracy: 0.9800\n",
      "Epoch 82/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0455 - accuracy: 0.9836 - val_loss: 0.0511 - val_accuracy: 0.9867\n",
      "Epoch 83/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0482 - accuracy: 0.9833 - val_loss: 0.0994 - val_accuracy: 0.9717\n",
      "Epoch 84/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0507 - accuracy: 0.9824 - val_loss: 0.0593 - val_accuracy: 0.9867\n",
      "Epoch 85/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0466 - accuracy: 0.9835 - val_loss: 0.0595 - val_accuracy: 0.9808\n",
      "Epoch 86/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0477 - accuracy: 0.9828 - val_loss: 0.0839 - val_accuracy: 0.9733\n",
      "Epoch 87/500\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.0508 - accuracy: 0.9832INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0506 - accuracy: 0.9833 - val_loss: 0.0312 - val_accuracy: 0.9900\n",
      "Epoch 88/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0499 - accuracy: 0.9811 - val_loss: 0.0449 - val_accuracy: 0.9892\n",
      "Epoch 89/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0436 - accuracy: 0.9858 - val_loss: 0.0734 - val_accuracy: 0.9758\n",
      "Epoch 90/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0464 - accuracy: 0.9837 - val_loss: 0.0623 - val_accuracy: 0.9817\n",
      "Epoch 91/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0464 - accuracy: 0.9847 - val_loss: 0.0526 - val_accuracy: 0.9825\n",
      "Epoch 92/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0465 - accuracy: 0.9835 - val_loss: 0.0841 - val_accuracy: 0.9758\n",
      "Epoch 93/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0505 - accuracy: 0.9822 - val_loss: 0.0595 - val_accuracy: 0.9808\n",
      "Epoch 94/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0484 - accuracy: 0.9836 - val_loss: 0.0552 - val_accuracy: 0.9833\n",
      "Epoch 95/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0500 - accuracy: 0.9823 - val_loss: 0.0818 - val_accuracy: 0.9758\n",
      "Epoch 96/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0501 - accuracy: 0.9818 - val_loss: 0.0886 - val_accuracy: 0.9725\n",
      "Epoch 97/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0434 - accuracy: 0.9838 - val_loss: 0.0439 - val_accuracy: 0.9875\n",
      "Epoch 98/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0493 - accuracy: 0.9834 - val_loss: 0.0544 - val_accuracy: 0.9842\n",
      "Epoch 99/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0505 - accuracy: 0.9820 - val_loss: 0.0536 - val_accuracy: 0.9850\n",
      "Epoch 100/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0464 - accuracy: 0.9833 - val_loss: 0.0688 - val_accuracy: 0.9808\n",
      "Epoch 101/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0401 - accuracy: 0.9843 - val_loss: 0.0874 - val_accuracy: 0.9750\n",
      "Epoch 102/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0450 - accuracy: 0.9830 - val_loss: 0.0720 - val_accuracy: 0.9767\n",
      "Epoch 103/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0445 - accuracy: 0.9828 - val_loss: 0.0677 - val_accuracy: 0.9750\n",
      "Epoch 104/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0446 - accuracy: 0.9850 - val_loss: 0.0859 - val_accuracy: 0.9692\n",
      "Epoch 105/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0474 - accuracy: 0.9837 - val_loss: 0.0382 - val_accuracy: 0.9867\n",
      "Epoch 106/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0443 - accuracy: 0.9838 - val_loss: 0.2014 - val_accuracy: 0.9450\n",
      "Epoch 107/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0462 - accuracy: 0.9834 - val_loss: 0.0488 - val_accuracy: 0.9875\n",
      "Epoch 108/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0437 - accuracy: 0.9840 - val_loss: 0.0768 - val_accuracy: 0.9792\n",
      "Epoch 109/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0448 - accuracy: 0.9844 - val_loss: 0.0680 - val_accuracy: 0.9792\n",
      "Epoch 110/500\n",
      "369/375 [============================>.] - ETA: 0s - loss: 0.0488 - accuracy: 0.9825INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0487 - accuracy: 0.9825 - val_loss: 0.0372 - val_accuracy: 0.9917\n",
      "Epoch 111/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0412 - accuracy: 0.9850 - val_loss: 0.1012 - val_accuracy: 0.9725\n",
      "Epoch 112/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0423 - accuracy: 0.9846 - val_loss: 0.0513 - val_accuracy: 0.9858\n",
      "Epoch 113/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0453 - accuracy: 0.9839 - val_loss: 0.0784 - val_accuracy: 0.9733\n",
      "Epoch 114/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0431 - accuracy: 0.9857 - val_loss: 0.0512 - val_accuracy: 0.9867\n",
      "Epoch 115/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0477 - accuracy: 0.9825 - val_loss: 0.1428 - val_accuracy: 0.9575\n",
      "Epoch 116/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0428 - accuracy: 0.9847 - val_loss: 0.0705 - val_accuracy: 0.9808\n",
      "Epoch 117/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0410 - accuracy: 0.9850 - val_loss: 0.0524 - val_accuracy: 0.9850\n",
      "Epoch 118/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0413 - accuracy: 0.9851 - val_loss: 0.0558 - val_accuracy: 0.9858\n",
      "Epoch 119/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0403 - accuracy: 0.9860 - val_loss: 0.0415 - val_accuracy: 0.9883\n",
      "Epoch 120/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0479 - accuracy: 0.9843 - val_loss: 0.0689 - val_accuracy: 0.9792\n",
      "Epoch 121/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0445 - accuracy: 0.9844 - val_loss: 0.0749 - val_accuracy: 0.9725\n",
      "Epoch 122/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0447 - accuracy: 0.9836 - val_loss: 0.0606 - val_accuracy: 0.9808\n",
      "Epoch 123/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0418 - accuracy: 0.9848 - val_loss: 0.0380 - val_accuracy: 0.9917\n",
      "Epoch 124/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0414 - accuracy: 0.9851 - val_loss: 0.0513 - val_accuracy: 0.9892\n",
      "Epoch 125/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0441 - accuracy: 0.9838 - val_loss: 0.0746 - val_accuracy: 0.9825\n",
      "Epoch 126/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0411 - accuracy: 0.9852 - val_loss: 0.0600 - val_accuracy: 0.9825\n",
      "Epoch 127/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0447 - accuracy: 0.9844 - val_loss: 0.0555 - val_accuracy: 0.9825\n",
      "Epoch 128/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0416 - accuracy: 0.9851 - val_loss: 0.0663 - val_accuracy: 0.9808\n",
      "Epoch 129/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0445 - accuracy: 0.9847 - val_loss: 0.0387 - val_accuracy: 0.9908\n",
      "Epoch 130/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0437 - accuracy: 0.9846 - val_loss: 0.0582 - val_accuracy: 0.9817\n",
      "Epoch 131/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0435 - accuracy: 0.9852 - val_loss: 0.0477 - val_accuracy: 0.9875\n",
      "Epoch 132/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0392 - accuracy: 0.9872 - val_loss: 0.0552 - val_accuracy: 0.9858\n",
      "Epoch 133/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0424 - accuracy: 0.9856 - val_loss: 0.0565 - val_accuracy: 0.9833\n",
      "Epoch 134/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0380 - accuracy: 0.9862 - val_loss: 0.0373 - val_accuracy: 0.9900\n",
      "Epoch 135/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0415 - accuracy: 0.9852 - val_loss: 0.0833 - val_accuracy: 0.9708\n",
      "Epoch 136/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0441 - accuracy: 0.9836 - val_loss: 0.0983 - val_accuracy: 0.9708\n",
      "Epoch 137/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0415 - accuracy: 0.9859 - val_loss: 0.0515 - val_accuracy: 0.9858\n",
      "Epoch 138/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0400 - accuracy: 0.9852 - val_loss: 0.0640 - val_accuracy: 0.9767\n",
      "Epoch 139/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0384 - accuracy: 0.9861 - val_loss: 0.1651 - val_accuracy: 0.9550\n",
      "Epoch 140/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0417 - accuracy: 0.9857 - val_loss: 0.0475 - val_accuracy: 0.9883\n",
      "Epoch 141/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0443 - accuracy: 0.9833 - val_loss: 0.0441 - val_accuracy: 0.9883\n",
      "Epoch 142/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0473 - accuracy: 0.9838 - val_loss: 0.0542 - val_accuracy: 0.9825\n",
      "Epoch 143/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0378 - accuracy: 0.9860 - val_loss: 0.0408 - val_accuracy: 0.9858\n",
      "Epoch 144/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0404 - accuracy: 0.9859 - val_loss: 0.0444 - val_accuracy: 0.9858\n",
      "Epoch 145/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0405 - accuracy: 0.9862 - val_loss: 0.0266 - val_accuracy: 0.9917\n",
      "Epoch 146/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0392 - accuracy: 0.9857 - val_loss: 0.0831 - val_accuracy: 0.9733\n",
      "Epoch 147/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0435 - accuracy: 0.9843 - val_loss: 0.0565 - val_accuracy: 0.9817\n",
      "Epoch 148/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0465 - accuracy: 0.9848 - val_loss: 0.0553 - val_accuracy: 0.9833\n",
      "Epoch 149/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0395 - accuracy: 0.9857 - val_loss: 0.0551 - val_accuracy: 0.9858\n",
      "Epoch 150/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0436 - accuracy: 0.9843 - val_loss: 0.0581 - val_accuracy: 0.9842\n",
      "Epoch 151/500\n",
      "367/375 [============================>.] - ETA: 0s - loss: 0.0435 - accuracy: 0.9843INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0446 - accuracy: 0.9841 - val_loss: 0.0362 - val_accuracy: 0.9925\n",
      "Epoch 152/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0361 - accuracy: 0.9879 - val_loss: 0.0279 - val_accuracy: 0.9917\n",
      "Epoch 153/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0390 - accuracy: 0.9868 - val_loss: 0.1143 - val_accuracy: 0.9633\n",
      "Epoch 154/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0410 - accuracy: 0.9859 - val_loss: 0.0549 - val_accuracy: 0.9817\n",
      "Epoch 155/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0406 - accuracy: 0.9858 - val_loss: 0.0804 - val_accuracy: 0.9733\n",
      "Epoch 156/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0426 - accuracy: 0.9844 - val_loss: 0.0636 - val_accuracy: 0.9825\n",
      "Epoch 157/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0417 - accuracy: 0.9862 - val_loss: 0.0389 - val_accuracy: 0.9900\n",
      "Epoch 158/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0383 - accuracy: 0.9854 - val_loss: 0.0579 - val_accuracy: 0.9842\n",
      "Epoch 159/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0409 - accuracy: 0.9854 - val_loss: 0.0573 - val_accuracy: 0.9825\n",
      "Epoch 160/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0397 - accuracy: 0.9845 - val_loss: 0.0701 - val_accuracy: 0.9767\n",
      "Epoch 161/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0375 - accuracy: 0.9858 - val_loss: 0.0609 - val_accuracy: 0.9783\n",
      "Epoch 162/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0357 - accuracy: 0.9873 - val_loss: 0.0341 - val_accuracy: 0.9925\n",
      "Epoch 163/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0379 - accuracy: 0.9873 - val_loss: 0.0471 - val_accuracy: 0.9875\n",
      "Epoch 164/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0407 - accuracy: 0.9853 - val_loss: 0.0839 - val_accuracy: 0.9775\n",
      "Epoch 165/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0375 - accuracy: 0.9857 - val_loss: 0.0506 - val_accuracy: 0.9850\n",
      "Epoch 166/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0377 - accuracy: 0.9865 - val_loss: 0.0600 - val_accuracy: 0.9842\n",
      "Epoch 167/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0398 - accuracy: 0.9858 - val_loss: 0.0617 - val_accuracy: 0.9808\n",
      "Epoch 168/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0363 - accuracy: 0.9872 - val_loss: 0.0601 - val_accuracy: 0.9825\n",
      "Epoch 169/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0416 - accuracy: 0.9855 - val_loss: 0.0629 - val_accuracy: 0.9767\n",
      "Epoch 170/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0416 - accuracy: 0.9846 - val_loss: 0.0633 - val_accuracy: 0.9800\n",
      "Epoch 171/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0347 - accuracy: 0.9881 - val_loss: 0.0404 - val_accuracy: 0.9892\n",
      "Epoch 172/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0397 - accuracy: 0.9864 - val_loss: 0.0572 - val_accuracy: 0.9817\n",
      "Epoch 173/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0348 - accuracy: 0.9872 - val_loss: 0.0532 - val_accuracy: 0.9867\n",
      "Epoch 174/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0377 - accuracy: 0.9868 - val_loss: 0.0603 - val_accuracy: 0.9817\n",
      "Epoch 175/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0425 - accuracy: 0.9849 - val_loss: 0.0884 - val_accuracy: 0.9683\n",
      "Epoch 176/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0376 - accuracy: 0.9877 - val_loss: 0.0527 - val_accuracy: 0.9875\n",
      "Epoch 177/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0362 - accuracy: 0.9876 - val_loss: 0.0431 - val_accuracy: 0.9875\n",
      "Epoch 178/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0356 - accuracy: 0.9877 - val_loss: 0.0548 - val_accuracy: 0.9825\n",
      "Epoch 179/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0391 - accuracy: 0.9859 - val_loss: 0.0357 - val_accuracy: 0.9908\n",
      "Epoch 180/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0415 - accuracy: 0.9843 - val_loss: 0.0725 - val_accuracy: 0.9767\n",
      "Epoch 181/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0327 - accuracy: 0.9889 - val_loss: 0.0775 - val_accuracy: 0.9742\n",
      "Epoch 182/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0388 - accuracy: 0.9865 - val_loss: 0.0627 - val_accuracy: 0.9817\n",
      "Epoch 183/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0389 - accuracy: 0.9866 - val_loss: 0.0504 - val_accuracy: 0.9842\n",
      "Epoch 184/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0352 - accuracy: 0.9868 - val_loss: 0.0446 - val_accuracy: 0.9850\n",
      "Epoch 185/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0425 - accuracy: 0.9853 - val_loss: 0.0425 - val_accuracy: 0.9883\n",
      "Epoch 186/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0369 - accuracy: 0.9877 - val_loss: 0.0474 - val_accuracy: 0.9875\n",
      "Epoch 187/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0351 - accuracy: 0.9883 - val_loss: 0.0612 - val_accuracy: 0.9867\n",
      "Epoch 188/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0362 - accuracy: 0.9868 - val_loss: 0.0484 - val_accuracy: 0.9833\n",
      "Epoch 189/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0350 - accuracy: 0.9865 - val_loss: 0.0738 - val_accuracy: 0.9792\n",
      "Epoch 190/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0375 - accuracy: 0.9861 - val_loss: 0.0732 - val_accuracy: 0.9775\n",
      "Epoch 191/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0361 - accuracy: 0.9873 - val_loss: 0.0256 - val_accuracy: 0.9917\n",
      "Epoch 192/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0349 - accuracy: 0.9881 - val_loss: 0.1253 - val_accuracy: 0.9642\n",
      "Epoch 193/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0410 - accuracy: 0.9846 - val_loss: 0.0522 - val_accuracy: 0.9858\n",
      "Epoch 194/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0387 - accuracy: 0.9870 - val_loss: 0.0594 - val_accuracy: 0.9850\n",
      "Epoch 195/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0380 - accuracy: 0.9873 - val_loss: 0.0554 - val_accuracy: 0.9842\n",
      "Epoch 196/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0412 - accuracy: 0.9841 - val_loss: 0.0620 - val_accuracy: 0.9817\n",
      "Epoch 197/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0379 - accuracy: 0.9874 - val_loss: 0.0428 - val_accuracy: 0.9883\n",
      "Epoch 198/500\n",
      "358/375 [===========================>..] - ETA: 0s - loss: 0.0386 - accuracy: 0.9852INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0385 - accuracy: 0.9853 - val_loss: 0.0320 - val_accuracy: 0.9933\n",
      "Epoch 199/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0382 - accuracy: 0.9854 - val_loss: 0.0510 - val_accuracy: 0.9817\n",
      "Epoch 200/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0330 - accuracy: 0.9867 - val_loss: 0.1122 - val_accuracy: 0.9583\n",
      "Epoch 201/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0398 - accuracy: 0.9863 - val_loss: 0.0635 - val_accuracy: 0.9825\n",
      "Epoch 202/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0309 - accuracy: 0.9886 - val_loss: 0.0679 - val_accuracy: 0.9817\n",
      "Epoch 203/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0344 - accuracy: 0.9879 - val_loss: 0.0432 - val_accuracy: 0.9867\n",
      "Epoch 204/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0367 - accuracy: 0.9862 - val_loss: 0.0557 - val_accuracy: 0.9817\n",
      "Epoch 205/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0382 - accuracy: 0.9871 - val_loss: 0.0506 - val_accuracy: 0.9825\n",
      "Epoch 206/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0360 - accuracy: 0.9864 - val_loss: 0.0564 - val_accuracy: 0.9792\n",
      "Epoch 207/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0357 - accuracy: 0.9872 - val_loss: 0.0405 - val_accuracy: 0.9900\n",
      "Epoch 208/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0314 - accuracy: 0.9889 - val_loss: 0.0649 - val_accuracy: 0.9825\n",
      "Epoch 209/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0359 - accuracy: 0.9866 - val_loss: 0.0475 - val_accuracy: 0.9850\n",
      "Epoch 210/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0333 - accuracy: 0.9886 - val_loss: 0.1289 - val_accuracy: 0.9550\n",
      "Epoch 211/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0417 - accuracy: 0.9848 - val_loss: 0.0999 - val_accuracy: 0.9692\n",
      "Epoch 212/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0358 - accuracy: 0.9884 - val_loss: 0.0595 - val_accuracy: 0.9867\n",
      "Epoch 213/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0377 - accuracy: 0.9862 - val_loss: 0.0723 - val_accuracy: 0.9750\n",
      "Epoch 214/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0351 - accuracy: 0.9873 - val_loss: 0.0505 - val_accuracy: 0.9833\n",
      "Epoch 215/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0285 - accuracy: 0.9892 - val_loss: 0.0493 - val_accuracy: 0.9850\n",
      "Epoch 216/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0338 - accuracy: 0.9870 - val_loss: 0.0402 - val_accuracy: 0.9883\n",
      "Epoch 217/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0350 - accuracy: 0.9882 - val_loss: 0.0386 - val_accuracy: 0.9892\n",
      "Epoch 218/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0413 - accuracy: 0.9865 - val_loss: 0.0476 - val_accuracy: 0.9867\n",
      "Epoch 219/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0365 - accuracy: 0.9868 - val_loss: 0.0413 - val_accuracy: 0.9842\n",
      "Epoch 220/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0342 - accuracy: 0.9877 - val_loss: 0.0601 - val_accuracy: 0.9833\n",
      "Epoch 221/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0446 - accuracy: 0.9837 - val_loss: 0.0809 - val_accuracy: 0.9725\n",
      "Epoch 222/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0356 - accuracy: 0.9867 - val_loss: 0.0563 - val_accuracy: 0.9833\n",
      "Epoch 223/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0355 - accuracy: 0.9866 - val_loss: 0.0364 - val_accuracy: 0.9883\n",
      "Epoch 224/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0361 - accuracy: 0.9862 - val_loss: 0.0719 - val_accuracy: 0.9775\n",
      "Epoch 225/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0382 - accuracy: 0.9862 - val_loss: 0.1172 - val_accuracy: 0.9617\n",
      "Epoch 226/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0374 - accuracy: 0.9868 - val_loss: 0.0699 - val_accuracy: 0.9783\n",
      "Epoch 227/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0355 - accuracy: 0.9869 - val_loss: 0.0520 - val_accuracy: 0.9850\n",
      "Epoch 228/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0330 - accuracy: 0.9877 - val_loss: 0.0444 - val_accuracy: 0.9858\n",
      "Epoch 229/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0355 - accuracy: 0.9877 - val_loss: 0.0391 - val_accuracy: 0.9908\n",
      "Epoch 230/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0327 - accuracy: 0.9879 - val_loss: 0.0383 - val_accuracy: 0.9892\n",
      "Epoch 231/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0431 - accuracy: 0.9843 - val_loss: 0.0515 - val_accuracy: 0.9850\n",
      "Epoch 232/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0322 - accuracy: 0.9882 - val_loss: 0.0473 - val_accuracy: 0.9875\n",
      "Epoch 233/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0352 - accuracy: 0.9863 - val_loss: 0.0410 - val_accuracy: 0.9842\n",
      "Epoch 234/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0335 - accuracy: 0.9879 - val_loss: 0.0501 - val_accuracy: 0.9850\n",
      "Epoch 235/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0317 - accuracy: 0.9884 - val_loss: 0.0484 - val_accuracy: 0.9842\n",
      "Epoch 236/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0361 - accuracy: 0.9859 - val_loss: 0.0575 - val_accuracy: 0.9858\n",
      "Epoch 237/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0312 - accuracy: 0.9888 - val_loss: 0.0664 - val_accuracy: 0.9775\n",
      "Epoch 238/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0362 - accuracy: 0.9874 - val_loss: 0.0521 - val_accuracy: 0.9833\n",
      "Epoch 239/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0337 - accuracy: 0.9868 - val_loss: 0.1830 - val_accuracy: 0.9533\n",
      "Epoch 240/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0393 - accuracy: 0.9873 - val_loss: 0.0481 - val_accuracy: 0.9825\n",
      "Epoch 241/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0306 - accuracy: 0.9902 - val_loss: 0.0404 - val_accuracy: 0.9875\n",
      "Epoch 242/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0375 - accuracy: 0.9868 - val_loss: 0.0585 - val_accuracy: 0.9833\n",
      "Epoch 243/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0331 - accuracy: 0.9870 - val_loss: 0.0417 - val_accuracy: 0.9858\n",
      "Epoch 244/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0316 - accuracy: 0.9887 - val_loss: 0.0491 - val_accuracy: 0.9850\n",
      "Epoch 245/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0410 - accuracy: 0.9857 - val_loss: 0.0722 - val_accuracy: 0.9825\n",
      "Epoch 246/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0313 - accuracy: 0.9887 - val_loss: 0.0404 - val_accuracy: 0.9900\n",
      "Epoch 247/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0320 - accuracy: 0.9886 - val_loss: 0.0573 - val_accuracy: 0.9850\n",
      "Epoch 248/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0444 - accuracy: 0.9845 - val_loss: 0.0968 - val_accuracy: 0.9708\n",
      "Epoch 249/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0353 - accuracy: 0.9880 - val_loss: 0.0499 - val_accuracy: 0.9867\n",
      "Epoch 250/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0345 - accuracy: 0.9881 - val_loss: 0.0235 - val_accuracy: 0.9925\n",
      "Epoch 251/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0340 - accuracy: 0.9884 - val_loss: 0.0303 - val_accuracy: 0.9900\n",
      "Epoch 252/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0320 - accuracy: 0.9875 - val_loss: 0.0408 - val_accuracy: 0.9900\n",
      "Epoch 253/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0337 - accuracy: 0.9884 - val_loss: 0.0669 - val_accuracy: 0.9792\n",
      "Epoch 254/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0385 - accuracy: 0.9864 - val_loss: 0.0320 - val_accuracy: 0.9908\n",
      "Epoch 255/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0340 - accuracy: 0.9877 - val_loss: 0.0660 - val_accuracy: 0.9783\n",
      "Epoch 256/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0294 - accuracy: 0.9893 - val_loss: 0.0417 - val_accuracy: 0.9858\n",
      "Epoch 257/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0348 - accuracy: 0.9874 - val_loss: 0.0368 - val_accuracy: 0.9883\n",
      "Epoch 258/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0362 - accuracy: 0.9875 - val_loss: 0.0678 - val_accuracy: 0.9833\n",
      "Epoch 259/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0349 - accuracy: 0.9875 - val_loss: 0.0983 - val_accuracy: 0.9667\n",
      "Epoch 260/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0321 - accuracy: 0.9892 - val_loss: 0.0582 - val_accuracy: 0.9783\n",
      "Epoch 261/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0344 - accuracy: 0.9872 - val_loss: 0.0314 - val_accuracy: 0.9925\n",
      "Epoch 262/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0317 - accuracy: 0.9881 - val_loss: 0.0346 - val_accuracy: 0.9908\n",
      "Epoch 263/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0334 - accuracy: 0.9884 - val_loss: 0.0554 - val_accuracy: 0.9833\n",
      "Epoch 264/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0348 - accuracy: 0.9868 - val_loss: 0.0352 - val_accuracy: 0.9925\n",
      "Epoch 265/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0340 - accuracy: 0.9877 - val_loss: 0.1325 - val_accuracy: 0.9608\n",
      "Epoch 266/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0339 - accuracy: 0.9874 - val_loss: 0.0490 - val_accuracy: 0.9842\n",
      "Epoch 267/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0310 - accuracy: 0.9899 - val_loss: 0.0481 - val_accuracy: 0.9850\n",
      "Epoch 268/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0321 - accuracy: 0.9885 - val_loss: 0.0531 - val_accuracy: 0.9833\n",
      "Epoch 269/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0346 - accuracy: 0.9874 - val_loss: 0.0516 - val_accuracy: 0.9833\n",
      "Epoch 270/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0342 - accuracy: 0.9878 - val_loss: 0.1504 - val_accuracy: 0.9508\n",
      "Epoch 271/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0363 - accuracy: 0.9866 - val_loss: 0.0415 - val_accuracy: 0.9892\n",
      "Epoch 272/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0338 - accuracy: 0.9869 - val_loss: 0.0615 - val_accuracy: 0.9775\n",
      "Epoch 273/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0318 - accuracy: 0.9891 - val_loss: 0.1373 - val_accuracy: 0.9508\n",
      "Epoch 274/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0367 - accuracy: 0.9858 - val_loss: 0.1214 - val_accuracy: 0.9583\n",
      "Epoch 275/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0350 - accuracy: 0.9875 - val_loss: 0.0863 - val_accuracy: 0.9783\n",
      "Epoch 276/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0336 - accuracy: 0.9878 - val_loss: 0.0916 - val_accuracy: 0.9742\n",
      "Epoch 277/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0362 - accuracy: 0.9858 - val_loss: 0.0617 - val_accuracy: 0.9792\n",
      "Epoch 278/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0330 - accuracy: 0.9877 - val_loss: 0.0747 - val_accuracy: 0.9725\n",
      "Epoch 279/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0328 - accuracy: 0.9876 - val_loss: 0.0543 - val_accuracy: 0.9833\n",
      "Epoch 280/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0326 - accuracy: 0.9881 - val_loss: 0.0633 - val_accuracy: 0.9808\n",
      "Epoch 281/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0352 - accuracy: 0.9876 - val_loss: 0.0351 - val_accuracy: 0.9917\n",
      "Epoch 282/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0342 - accuracy: 0.9895 - val_loss: 0.0791 - val_accuracy: 0.9750\n",
      "Epoch 283/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0328 - accuracy: 0.9883 - val_loss: 0.0748 - val_accuracy: 0.9717\n",
      "Epoch 284/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0322 - accuracy: 0.9885 - val_loss: 0.0662 - val_accuracy: 0.9783\n",
      "Epoch 285/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0293 - accuracy: 0.9898 - val_loss: 0.0662 - val_accuracy: 0.9783\n",
      "Epoch 286/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0319 - accuracy: 0.9887 - val_loss: 0.0775 - val_accuracy: 0.9717\n",
      "Epoch 287/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0444 - accuracy: 0.9852 - val_loss: 0.0355 - val_accuracy: 0.9892\n",
      "Epoch 288/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0332 - accuracy: 0.9881 - val_loss: 0.0945 - val_accuracy: 0.9742\n",
      "Epoch 289/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0354 - accuracy: 0.9878 - val_loss: 0.0677 - val_accuracy: 0.9775\n",
      "Epoch 290/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0313 - accuracy: 0.9887 - val_loss: 0.0586 - val_accuracy: 0.9792\n",
      "Epoch 291/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0366 - accuracy: 0.9872 - val_loss: 0.0502 - val_accuracy: 0.9850\n",
      "Epoch 292/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0326 - accuracy: 0.9880 - val_loss: 0.0472 - val_accuracy: 0.9867\n",
      "Epoch 293/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0338 - accuracy: 0.9877 - val_loss: 0.0482 - val_accuracy: 0.9867\n",
      "Epoch 294/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0343 - accuracy: 0.9885 - val_loss: 0.0462 - val_accuracy: 0.9867\n",
      "Epoch 295/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0322 - accuracy: 0.9879 - val_loss: 0.0676 - val_accuracy: 0.9742\n",
      "Epoch 296/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0276 - accuracy: 0.9896 - val_loss: 0.0292 - val_accuracy: 0.9883\n",
      "Epoch 297/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0309 - accuracy: 0.9883 - val_loss: 0.0645 - val_accuracy: 0.9817\n",
      "Epoch 298/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0298 - accuracy: 0.9896 - val_loss: 0.0496 - val_accuracy: 0.9833\n",
      "Epoch 299/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0336 - accuracy: 0.9887 - val_loss: 0.0225 - val_accuracy: 0.9908\n",
      "Epoch 300/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0340 - accuracy: 0.9874 - val_loss: 0.1130 - val_accuracy: 0.9650\n",
      "Epoch 301/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0316 - accuracy: 0.9896 - val_loss: 0.0414 - val_accuracy: 0.9892\n",
      "Epoch 302/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0341 - accuracy: 0.9877 - val_loss: 0.0473 - val_accuracy: 0.9825\n",
      "Epoch 303/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0325 - accuracy: 0.9880 - val_loss: 0.0484 - val_accuracy: 0.9850\n",
      "Epoch 304/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0321 - accuracy: 0.9892 - val_loss: 0.0428 - val_accuracy: 0.9825\n",
      "Epoch 305/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0334 - accuracy: 0.9873 - val_loss: 0.0336 - val_accuracy: 0.9892\n",
      "Epoch 306/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0303 - accuracy: 0.9890 - val_loss: 0.0336 - val_accuracy: 0.9900\n",
      "Epoch 307/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0315 - accuracy: 0.9886 - val_loss: 0.0425 - val_accuracy: 0.9892\n",
      "Epoch 308/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0335 - accuracy: 0.9872 - val_loss: 0.0676 - val_accuracy: 0.9742\n",
      "Epoch 309/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0319 - accuracy: 0.9885 - val_loss: 0.0737 - val_accuracy: 0.9792\n",
      "Epoch 310/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0396 - accuracy: 0.9865 - val_loss: 0.0537 - val_accuracy: 0.9817\n",
      "Epoch 311/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0332 - accuracy: 0.9879 - val_loss: 0.0556 - val_accuracy: 0.9842\n",
      "Epoch 312/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0286 - accuracy: 0.9889 - val_loss: 0.0616 - val_accuracy: 0.9800\n",
      "Epoch 313/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0296 - accuracy: 0.9886 - val_loss: 0.0443 - val_accuracy: 0.9875\n",
      "Epoch 314/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0381 - accuracy: 0.9855 - val_loss: 0.0498 - val_accuracy: 0.9858\n",
      "Epoch 315/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0290 - accuracy: 0.9894 - val_loss: 0.0371 - val_accuracy: 0.9892\n",
      "Epoch 316/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0295 - accuracy: 0.9887 - val_loss: 0.0572 - val_accuracy: 0.9825\n",
      "Epoch 317/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0308 - accuracy: 0.9885 - val_loss: 0.0409 - val_accuracy: 0.9908\n",
      "Epoch 318/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0291 - accuracy: 0.9893 - val_loss: 0.0601 - val_accuracy: 0.9800\n",
      "Epoch 319/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0302 - accuracy: 0.9894 - val_loss: 0.0488 - val_accuracy: 0.9858\n",
      "Epoch 320/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0292 - accuracy: 0.9894 - val_loss: 0.0334 - val_accuracy: 0.9917\n",
      "Epoch 321/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0348 - accuracy: 0.9884 - val_loss: 0.0410 - val_accuracy: 0.9892\n",
      "Epoch 322/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0426 - accuracy: 0.9859 - val_loss: 0.0456 - val_accuracy: 0.9850\n",
      "Epoch 323/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0262 - accuracy: 0.9907 - val_loss: 0.0621 - val_accuracy: 0.9800\n",
      "Epoch 324/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0304 - accuracy: 0.9885 - val_loss: 0.0538 - val_accuracy: 0.9842\n",
      "Epoch 325/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0362 - accuracy: 0.9868 - val_loss: 0.0582 - val_accuracy: 0.9808\n",
      "Epoch 326/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0296 - accuracy: 0.9882 - val_loss: 0.0429 - val_accuracy: 0.9883\n",
      "Epoch 327/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0285 - accuracy: 0.9896 - val_loss: 0.0320 - val_accuracy: 0.9917\n",
      "Epoch 328/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0290 - accuracy: 0.9899 - val_loss: 0.0489 - val_accuracy: 0.9825\n",
      "Epoch 329/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0319 - accuracy: 0.9885 - val_loss: 0.0796 - val_accuracy: 0.9758\n",
      "Epoch 330/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0317 - accuracy: 0.9887 - val_loss: 0.0936 - val_accuracy: 0.9767\n",
      "Epoch 331/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0318 - accuracy: 0.9894 - val_loss: 0.0408 - val_accuracy: 0.9867\n",
      "Epoch 332/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0314 - accuracy: 0.9892 - val_loss: 0.0695 - val_accuracy: 0.9775\n",
      "Epoch 333/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0270 - accuracy: 0.9896 - val_loss: 0.1373 - val_accuracy: 0.9617\n",
      "Epoch 334/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0300 - accuracy: 0.9892 - val_loss: 0.0531 - val_accuracy: 0.9800\n",
      "Epoch 335/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0275 - accuracy: 0.9899 - val_loss: 0.0282 - val_accuracy: 0.9900\n",
      "Epoch 336/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0290 - accuracy: 0.9893 - val_loss: 0.0370 - val_accuracy: 0.9892\n",
      "Epoch 337/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0334 - accuracy: 0.9883 - val_loss: 0.1194 - val_accuracy: 0.9617\n",
      "Epoch 338/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0309 - accuracy: 0.9893 - val_loss: 0.0405 - val_accuracy: 0.9900\n",
      "Epoch 339/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0296 - accuracy: 0.9887 - val_loss: 0.0891 - val_accuracy: 0.9750\n",
      "Epoch 340/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0389 - accuracy: 0.9855 - val_loss: 0.1150 - val_accuracy: 0.9633\n",
      "Epoch 341/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0322 - accuracy: 0.9878 - val_loss: 0.0794 - val_accuracy: 0.9742\n",
      "Epoch 342/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0290 - accuracy: 0.9898 - val_loss: 0.0509 - val_accuracy: 0.9817\n",
      "Epoch 343/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0294 - accuracy: 0.9899 - val_loss: 0.1023 - val_accuracy: 0.9650\n",
      "Epoch 344/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0283 - accuracy: 0.9894 - val_loss: 0.0427 - val_accuracy: 0.9842\n",
      "Epoch 345/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0340 - accuracy: 0.9872 - val_loss: 0.1200 - val_accuracy: 0.9667\n",
      "Epoch 346/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0301 - accuracy: 0.9884 - val_loss: 0.1371 - val_accuracy: 0.9567\n",
      "Epoch 347/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0361 - accuracy: 0.9877 - val_loss: 0.0305 - val_accuracy: 0.9900\n",
      "Epoch 348/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0309 - accuracy: 0.9889 - val_loss: 0.1290 - val_accuracy: 0.9692\n",
      "Epoch 349/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0343 - accuracy: 0.9879 - val_loss: 0.0586 - val_accuracy: 0.9833\n",
      "Epoch 350/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0279 - accuracy: 0.9897 - val_loss: 0.0863 - val_accuracy: 0.9750\n",
      "Epoch 351/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0309 - accuracy: 0.9891 - val_loss: 0.0755 - val_accuracy: 0.9742\n",
      "Epoch 352/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0297 - accuracy: 0.9892 - val_loss: 0.0955 - val_accuracy: 0.9725\n",
      "Epoch 353/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0271 - accuracy: 0.9904 - val_loss: 0.1324 - val_accuracy: 0.9567\n",
      "Epoch 354/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0347 - accuracy: 0.9866 - val_loss: 0.0664 - val_accuracy: 0.9808\n",
      "Epoch 355/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0305 - accuracy: 0.9887 - val_loss: 0.0473 - val_accuracy: 0.9817\n",
      "Epoch 356/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0289 - accuracy: 0.9899 - val_loss: 0.0644 - val_accuracy: 0.9775\n",
      "Epoch 357/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0362 - accuracy: 0.9869 - val_loss: 0.0766 - val_accuracy: 0.9792\n",
      "Epoch 358/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0310 - accuracy: 0.9886 - val_loss: 0.0815 - val_accuracy: 0.9692\n",
      "Epoch 359/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0342 - accuracy: 0.9871 - val_loss: 0.0764 - val_accuracy: 0.9792\n",
      "Epoch 360/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0291 - accuracy: 0.9883 - val_loss: 0.0989 - val_accuracy: 0.9733\n",
      "Epoch 361/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0299 - accuracy: 0.9894 - val_loss: 0.0711 - val_accuracy: 0.9767\n",
      "Epoch 362/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0310 - accuracy: 0.9885 - val_loss: 0.0613 - val_accuracy: 0.9792\n",
      "Epoch 363/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0266 - accuracy: 0.9905 - val_loss: 0.1655 - val_accuracy: 0.9600\n",
      "Epoch 364/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0307 - accuracy: 0.9890 - val_loss: 0.0559 - val_accuracy: 0.9883\n",
      "Epoch 365/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0386 - accuracy: 0.9862 - val_loss: 0.1200 - val_accuracy: 0.9642\n",
      "Epoch 366/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0279 - accuracy: 0.9889 - val_loss: 0.0563 - val_accuracy: 0.9833\n",
      "Epoch 367/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0395 - accuracy: 0.9854 - val_loss: 0.0761 - val_accuracy: 0.9733\n",
      "Epoch 368/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0286 - accuracy: 0.9902 - val_loss: 0.0631 - val_accuracy: 0.9792\n",
      "Epoch 369/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0269 - accuracy: 0.9902 - val_loss: 0.0845 - val_accuracy: 0.9733\n",
      "Epoch 370/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0266 - accuracy: 0.9902 - val_loss: 0.1156 - val_accuracy: 0.9642\n",
      "Epoch 371/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0312 - accuracy: 0.9877 - val_loss: 0.0470 - val_accuracy: 0.9817\n",
      "Epoch 372/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0275 - accuracy: 0.9902 - val_loss: 0.0786 - val_accuracy: 0.9717\n",
      "Epoch 373/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0307 - accuracy: 0.9882 - val_loss: 0.0951 - val_accuracy: 0.9700\n",
      "Epoch 374/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0302 - accuracy: 0.9893 - val_loss: 0.0799 - val_accuracy: 0.9742\n",
      "Epoch 375/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0297 - accuracy: 0.9897 - val_loss: 0.1540 - val_accuracy: 0.9492\n",
      "Epoch 376/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0297 - accuracy: 0.9898 - val_loss: 0.0486 - val_accuracy: 0.9850\n",
      "Epoch 377/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0281 - accuracy: 0.9892 - val_loss: 0.1279 - val_accuracy: 0.9558\n",
      "Epoch 378/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0317 - accuracy: 0.9886 - val_loss: 0.0534 - val_accuracy: 0.9850\n",
      "Epoch 379/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0280 - accuracy: 0.9908 - val_loss: 0.1181 - val_accuracy: 0.9617\n",
      "Epoch 380/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0321 - accuracy: 0.9890 - val_loss: 0.0678 - val_accuracy: 0.9808\n",
      "Epoch 381/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0286 - accuracy: 0.9891 - val_loss: 0.0865 - val_accuracy: 0.9700\n",
      "Epoch 382/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0367 - accuracy: 0.9873 - val_loss: 0.1135 - val_accuracy: 0.9667\n",
      "Epoch 383/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0321 - accuracy: 0.9889 - val_loss: 0.0628 - val_accuracy: 0.9800\n",
      "Epoch 384/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0266 - accuracy: 0.9907 - val_loss: 0.0658 - val_accuracy: 0.9800\n",
      "Epoch 385/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0265 - accuracy: 0.9904 - val_loss: 0.0466 - val_accuracy: 0.9833\n",
      "Epoch 386/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0329 - accuracy: 0.9883 - val_loss: 0.1373 - val_accuracy: 0.9583\n",
      "Epoch 387/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0286 - accuracy: 0.9892 - val_loss: 0.0390 - val_accuracy: 0.9883\n",
      "Epoch 388/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0323 - accuracy: 0.9888 - val_loss: 0.1122 - val_accuracy: 0.9708\n",
      "Epoch 389/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0298 - accuracy: 0.9889 - val_loss: 0.0765 - val_accuracy: 0.9767\n",
      "Epoch 390/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0303 - accuracy: 0.9889 - val_loss: 0.4070 - val_accuracy: 0.9092\n",
      "Epoch 391/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0302 - accuracy: 0.9892 - val_loss: 0.1169 - val_accuracy: 0.9525\n",
      "Epoch 392/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0342 - accuracy: 0.9880 - val_loss: 0.0936 - val_accuracy: 0.9650\n",
      "Epoch 393/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0287 - accuracy: 0.9898 - val_loss: 0.0445 - val_accuracy: 0.9867\n",
      "Epoch 394/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0335 - accuracy: 0.9872 - val_loss: 0.0463 - val_accuracy: 0.9867\n",
      "Epoch 395/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0281 - accuracy: 0.9898 - val_loss: 0.1056 - val_accuracy: 0.9625\n",
      "Epoch 396/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0292 - accuracy: 0.9893 - val_loss: 0.1186 - val_accuracy: 0.9567\n",
      "Epoch 397/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0263 - accuracy: 0.9899 - val_loss: 0.1138 - val_accuracy: 0.9658\n",
      "Epoch 398/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0280 - accuracy: 0.9889 - val_loss: 0.1072 - val_accuracy: 0.9700\n",
      "Epoch 399/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0332 - accuracy: 0.9884 - val_loss: 0.0708 - val_accuracy: 0.9800\n",
      "Epoch 400/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0266 - accuracy: 0.9896 - val_loss: 0.1554 - val_accuracy: 0.9492\n",
      "Epoch 401/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0288 - accuracy: 0.9894 - val_loss: 0.0571 - val_accuracy: 0.9817\n",
      "Epoch 402/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0285 - accuracy: 0.9897 - val_loss: 0.0678 - val_accuracy: 0.9767\n",
      "Epoch 403/500\n",
      "362/375 [===========================>..] - ETA: 0s - loss: 0.0281 - accuracy: 0.9890INFO:tensorflow:Assets written to: ./normalization/assets\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0280 - accuracy: 0.9889 - val_loss: 0.0263 - val_accuracy: 0.9950\n",
      "Epoch 404/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0309 - accuracy: 0.9881 - val_loss: 0.1427 - val_accuracy: 0.9500\n",
      "Epoch 405/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0268 - accuracy: 0.9907 - val_loss: 0.0390 - val_accuracy: 0.9850\n",
      "Epoch 406/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0362 - accuracy: 0.9861 - val_loss: 0.0482 - val_accuracy: 0.9875\n",
      "Epoch 407/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0299 - accuracy: 0.9886 - val_loss: 0.0912 - val_accuracy: 0.9775\n",
      "Epoch 408/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0334 - accuracy: 0.9883 - val_loss: 0.0875 - val_accuracy: 0.9767\n",
      "Epoch 409/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0324 - accuracy: 0.9890 - val_loss: 0.0942 - val_accuracy: 0.9700\n",
      "Epoch 410/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0287 - accuracy: 0.9897 - val_loss: 0.0554 - val_accuracy: 0.9825\n",
      "Epoch 411/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0244 - accuracy: 0.9910 - val_loss: 0.0342 - val_accuracy: 0.9917\n",
      "Epoch 412/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0300 - accuracy: 0.9892 - val_loss: 0.0446 - val_accuracy: 0.9842\n",
      "Epoch 413/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0266 - accuracy: 0.9897 - val_loss: 0.1835 - val_accuracy: 0.9433\n",
      "Epoch 414/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0261 - accuracy: 0.9899 - val_loss: 0.0693 - val_accuracy: 0.9775\n",
      "Epoch 415/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0264 - accuracy: 0.9903 - val_loss: 0.0712 - val_accuracy: 0.9792\n",
      "Epoch 416/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0307 - accuracy: 0.9887 - val_loss: 0.1503 - val_accuracy: 0.9575\n",
      "Epoch 417/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0284 - accuracy: 0.9885 - val_loss: 0.0766 - val_accuracy: 0.9758\n",
      "Epoch 418/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0331 - accuracy: 0.9877 - val_loss: 0.0417 - val_accuracy: 0.9917\n",
      "Epoch 419/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0305 - accuracy: 0.9882 - val_loss: 0.1153 - val_accuracy: 0.9667\n",
      "Epoch 420/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0272 - accuracy: 0.9903 - val_loss: 0.0641 - val_accuracy: 0.9783\n",
      "Epoch 421/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0277 - accuracy: 0.9899 - val_loss: 0.0800 - val_accuracy: 0.9750\n",
      "Epoch 422/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0257 - accuracy: 0.9898 - val_loss: 0.0627 - val_accuracy: 0.9808\n",
      "Epoch 423/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0279 - accuracy: 0.9897 - val_loss: 0.1130 - val_accuracy: 0.9633\n",
      "Epoch 424/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0322 - accuracy: 0.9872 - val_loss: 0.0556 - val_accuracy: 0.9867\n",
      "Epoch 425/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0266 - accuracy: 0.9901 - val_loss: 0.0700 - val_accuracy: 0.9792\n",
      "Epoch 426/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0339 - accuracy: 0.9882 - val_loss: 0.0986 - val_accuracy: 0.9700\n",
      "Epoch 427/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0295 - accuracy: 0.9893 - val_loss: 0.0703 - val_accuracy: 0.9792\n",
      "Epoch 428/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0282 - accuracy: 0.9893 - val_loss: 0.0719 - val_accuracy: 0.9792\n",
      "Epoch 429/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0266 - accuracy: 0.9902 - val_loss: 0.0716 - val_accuracy: 0.9783\n",
      "Epoch 430/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0318 - accuracy: 0.9896 - val_loss: 0.1095 - val_accuracy: 0.9692\n",
      "Epoch 431/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0293 - accuracy: 0.9900 - val_loss: 0.0545 - val_accuracy: 0.9892\n",
      "Epoch 432/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0278 - accuracy: 0.9908 - val_loss: 0.0350 - val_accuracy: 0.9883\n",
      "Epoch 433/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0281 - accuracy: 0.9905 - val_loss: 0.1625 - val_accuracy: 0.9425\n",
      "Epoch 434/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0280 - accuracy: 0.9904 - val_loss: 0.1506 - val_accuracy: 0.9542\n",
      "Epoch 435/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0318 - accuracy: 0.9884 - val_loss: 0.1187 - val_accuracy: 0.9650\n",
      "Epoch 436/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0290 - accuracy: 0.9891 - val_loss: 0.1236 - val_accuracy: 0.9717\n",
      "Epoch 437/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0310 - accuracy: 0.9893 - val_loss: 0.0624 - val_accuracy: 0.9817\n",
      "Epoch 438/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0268 - accuracy: 0.9904 - val_loss: 0.0830 - val_accuracy: 0.9808\n",
      "Epoch 439/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0283 - accuracy: 0.9890 - val_loss: 0.0547 - val_accuracy: 0.9833\n",
      "Epoch 440/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0291 - accuracy: 0.9903 - val_loss: 0.1196 - val_accuracy: 0.9642\n",
      "Epoch 441/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0293 - accuracy: 0.9893 - val_loss: 0.0610 - val_accuracy: 0.9825\n",
      "Epoch 442/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0340 - accuracy: 0.9877 - val_loss: 0.3372 - val_accuracy: 0.9142\n",
      "Epoch 443/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0276 - accuracy: 0.9898 - val_loss: 0.0734 - val_accuracy: 0.9750\n",
      "Epoch 444/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0301 - accuracy: 0.9890 - val_loss: 0.0543 - val_accuracy: 0.9792\n",
      "Epoch 445/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0304 - accuracy: 0.9901 - val_loss: 0.0723 - val_accuracy: 0.9817\n",
      "Epoch 446/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0293 - accuracy: 0.9896 - val_loss: 0.0714 - val_accuracy: 0.9775\n",
      "Epoch 447/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0308 - accuracy: 0.9899 - val_loss: 0.0619 - val_accuracy: 0.9767\n",
      "Epoch 448/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0318 - accuracy: 0.9900 - val_loss: 0.1561 - val_accuracy: 0.9642\n",
      "Epoch 449/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0328 - accuracy: 0.9896 - val_loss: 0.0589 - val_accuracy: 0.9800\n",
      "Epoch 450/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0239 - accuracy: 0.9907 - val_loss: 0.0473 - val_accuracy: 0.9867\n",
      "Epoch 451/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0275 - accuracy: 0.9898 - val_loss: 0.0606 - val_accuracy: 0.9808\n",
      "Epoch 452/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0254 - accuracy: 0.9907 - val_loss: 0.1508 - val_accuracy: 0.9650\n",
      "Epoch 453/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0265 - accuracy: 0.9902 - val_loss: 0.0733 - val_accuracy: 0.9783\n",
      "Epoch 454/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0299 - accuracy: 0.9899 - val_loss: 0.0988 - val_accuracy: 0.9658\n",
      "Epoch 455/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0275 - accuracy: 0.9895 - val_loss: 0.0380 - val_accuracy: 0.9883\n",
      "Epoch 456/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0260 - accuracy: 0.9915 - val_loss: 0.0860 - val_accuracy: 0.9717\n",
      "Epoch 457/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0337 - accuracy: 0.9878 - val_loss: 0.0717 - val_accuracy: 0.9808\n",
      "Epoch 458/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0274 - accuracy: 0.9901 - val_loss: 0.1026 - val_accuracy: 0.9633\n",
      "Epoch 459/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0242 - accuracy: 0.9910 - val_loss: 0.0781 - val_accuracy: 0.9758\n",
      "Epoch 460/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0251 - accuracy: 0.9909 - val_loss: 0.1265 - val_accuracy: 0.9575\n",
      "Epoch 461/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0306 - accuracy: 0.9896 - val_loss: 0.2047 - val_accuracy: 0.9425\n",
      "Epoch 462/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0318 - accuracy: 0.9884 - val_loss: 0.1012 - val_accuracy: 0.9667\n",
      "Epoch 463/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0251 - accuracy: 0.9915 - val_loss: 0.1662 - val_accuracy: 0.9500\n",
      "Epoch 464/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0274 - accuracy: 0.9909 - val_loss: 0.0574 - val_accuracy: 0.9883\n",
      "Epoch 465/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0330 - accuracy: 0.9884 - val_loss: 0.0988 - val_accuracy: 0.9658\n",
      "Epoch 466/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0267 - accuracy: 0.9912 - val_loss: 0.1465 - val_accuracy: 0.9642\n",
      "Epoch 467/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0312 - accuracy: 0.9888 - val_loss: 0.0865 - val_accuracy: 0.9700\n",
      "Epoch 468/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0344 - accuracy: 0.9873 - val_loss: 0.0488 - val_accuracy: 0.9833\n",
      "Epoch 469/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0244 - accuracy: 0.9913 - val_loss: 0.0997 - val_accuracy: 0.9667\n",
      "Epoch 470/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0264 - accuracy: 0.9902 - val_loss: 0.0520 - val_accuracy: 0.9833\n",
      "Epoch 471/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0342 - accuracy: 0.9873 - val_loss: 0.0574 - val_accuracy: 0.9825\n",
      "Epoch 472/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0280 - accuracy: 0.9897 - val_loss: 0.0436 - val_accuracy: 0.9858\n",
      "Epoch 473/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0252 - accuracy: 0.9916 - val_loss: 0.0782 - val_accuracy: 0.9792\n",
      "Epoch 474/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0302 - accuracy: 0.9888 - val_loss: 0.1022 - val_accuracy: 0.9717\n",
      "Epoch 475/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0246 - accuracy: 0.9910 - val_loss: 0.1037 - val_accuracy: 0.9683\n",
      "Epoch 476/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0256 - accuracy: 0.9906 - val_loss: 0.0613 - val_accuracy: 0.9808\n",
      "Epoch 477/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0248 - accuracy: 0.9918 - val_loss: 0.0803 - val_accuracy: 0.9767\n",
      "Epoch 478/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0250 - accuracy: 0.9908 - val_loss: 0.1777 - val_accuracy: 0.9550\n",
      "Epoch 479/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0315 - accuracy: 0.9893 - val_loss: 0.0605 - val_accuracy: 0.9808\n",
      "Epoch 480/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0288 - accuracy: 0.9899 - val_loss: 0.0544 - val_accuracy: 0.9867\n",
      "Epoch 481/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0304 - accuracy: 0.9891 - val_loss: 0.0966 - val_accuracy: 0.9700\n",
      "Epoch 482/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0296 - accuracy: 0.9894 - val_loss: 0.0916 - val_accuracy: 0.9750\n",
      "Epoch 483/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0272 - accuracy: 0.9899 - val_loss: 0.0419 - val_accuracy: 0.9883\n",
      "Epoch 484/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0317 - accuracy: 0.9890 - val_loss: 0.0769 - val_accuracy: 0.9783\n",
      "Epoch 485/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0294 - accuracy: 0.9895 - val_loss: 0.0740 - val_accuracy: 0.9792\n",
      "Epoch 486/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0301 - accuracy: 0.9901 - val_loss: 0.0653 - val_accuracy: 0.9808\n",
      "Epoch 487/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0269 - accuracy: 0.9902 - val_loss: 0.0908 - val_accuracy: 0.9733\n",
      "Epoch 488/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0245 - accuracy: 0.9908 - val_loss: 0.0435 - val_accuracy: 0.9883\n",
      "Epoch 489/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0292 - accuracy: 0.9899 - val_loss: 0.0540 - val_accuracy: 0.9858\n",
      "Epoch 490/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0290 - accuracy: 0.9904 - val_loss: 0.0550 - val_accuracy: 0.9825\n",
      "Epoch 491/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0333 - accuracy: 0.9882 - val_loss: 0.1158 - val_accuracy: 0.9683\n",
      "Epoch 492/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0237 - accuracy: 0.9917 - val_loss: 0.1238 - val_accuracy: 0.9608\n",
      "Epoch 493/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0266 - accuracy: 0.9902 - val_loss: 0.1039 - val_accuracy: 0.9683\n",
      "Epoch 494/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0251 - accuracy: 0.9913 - val_loss: 0.0942 - val_accuracy: 0.9733\n",
      "Epoch 495/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0266 - accuracy: 0.9905 - val_loss: 0.0522 - val_accuracy: 0.9867\n",
      "Epoch 496/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0255 - accuracy: 0.9912 - val_loss: 0.1299 - val_accuracy: 0.9608\n",
      "Epoch 497/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0294 - accuracy: 0.9897 - val_loss: 0.0538 - val_accuracy: 0.9858\n",
      "Epoch 498/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0246 - accuracy: 0.9901 - val_loss: 0.0744 - val_accuracy: 0.9725\n",
      "Epoch 499/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0282 - accuracy: 0.9904 - val_loss: 0.0959 - val_accuracy: 0.9717\n",
      "Epoch 500/500\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0270 - accuracy: 0.9905 - val_loss: 0.0675 - val_accuracy: 0.9808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ipykernel_launcher:7: MatplotlibDeprecationWarning: Unrecognized location 'upperleft'. Falling back on 'best'; valid locations are\n",
      "\tbest\n",
      "\tupper right\n",
      "\tupper left\n",
      "\tlower left\n",
      "\tlower right\n",
      "\tright\n",
      "\tcenter left\n",
      "\tcenter right\n",
      "\tlower center\n",
      "\tupper center\n",
      "\tcenter\n",
      "This will raise an exception in 3.3.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history2 = training(X_n, Y_s, test_X = test_X_n, test_Y = test_Y_s, EPOCHS = 500, cp_filepath='./normalization')\n",
    "plotting(history2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9908333420753479\n"
     ]
    }
   ],
   "source": [
    "print(max(history1.history['val_accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9950000047683716\n"
     ]
    }
   ],
   "source": [
    "print(max(history2.history['val_accuracy']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "77685dea35024d00c47c2bd6674a5d99e524bb0acc43ac0da346cfc9a7e35ee9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('radar')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
